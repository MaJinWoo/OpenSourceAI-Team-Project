{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "mount_file_id": "16LgTp6ZtFydZRN-GP_nlt5r5xtgaWVjz",
      "authorship_tag": "ABX9TyPWbwe4vTiZZ8OhM6v+iGr2",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/MaJinWoo/OpenSourceAI-Team-Project/blob/main/%ED%8C%80%ED%94%8C.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.utils import np_utils\n",
        "from keras.datasets import mnist\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Activation\n"
      ],
      "metadata": {
        "id": "75_Wayrh5Vz8"
      },
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "i2vlbBVTnj3T",
        "outputId": "284f5089-39e4-44e7-a191-d80defa90bff"
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "f_path = '/content/drive/MyDrive/heart.csv'"
      ],
      "metadata": {
        "id": "ednJYqRXnwWO"
      },
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "heart = pd.read_csv(f_path)"
      ],
      "metadata": {
        "id": "COKrcDS2prwy"
      },
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "heart = pd.get_dummies(heart)\n",
        "heart.count()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EwE7oj_vqNWX",
        "outputId": "9d055d3d-c5cf-4bcc-f948-8e174e36b657"
      },
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Age                  918\n",
              "RestingBP            918\n",
              "Cholesterol          918\n",
              "FastingBS            918\n",
              "MaxHR                918\n",
              "Oldpeak              918\n",
              "HeartDisease         918\n",
              "Sex_F                918\n",
              "Sex_M                918\n",
              "ChestPainType_ASY    918\n",
              "ChestPainType_ATA    918\n",
              "ChestPainType_NAP    918\n",
              "ChestPainType_TA     918\n",
              "RestingECG_LVH       918\n",
              "RestingECG_Normal    918\n",
              "RestingECG_ST        918\n",
              "ExerciseAngina_N     918\n",
              "ExerciseAngina_Y     918\n",
              "ST_Slope_Down        918\n",
              "ST_Slope_Flat        918\n",
              "ST_Slope_Up          918\n",
              "dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 41
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x = heart.drop('HeartDisease', axis=1)\n",
        "y = pd.get_dummies(heart[\"HeartDisease\"])\n"
      ],
      "metadata": {
        "id": "MkwhaogSqZ77"
      },
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "heart.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 300
        },
        "id": "ymWD5B1gdbKk",
        "outputId": "30c8c4ad-661d-4c6f-e68f-4e013770eb70"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   Age  RestingBP  Cholesterol  FastingBS  MaxHR  Oldpeak  HeartDisease  \\\n",
              "0   40        140          289          0    172      0.0             0   \n",
              "1   49        160          180          0    156      1.0             1   \n",
              "2   37        130          283          0     98      0.0             0   \n",
              "3   48        138          214          0    108      1.5             1   \n",
              "4   54        150          195          0    122      0.0             0   \n",
              "\n",
              "   Sex_F  Sex_M  ChestPainType_ASY  ...  ChestPainType_NAP  ChestPainType_TA  \\\n",
              "0      0      1                  0  ...                  0                 0   \n",
              "1      1      0                  0  ...                  1                 0   \n",
              "2      0      1                  0  ...                  0                 0   \n",
              "3      1      0                  1  ...                  0                 0   \n",
              "4      0      1                  0  ...                  1                 0   \n",
              "\n",
              "   RestingECG_LVH  RestingECG_Normal  RestingECG_ST  ExerciseAngina_N  \\\n",
              "0               0                  1              0                 1   \n",
              "1               0                  1              0                 1   \n",
              "2               0                  0              1                 1   \n",
              "3               0                  1              0                 0   \n",
              "4               0                  1              0                 1   \n",
              "\n",
              "   ExerciseAngina_Y  ST_Slope_Down  ST_Slope_Flat  ST_Slope_Up  \n",
              "0                 0              0              0            1  \n",
              "1                 0              0              1            0  \n",
              "2                 0              0              0            1  \n",
              "3                 1              0              1            0  \n",
              "4                 0              0              0            1  \n",
              "\n",
              "[5 rows x 21 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-53ac6926-ca68-425c-b3ea-7ae21bd8a046\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Age</th>\n",
              "      <th>RestingBP</th>\n",
              "      <th>Cholesterol</th>\n",
              "      <th>FastingBS</th>\n",
              "      <th>MaxHR</th>\n",
              "      <th>Oldpeak</th>\n",
              "      <th>HeartDisease</th>\n",
              "      <th>Sex_F</th>\n",
              "      <th>Sex_M</th>\n",
              "      <th>ChestPainType_ASY</th>\n",
              "      <th>...</th>\n",
              "      <th>ChestPainType_NAP</th>\n",
              "      <th>ChestPainType_TA</th>\n",
              "      <th>RestingECG_LVH</th>\n",
              "      <th>RestingECG_Normal</th>\n",
              "      <th>RestingECG_ST</th>\n",
              "      <th>ExerciseAngina_N</th>\n",
              "      <th>ExerciseAngina_Y</th>\n",
              "      <th>ST_Slope_Down</th>\n",
              "      <th>ST_Slope_Flat</th>\n",
              "      <th>ST_Slope_Up</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>40</td>\n",
              "      <td>140</td>\n",
              "      <td>289</td>\n",
              "      <td>0</td>\n",
              "      <td>172</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>49</td>\n",
              "      <td>160</td>\n",
              "      <td>180</td>\n",
              "      <td>0</td>\n",
              "      <td>156</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>37</td>\n",
              "      <td>130</td>\n",
              "      <td>283</td>\n",
              "      <td>0</td>\n",
              "      <td>98</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>48</td>\n",
              "      <td>138</td>\n",
              "      <td>214</td>\n",
              "      <td>0</td>\n",
              "      <td>108</td>\n",
              "      <td>1.5</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>54</td>\n",
              "      <td>150</td>\n",
              "      <td>195</td>\n",
              "      <td>0</td>\n",
              "      <td>122</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows × 21 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-53ac6926-ca68-425c-b3ea-7ae21bd8a046')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-53ac6926-ca68-425c-b3ea-7ae21bd8a046 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-53ac6926-ca68-425c-b3ea-7ae21bd8a046');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size = 0.13,shuffle=True, random_state = 42)\n",
        "\n",
        "print(\"X_train: \", x_train.shape)\n",
        "print(\"y_train: \", y_train.shape)\n",
        "\n",
        "print(\"X_test: \", x_test.shape)\n",
        "print(\"y_test: \", y_test.shape)"
      ],
      "metadata": {
        "id": "0ktxkdpfqdbu",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "13d56c48-a614-4250-a1a1-cff07d68f634"
      },
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "X_train:  (798, 20)\n",
            "y_train:  (798, 2)\n",
            "X_test:  (120, 20)\n",
            "y_test:  (120, 2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_test"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "id": "8VeeiPLIEm9W",
        "outputId": "1d45b72a-c2a6-40ca-af9f-ca655c465b38"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "     0  1\n",
              "668  1  0\n",
              "30   0  1\n",
              "377  0  1\n",
              "535  0  1\n",
              "807  1  0\n",
              "..  .. ..\n",
              "839  1  0\n",
              "299  0  1\n",
              "597  1  0\n",
              "685  0  1\n",
              "844  1  0\n",
              "\n",
              "[120 rows x 2 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-c778e4d1-9aec-4620-ae7f-dca124469c5b\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>668</th>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>30</th>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>377</th>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>535</th>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>807</th>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>839</th>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>299</th>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>597</th>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>685</th>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>844</th>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>120 rows × 2 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-c778e4d1-9aec-4620-ae7f-dca124469c5b')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-c778e4d1-9aec-4620-ae7f-dca124469c5b button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-c778e4d1-9aec-4620-ae7f-dca124469c5b');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 94
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "FullModel"
      ],
      "metadata": {
        "id": "Csj4QiHT9Rne"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import keras\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Dropout, Activation\n",
        "\n",
        "fullmodel = Sequential()\n",
        "\n",
        "\n",
        "fullmodel.add(Dense(128, activation = \"relu\",input_dim=20))\n",
        "fullmodel.add(Dropout(rate=0.2))\n",
        "fullmodel.add(Dense(64, activation = \"relu\"))\n",
        "fullmodel.add(Dropout(rate=0.2))\n",
        "fullmodel.add(Dense(32, activation = \"relu\"))\n",
        "fullmodel.add(Dropout(rate=0.1))\n",
        "fullmodel.add(Dense(16, activation = \"relu\"))\n",
        "fullmodel.add(Dense(8, activation = \"relu\"))\n",
        "fullmodel.add(Dense(2, activation = \"sigmoid\"))\n",
        "\n",
        "fullmodel.compile(optimizer = \"adam\", loss = \"categorical_crossentropy\", metrics = [\"accuracy\"])\n",
        "fullmodel.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iYIC_a_H4524",
        "outputId": "ddc04b9d-88fd-4772-d026-aba5d0b95382"
      },
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_3\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense_18 (Dense)            (None, 128)               2688      \n",
            "                                                                 \n",
            " dropout_9 (Dropout)         (None, 128)               0         \n",
            "                                                                 \n",
            " dense_19 (Dense)            (None, 64)                8256      \n",
            "                                                                 \n",
            " dropout_10 (Dropout)        (None, 64)                0         \n",
            "                                                                 \n",
            " dense_20 (Dense)            (None, 32)                2080      \n",
            "                                                                 \n",
            " dropout_11 (Dropout)        (None, 32)                0         \n",
            "                                                                 \n",
            " dense_21 (Dense)            (None, 16)                528       \n",
            "                                                                 \n",
            " dense_22 (Dense)            (None, 8)                 136       \n",
            "                                                                 \n",
            " dense_23 (Dense)            (None, 2)                 18        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 13,706\n",
            "Trainable params: 13,706\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "hin=fullmodel.fit(x_train,y_train,epochs=200, validation_split=0.2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KxdybnVm-a32",
        "outputId": "edc616e4-3b1a-4175-aedf-0a9b363afabb"
      },
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/200\n",
            "20/20 [==============================] - 1s 12ms/step - loss: 3.8318 - accuracy: 0.5345 - val_loss: 1.2512 - val_accuracy: 0.4938\n",
            "Epoch 2/200\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 1.4859 - accuracy: 0.5282 - val_loss: 0.6906 - val_accuracy: 0.4875\n",
            "Epoch 3/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.9388 - accuracy: 0.5721 - val_loss: 0.6565 - val_accuracy: 0.5063\n",
            "Epoch 4/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.8741 - accuracy: 0.5439 - val_loss: 0.6248 - val_accuracy: 0.6062\n",
            "Epoch 5/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.7402 - accuracy: 0.5674 - val_loss: 0.6216 - val_accuracy: 0.6062\n",
            "Epoch 6/200\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.7368 - accuracy: 0.5502 - val_loss: 0.6250 - val_accuracy: 0.5188\n",
            "Epoch 7/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.7493 - accuracy: 0.5282 - val_loss: 0.6309 - val_accuracy: 0.5000\n",
            "Epoch 8/200\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.7523 - accuracy: 0.5470 - val_loss: 0.6215 - val_accuracy: 0.6812\n",
            "Epoch 9/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.7041 - accuracy: 0.6003 - val_loss: 0.6196 - val_accuracy: 0.6250\n",
            "Epoch 10/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.7051 - accuracy: 0.5768 - val_loss: 0.6218 - val_accuracy: 0.6062\n",
            "Epoch 11/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.6786 - accuracy: 0.5705 - val_loss: 0.6387 - val_accuracy: 0.5250\n",
            "Epoch 12/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.6718 - accuracy: 0.5925 - val_loss: 0.6058 - val_accuracy: 0.6812\n",
            "Epoch 13/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.6878 - accuracy: 0.5643 - val_loss: 0.6015 - val_accuracy: 0.7063\n",
            "Epoch 14/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.7189 - accuracy: 0.5282 - val_loss: 0.6021 - val_accuracy: 0.6687\n",
            "Epoch 15/200\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.6944 - accuracy: 0.5596 - val_loss: 0.6017 - val_accuracy: 0.6687\n",
            "Epoch 16/200\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.6658 - accuracy: 0.5564 - val_loss: 0.6107 - val_accuracy: 0.6687\n",
            "Epoch 17/200\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.6789 - accuracy: 0.5752 - val_loss: 0.6132 - val_accuracy: 0.7188\n",
            "Epoch 18/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.6733 - accuracy: 0.5909 - val_loss: 0.6070 - val_accuracy: 0.6687\n",
            "Epoch 19/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.6435 - accuracy: 0.6113 - val_loss: 0.6115 - val_accuracy: 0.6625\n",
            "Epoch 20/200\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.6562 - accuracy: 0.5862 - val_loss: 0.6075 - val_accuracy: 0.6750\n",
            "Epoch 21/200\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.6787 - accuracy: 0.5549 - val_loss: 0.6163 - val_accuracy: 0.6687\n",
            "Epoch 22/200\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.6404 - accuracy: 0.5956 - val_loss: 0.6253 - val_accuracy: 0.5063\n",
            "Epoch 23/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.6755 - accuracy: 0.5580 - val_loss: 0.6188 - val_accuracy: 0.5562\n",
            "Epoch 24/200\n",
            "20/20 [==============================] - 0s 6ms/step - loss: 0.6705 - accuracy: 0.5768 - val_loss: 0.5997 - val_accuracy: 0.6750\n",
            "Epoch 25/200\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.6579 - accuracy: 0.5658 - val_loss: 0.6033 - val_accuracy: 0.7250\n",
            "Epoch 26/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.6586 - accuracy: 0.5690 - val_loss: 0.6056 - val_accuracy: 0.7063\n",
            "Epoch 27/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.6571 - accuracy: 0.5737 - val_loss: 0.6053 - val_accuracy: 0.6750\n",
            "Epoch 28/200\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.6665 - accuracy: 0.5611 - val_loss: 0.6097 - val_accuracy: 0.6750\n",
            "Epoch 29/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.6473 - accuracy: 0.5846 - val_loss: 0.6061 - val_accuracy: 0.6750\n",
            "Epoch 30/200\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.6576 - accuracy: 0.5658 - val_loss: 0.6064 - val_accuracy: 0.6687\n",
            "Epoch 31/200\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.6555 - accuracy: 0.5893 - val_loss: 0.6053 - val_accuracy: 0.6938\n",
            "Epoch 32/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.6576 - accuracy: 0.5627 - val_loss: 0.6166 - val_accuracy: 0.6625\n",
            "Epoch 33/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.6561 - accuracy: 0.5658 - val_loss: 0.6103 - val_accuracy: 0.6938\n",
            "Epoch 34/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.6497 - accuracy: 0.5846 - val_loss: 0.6084 - val_accuracy: 0.6687\n",
            "Epoch 35/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.6462 - accuracy: 0.6019 - val_loss: 0.6073 - val_accuracy: 0.6750\n",
            "Epoch 36/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.6568 - accuracy: 0.5862 - val_loss: 0.6116 - val_accuracy: 0.7063\n",
            "Epoch 37/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.6410 - accuracy: 0.6003 - val_loss: 0.6125 - val_accuracy: 0.7000\n",
            "Epoch 38/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.6514 - accuracy: 0.6050 - val_loss: 0.6093 - val_accuracy: 0.6750\n",
            "Epoch 39/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.6571 - accuracy: 0.6050 - val_loss: 0.6130 - val_accuracy: 0.7063\n",
            "Epoch 40/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.6408 - accuracy: 0.6113 - val_loss: 0.6124 - val_accuracy: 0.7000\n",
            "Epoch 41/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.6483 - accuracy: 0.5940 - val_loss: 0.6093 - val_accuracy: 0.6938\n",
            "Epoch 42/200\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.6524 - accuracy: 0.5784 - val_loss: 0.6061 - val_accuracy: 0.6750\n",
            "Epoch 43/200\n",
            "20/20 [==============================] - 0s 6ms/step - loss: 0.6388 - accuracy: 0.6144 - val_loss: 0.6075 - val_accuracy: 0.6750\n",
            "Epoch 44/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.6325 - accuracy: 0.6364 - val_loss: 0.6083 - val_accuracy: 0.6750\n",
            "Epoch 45/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.6413 - accuracy: 0.5893 - val_loss: 0.6007 - val_accuracy: 0.6812\n",
            "Epoch 46/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.6458 - accuracy: 0.5956 - val_loss: 0.6027 - val_accuracy: 0.6750\n",
            "Epoch 47/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.6459 - accuracy: 0.5815 - val_loss: 0.6010 - val_accuracy: 0.6750\n",
            "Epoch 48/200\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.6382 - accuracy: 0.5893 - val_loss: 0.5968 - val_accuracy: 0.6750\n",
            "Epoch 49/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.6333 - accuracy: 0.5690 - val_loss: 0.5941 - val_accuracy: 0.6750\n",
            "Epoch 50/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.6353 - accuracy: 0.5768 - val_loss: 0.5980 - val_accuracy: 0.6750\n",
            "Epoch 51/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.6345 - accuracy: 0.5784 - val_loss: 0.6067 - val_accuracy: 0.6750\n",
            "Epoch 52/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.6275 - accuracy: 0.6066 - val_loss: 0.6041 - val_accuracy: 0.6812\n",
            "Epoch 53/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.6297 - accuracy: 0.6144 - val_loss: 0.5969 - val_accuracy: 0.6938\n",
            "Epoch 54/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.6333 - accuracy: 0.5940 - val_loss: 0.5888 - val_accuracy: 0.7750\n",
            "Epoch 55/200\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.6221 - accuracy: 0.6003 - val_loss: 0.5796 - val_accuracy: 0.7375\n",
            "Epoch 56/200\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.6156 - accuracy: 0.6473 - val_loss: 0.5574 - val_accuracy: 0.7625\n",
            "Epoch 57/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.6329 - accuracy: 0.6458 - val_loss: 0.5824 - val_accuracy: 0.7688\n",
            "Epoch 58/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.6143 - accuracy: 0.6583 - val_loss: 0.5811 - val_accuracy: 0.7875\n",
            "Epoch 59/200\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.6216 - accuracy: 0.6426 - val_loss: 0.5748 - val_accuracy: 0.7437\n",
            "Epoch 60/200\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.6107 - accuracy: 0.6567 - val_loss: 0.5616 - val_accuracy: 0.7625\n",
            "Epoch 61/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.6074 - accuracy: 0.6473 - val_loss: 0.5351 - val_accuracy: 0.7625\n",
            "Epoch 62/200\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.5989 - accuracy: 0.6693 - val_loss: 0.5554 - val_accuracy: 0.7000\n",
            "Epoch 63/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.6075 - accuracy: 0.6442 - val_loss: 0.5300 - val_accuracy: 0.7937\n",
            "Epoch 64/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.5879 - accuracy: 0.6865 - val_loss: 0.5171 - val_accuracy: 0.7688\n",
            "Epoch 65/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.5994 - accuracy: 0.6818 - val_loss: 0.5341 - val_accuracy: 0.7812\n",
            "Epoch 66/200\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.5932 - accuracy: 0.6928 - val_loss: 0.5238 - val_accuracy: 0.7875\n",
            "Epoch 67/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.5934 - accuracy: 0.6740 - val_loss: 0.5369 - val_accuracy: 0.7875\n",
            "Epoch 68/200\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.5924 - accuracy: 0.6944 - val_loss: 0.5186 - val_accuracy: 0.7750\n",
            "Epoch 69/200\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.5679 - accuracy: 0.7038 - val_loss: 0.5031 - val_accuracy: 0.7875\n",
            "Epoch 70/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.5724 - accuracy: 0.7053 - val_loss: 0.5031 - val_accuracy: 0.7875\n",
            "Epoch 71/200\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.5604 - accuracy: 0.7241 - val_loss: 0.5010 - val_accuracy: 0.7937\n",
            "Epoch 72/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.5605 - accuracy: 0.7194 - val_loss: 0.5107 - val_accuracy: 0.7625\n",
            "Epoch 73/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.5551 - accuracy: 0.7320 - val_loss: 0.4821 - val_accuracy: 0.7750\n",
            "Epoch 74/200\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.5459 - accuracy: 0.7429 - val_loss: 0.4881 - val_accuracy: 0.7937\n",
            "Epoch 75/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.5159 - accuracy: 0.7649 - val_loss: 0.4673 - val_accuracy: 0.7875\n",
            "Epoch 76/200\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.5526 - accuracy: 0.7382 - val_loss: 0.4761 - val_accuracy: 0.8062\n",
            "Epoch 77/200\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.5333 - accuracy: 0.7461 - val_loss: 0.5012 - val_accuracy: 0.7688\n",
            "Epoch 78/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.5343 - accuracy: 0.7524 - val_loss: 0.4998 - val_accuracy: 0.7750\n",
            "Epoch 79/200\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.5204 - accuracy: 0.7508 - val_loss: 0.5131 - val_accuracy: 0.7563\n",
            "Epoch 80/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.5288 - accuracy: 0.7571 - val_loss: 0.4839 - val_accuracy: 0.8062\n",
            "Epoch 81/200\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.5291 - accuracy: 0.7398 - val_loss: 0.4923 - val_accuracy: 0.8062\n",
            "Epoch 82/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.5286 - accuracy: 0.7633 - val_loss: 0.4842 - val_accuracy: 0.7750\n",
            "Epoch 83/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.4955 - accuracy: 0.7774 - val_loss: 0.4603 - val_accuracy: 0.8250\n",
            "Epoch 84/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.4999 - accuracy: 0.7696 - val_loss: 0.4604 - val_accuracy: 0.8062\n",
            "Epoch 85/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.5100 - accuracy: 0.7743 - val_loss: 0.4670 - val_accuracy: 0.7937\n",
            "Epoch 86/200\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.4933 - accuracy: 0.7790 - val_loss: 0.4697 - val_accuracy: 0.7750\n",
            "Epoch 87/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.5044 - accuracy: 0.7571 - val_loss: 0.4707 - val_accuracy: 0.8062\n",
            "Epoch 88/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.4961 - accuracy: 0.7774 - val_loss: 0.4636 - val_accuracy: 0.8188\n",
            "Epoch 89/200\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.4974 - accuracy: 0.7759 - val_loss: 0.4683 - val_accuracy: 0.7750\n",
            "Epoch 90/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.4745 - accuracy: 0.7571 - val_loss: 0.4462 - val_accuracy: 0.8313\n",
            "Epoch 91/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.4649 - accuracy: 0.7821 - val_loss: 0.4351 - val_accuracy: 0.8375\n",
            "Epoch 92/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.4502 - accuracy: 0.8041 - val_loss: 0.4405 - val_accuracy: 0.8188\n",
            "Epoch 93/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.4771 - accuracy: 0.7994 - val_loss: 0.4338 - val_accuracy: 0.8250\n",
            "Epoch 94/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.4674 - accuracy: 0.7962 - val_loss: 0.4433 - val_accuracy: 0.8188\n",
            "Epoch 95/200\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.4754 - accuracy: 0.7962 - val_loss: 0.4395 - val_accuracy: 0.8188\n",
            "Epoch 96/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.4431 - accuracy: 0.7900 - val_loss: 0.4320 - val_accuracy: 0.8188\n",
            "Epoch 97/200\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.4619 - accuracy: 0.8009 - val_loss: 0.4269 - val_accuracy: 0.8313\n",
            "Epoch 98/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.4350 - accuracy: 0.8135 - val_loss: 0.4293 - val_accuracy: 0.8188\n",
            "Epoch 99/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.4269 - accuracy: 0.8197 - val_loss: 0.4133 - val_accuracy: 0.8438\n",
            "Epoch 100/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.4234 - accuracy: 0.8213 - val_loss: 0.3972 - val_accuracy: 0.8438\n",
            "Epoch 101/200\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.4688 - accuracy: 0.7994 - val_loss: 0.4197 - val_accuracy: 0.8313\n",
            "Epoch 102/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.4299 - accuracy: 0.8088 - val_loss: 0.3902 - val_accuracy: 0.8500\n",
            "Epoch 103/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.4350 - accuracy: 0.8119 - val_loss: 0.4288 - val_accuracy: 0.8250\n",
            "Epoch 104/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.4101 - accuracy: 0.8229 - val_loss: 0.3817 - val_accuracy: 0.8500\n",
            "Epoch 105/200\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.4014 - accuracy: 0.8354 - val_loss: 0.4005 - val_accuracy: 0.8375\n",
            "Epoch 106/200\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.4213 - accuracy: 0.8260 - val_loss: 0.3757 - val_accuracy: 0.8500\n",
            "Epoch 107/200\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.4004 - accuracy: 0.8245 - val_loss: 0.3791 - val_accuracy: 0.8562\n",
            "Epoch 108/200\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.4430 - accuracy: 0.8025 - val_loss: 0.3821 - val_accuracy: 0.8562\n",
            "Epoch 109/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.3976 - accuracy: 0.8354 - val_loss: 0.3937 - val_accuracy: 0.8562\n",
            "Epoch 110/200\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.4007 - accuracy: 0.8527 - val_loss: 0.3733 - val_accuracy: 0.8562\n",
            "Epoch 111/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.4260 - accuracy: 0.8041 - val_loss: 0.3989 - val_accuracy: 0.8375\n",
            "Epoch 112/200\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.4133 - accuracy: 0.8292 - val_loss: 0.3853 - val_accuracy: 0.8500\n",
            "Epoch 113/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.4109 - accuracy: 0.8245 - val_loss: 0.3917 - val_accuracy: 0.8375\n",
            "Epoch 114/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.4018 - accuracy: 0.8433 - val_loss: 0.3872 - val_accuracy: 0.8375\n",
            "Epoch 115/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.3804 - accuracy: 0.8433 - val_loss: 0.3806 - val_accuracy: 0.8750\n",
            "Epoch 116/200\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.3864 - accuracy: 0.8589 - val_loss: 0.3866 - val_accuracy: 0.8438\n",
            "Epoch 117/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.4001 - accuracy: 0.8213 - val_loss: 0.4517 - val_accuracy: 0.8062\n",
            "Epoch 118/200\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.3762 - accuracy: 0.8464 - val_loss: 0.3678 - val_accuracy: 0.8687\n",
            "Epoch 119/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.3945 - accuracy: 0.8401 - val_loss: 0.3961 - val_accuracy: 0.8438\n",
            "Epoch 120/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.3918 - accuracy: 0.8213 - val_loss: 0.3709 - val_accuracy: 0.8562\n",
            "Epoch 121/200\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.3929 - accuracy: 0.8260 - val_loss: 0.3580 - val_accuracy: 0.8687\n",
            "Epoch 122/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.3942 - accuracy: 0.8417 - val_loss: 0.3541 - val_accuracy: 0.8625\n",
            "Epoch 123/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.3763 - accuracy: 0.8401 - val_loss: 0.3534 - val_accuracy: 0.8687\n",
            "Epoch 124/200\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.3681 - accuracy: 0.8589 - val_loss: 0.3570 - val_accuracy: 0.8562\n",
            "Epoch 125/200\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.3835 - accuracy: 0.8527 - val_loss: 0.3559 - val_accuracy: 0.8625\n",
            "Epoch 126/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.3574 - accuracy: 0.8448 - val_loss: 0.3527 - val_accuracy: 0.8562\n",
            "Epoch 127/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.3499 - accuracy: 0.8511 - val_loss: 0.3546 - val_accuracy: 0.8562\n",
            "Epoch 128/200\n",
            "20/20 [==============================] - 0s 6ms/step - loss: 0.3626 - accuracy: 0.8464 - val_loss: 0.3551 - val_accuracy: 0.8562\n",
            "Epoch 129/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.3624 - accuracy: 0.8574 - val_loss: 0.3864 - val_accuracy: 0.8500\n",
            "Epoch 130/200\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.3728 - accuracy: 0.8464 - val_loss: 0.3604 - val_accuracy: 0.8750\n",
            "Epoch 131/200\n",
            "20/20 [==============================] - 0s 6ms/step - loss: 0.3568 - accuracy: 0.8480 - val_loss: 0.3734 - val_accuracy: 0.8562\n",
            "Epoch 132/200\n",
            "20/20 [==============================] - 0s 6ms/step - loss: 0.3712 - accuracy: 0.8370 - val_loss: 0.4077 - val_accuracy: 0.8500\n",
            "Epoch 133/200\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.3710 - accuracy: 0.8401 - val_loss: 0.4024 - val_accuracy: 0.8375\n",
            "Epoch 134/200\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.3808 - accuracy: 0.8323 - val_loss: 0.3818 - val_accuracy: 0.8438\n",
            "Epoch 135/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.3394 - accuracy: 0.8464 - val_loss: 0.3615 - val_accuracy: 0.8625\n",
            "Epoch 136/200\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.3594 - accuracy: 0.8495 - val_loss: 0.3541 - val_accuracy: 0.8750\n",
            "Epoch 137/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.3395 - accuracy: 0.8699 - val_loss: 0.3820 - val_accuracy: 0.8438\n",
            "Epoch 138/200\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.3464 - accuracy: 0.8636 - val_loss: 0.3430 - val_accuracy: 0.8625\n",
            "Epoch 139/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.3468 - accuracy: 0.8621 - val_loss: 0.3652 - val_accuracy: 0.8625\n",
            "Epoch 140/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.3286 - accuracy: 0.8542 - val_loss: 0.3808 - val_accuracy: 0.8562\n",
            "Epoch 141/200\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.3320 - accuracy: 0.8699 - val_loss: 0.3617 - val_accuracy: 0.8562\n",
            "Epoch 142/200\n",
            "20/20 [==============================] - 0s 6ms/step - loss: 0.3274 - accuracy: 0.8621 - val_loss: 0.3491 - val_accuracy: 0.8687\n",
            "Epoch 143/200\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.3368 - accuracy: 0.8683 - val_loss: 0.3654 - val_accuracy: 0.8562\n",
            "Epoch 144/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.3570 - accuracy: 0.8480 - val_loss: 0.3582 - val_accuracy: 0.8562\n",
            "Epoch 145/200\n",
            "20/20 [==============================] - 0s 6ms/step - loss: 0.3545 - accuracy: 0.8527 - val_loss: 0.3485 - val_accuracy: 0.8687\n",
            "Epoch 146/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.3271 - accuracy: 0.8683 - val_loss: 0.4188 - val_accuracy: 0.8188\n",
            "Epoch 147/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.3455 - accuracy: 0.8527 - val_loss: 0.4458 - val_accuracy: 0.8062\n",
            "Epoch 148/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.3444 - accuracy: 0.8464 - val_loss: 0.4408 - val_accuracy: 0.7937\n",
            "Epoch 149/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.3519 - accuracy: 0.8605 - val_loss: 0.3850 - val_accuracy: 0.8375\n",
            "Epoch 150/200\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.3408 - accuracy: 0.8574 - val_loss: 0.3537 - val_accuracy: 0.8687\n",
            "Epoch 151/200\n",
            "20/20 [==============================] - 0s 6ms/step - loss: 0.3463 - accuracy: 0.8636 - val_loss: 0.4026 - val_accuracy: 0.8188\n",
            "Epoch 152/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.3292 - accuracy: 0.8589 - val_loss: 0.3543 - val_accuracy: 0.8625\n",
            "Epoch 153/200\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.3253 - accuracy: 0.8730 - val_loss: 0.3991 - val_accuracy: 0.8062\n",
            "Epoch 154/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.3499 - accuracy: 0.8605 - val_loss: 0.3825 - val_accuracy: 0.8313\n",
            "Epoch 155/200\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.3456 - accuracy: 0.8589 - val_loss: 0.3531 - val_accuracy: 0.8687\n",
            "Epoch 156/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.3333 - accuracy: 0.8621 - val_loss: 0.4270 - val_accuracy: 0.7875\n",
            "Epoch 157/200\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.3382 - accuracy: 0.8480 - val_loss: 0.3682 - val_accuracy: 0.8500\n",
            "Epoch 158/200\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.3310 - accuracy: 0.8574 - val_loss: 0.3574 - val_accuracy: 0.8562\n",
            "Epoch 159/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.3210 - accuracy: 0.8668 - val_loss: 0.3682 - val_accuracy: 0.8500\n",
            "Epoch 160/200\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.3271 - accuracy: 0.8699 - val_loss: 0.3845 - val_accuracy: 0.8188\n",
            "Epoch 161/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.3276 - accuracy: 0.8574 - val_loss: 0.3682 - val_accuracy: 0.8500\n",
            "Epoch 162/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.3092 - accuracy: 0.8730 - val_loss: 0.3618 - val_accuracy: 0.8562\n",
            "Epoch 163/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.3384 - accuracy: 0.8715 - val_loss: 0.3479 - val_accuracy: 0.8875\n",
            "Epoch 164/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.3397 - accuracy: 0.8621 - val_loss: 0.3840 - val_accuracy: 0.8375\n",
            "Epoch 165/200\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.3066 - accuracy: 0.8840 - val_loss: 0.4086 - val_accuracy: 0.8250\n",
            "Epoch 166/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.3295 - accuracy: 0.8683 - val_loss: 0.3593 - val_accuracy: 0.8687\n",
            "Epoch 167/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.2946 - accuracy: 0.8793 - val_loss: 0.3752 - val_accuracy: 0.8500\n",
            "Epoch 168/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.3058 - accuracy: 0.8746 - val_loss: 0.4364 - val_accuracy: 0.8062\n",
            "Epoch 169/200\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.3544 - accuracy: 0.8605 - val_loss: 0.3613 - val_accuracy: 0.8500\n",
            "Epoch 170/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.3101 - accuracy: 0.8699 - val_loss: 0.3582 - val_accuracy: 0.8625\n",
            "Epoch 171/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.3243 - accuracy: 0.8652 - val_loss: 0.3642 - val_accuracy: 0.8500\n",
            "Epoch 172/200\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.3178 - accuracy: 0.8652 - val_loss: 0.4073 - val_accuracy: 0.8188\n",
            "Epoch 173/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.3177 - accuracy: 0.8683 - val_loss: 0.3644 - val_accuracy: 0.8438\n",
            "Epoch 174/200\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.3140 - accuracy: 0.8652 - val_loss: 0.3355 - val_accuracy: 0.8750\n",
            "Epoch 175/200\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.3387 - accuracy: 0.8683 - val_loss: 0.3980 - val_accuracy: 0.8188\n",
            "Epoch 176/200\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.3295 - accuracy: 0.8558 - val_loss: 0.3579 - val_accuracy: 0.8625\n",
            "Epoch 177/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.3163 - accuracy: 0.8715 - val_loss: 0.3927 - val_accuracy: 0.8250\n",
            "Epoch 178/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.3249 - accuracy: 0.8542 - val_loss: 0.4060 - val_accuracy: 0.8313\n",
            "Epoch 179/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.3228 - accuracy: 0.8699 - val_loss: 0.3804 - val_accuracy: 0.8250\n",
            "Epoch 180/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.3004 - accuracy: 0.8746 - val_loss: 0.4519 - val_accuracy: 0.7937\n",
            "Epoch 181/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.3309 - accuracy: 0.8636 - val_loss: 0.3715 - val_accuracy: 0.8500\n",
            "Epoch 182/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.3091 - accuracy: 0.8730 - val_loss: 0.3609 - val_accuracy: 0.8562\n",
            "Epoch 183/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.3148 - accuracy: 0.8762 - val_loss: 0.3724 - val_accuracy: 0.8500\n",
            "Epoch 184/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.2924 - accuracy: 0.8809 - val_loss: 0.3517 - val_accuracy: 0.8625\n",
            "Epoch 185/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.3147 - accuracy: 0.8699 - val_loss: 0.3701 - val_accuracy: 0.8562\n",
            "Epoch 186/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.3160 - accuracy: 0.8777 - val_loss: 0.3528 - val_accuracy: 0.8625\n",
            "Epoch 187/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.3138 - accuracy: 0.8636 - val_loss: 0.3520 - val_accuracy: 0.8625\n",
            "Epoch 188/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.2829 - accuracy: 0.8809 - val_loss: 0.3764 - val_accuracy: 0.8500\n",
            "Epoch 189/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.2902 - accuracy: 0.8793 - val_loss: 0.3888 - val_accuracy: 0.8313\n",
            "Epoch 190/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.3164 - accuracy: 0.8777 - val_loss: 0.3680 - val_accuracy: 0.8375\n",
            "Epoch 191/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.2928 - accuracy: 0.8777 - val_loss: 0.3557 - val_accuracy: 0.8500\n",
            "Epoch 192/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.2951 - accuracy: 0.8777 - val_loss: 0.3943 - val_accuracy: 0.8500\n",
            "Epoch 193/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.3001 - accuracy: 0.8746 - val_loss: 0.3543 - val_accuracy: 0.8687\n",
            "Epoch 194/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.3073 - accuracy: 0.8762 - val_loss: 0.3948 - val_accuracy: 0.8438\n",
            "Epoch 195/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.3140 - accuracy: 0.8589 - val_loss: 0.3791 - val_accuracy: 0.8313\n",
            "Epoch 196/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.3269 - accuracy: 0.8652 - val_loss: 0.4376 - val_accuracy: 0.8000\n",
            "Epoch 197/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.2993 - accuracy: 0.8652 - val_loss: 0.3385 - val_accuracy: 0.8750\n",
            "Epoch 198/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.3052 - accuracy: 0.8809 - val_loss: 0.3372 - val_accuracy: 0.8687\n",
            "Epoch 199/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.3052 - accuracy: 0.8762 - val_loss: 0.3773 - val_accuracy: 0.8313\n",
            "Epoch 200/200\n",
            "20/20 [==============================] - 0s 6ms/step - loss: 0.2861 - accuracy: 0.8903 - val_loss: 0.3873 - val_accuracy: 0.8313\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "loss_and_metrics = fullmodel.evaluate(x_test, y_test, batch_size=32)\n",
        "print('## evaluation loss and_metrics ##')\n",
        "print(loss_and_metrics)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dlgTNdK-cPqF",
        "outputId": "5a06a21f-ffa4-4abc-b11e-3a68d385a241"
      },
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "4/4 [==============================] - 0s 4ms/step - loss: 0.3598 - accuracy: 0.8833\n",
            "## evaluation loss and_metrics ##\n",
            "[0.35979679226875305, 0.8833333253860474]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "0oDN-ASADfMa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from matplotlib.projections.polar import rcParams\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "%matplotlib inline\n",
        "sns.set(style='whitegrid',palette='muted',font_scale=1.5)\n",
        "rcParams['figure.figsize']=20,8\n",
        "RANDOM_SEED=42\n",
        "np.random.seed(RANDOM_SEED)\n"
      ],
      "metadata": {
        "id": "6Eqo1PbTstsE"
      },
      "execution_count": 49,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(20, 20))\n",
        "plt.subplot(2,2,1)\n",
        "plt.plot(hin.history[\"loss\"], label=\"loss\")\n",
        "plt.plot(hin.history[\"val_loss\"], label=\"val_loss\")\n",
        "plt.legend()\n",
        "\n",
        "plt.subplot(2,2,2)\n",
        "plt.plot(hin.history[\"accuracy\"], label=\"accuracy\")\n",
        "plt.plot(hin.history[\"val_accuracy\"], label=\"val_accuracy\")\n",
        "plt.legend()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 576
        },
        "id": "U-Gs98zXuBov",
        "outputId": "931d66cd-2353-49b9-9299-6c473c5d2788"
      },
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.legend.Legend at 0x7fdb7c55a750>"
            ]
          },
          "metadata": {},
          "execution_count": 50
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1440x1440 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred = fullmodel.predict(x_test)\n",
        "y_pred"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vIGyvvxF5Ad3",
        "outputId": "44779692-4bc6-4211-d85b-ae1ac7ae8f9c"
      },
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "4/4 [==============================] - 0s 3ms/step\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0.90757024, 0.17491195],\n",
              "       [0.49199307, 0.5230475 ],\n",
              "       [0.37879726, 0.9903109 ],\n",
              "       [0.45796573, 0.9606757 ],\n",
              "       [0.7005149 , 0.3527357 ],\n",
              "       [0.48644784, 0.6489809 ],\n",
              "       [0.5772921 , 0.80926573],\n",
              "       [0.74732834, 0.31783786],\n",
              "       [0.49203348, 0.73275024],\n",
              "       [0.37091643, 0.8505558 ],\n",
              "       [0.47628573, 0.544148  ],\n",
              "       [0.7641216 , 0.30512375],\n",
              "       [0.4226688 , 0.68539387],\n",
              "       [0.7702989 , 0.30025247],\n",
              "       [0.29581332, 0.8649156 ],\n",
              "       [0.68103683, 0.98752606],\n",
              "       [0.85602987, 0.22780001],\n",
              "       [0.6481732 , 0.9364355 ],\n",
              "       [0.49820653, 0.7167111 ],\n",
              "       [0.6093051 , 0.44025415],\n",
              "       [0.46478114, 0.72906315],\n",
              "       [0.3308984 , 0.8394898 ],\n",
              "       [0.87529576, 0.2089753 ],\n",
              "       [0.4756342 , 0.63753533],\n",
              "       [0.31541663, 0.853682  ],\n",
              "       [0.33025607, 0.8301514 ],\n",
              "       [0.85795844, 0.22571506],\n",
              "       [0.42678857, 0.6804442 ],\n",
              "       [0.8971733 , 0.18643486],\n",
              "       [0.94429547, 0.12847514],\n",
              "       [0.48520926, 0.5791926 ],\n",
              "       [0.8744161 , 0.2100209 ],\n",
              "       [0.43374413, 0.6806048 ],\n",
              "       [0.24802026, 0.9279676 ],\n",
              "       [0.19552533, 0.96093345],\n",
              "       [0.6310576 , 0.40134308],\n",
              "       [0.2585725 , 0.91088206],\n",
              "       [0.8589603 , 0.22485256],\n",
              "       [0.3205745 , 0.83960974],\n",
              "       [0.37266776, 0.766973  ],\n",
              "       [0.3587728 , 0.79975015],\n",
              "       [0.3263164 , 0.88561714],\n",
              "       [0.44264042, 0.6234338 ],\n",
              "       [0.73937523, 0.3238273 ],\n",
              "       [0.90099096, 0.18229268],\n",
              "       [0.48385972, 0.6479412 ],\n",
              "       [0.45833296, 0.60557985],\n",
              "       [0.34872895, 0.848935  ],\n",
              "       [0.61988795, 0.99401855],\n",
              "       [0.44496188, 0.62887555],\n",
              "       [0.9488519 , 0.12262974],\n",
              "       [0.95200354, 0.11800278],\n",
              "       [0.30560616, 0.8571193 ],\n",
              "       [0.29154763, 0.9138872 ],\n",
              "       [0.4807001 , 0.6513467 ],\n",
              "       [0.8048849 , 0.27249095],\n",
              "       [0.7741782 , 0.29717028],\n",
              "       [0.4027661 , 0.70925903],\n",
              "       [0.46289295, 0.59629637],\n",
              "       [0.4063836 , 0.7986151 ],\n",
              "       [0.83557117, 0.24640992],\n",
              "       [0.710133  , 0.34531713],\n",
              "       [0.95039433, 0.12026791],\n",
              "       [0.24788445, 0.91601783],\n",
              "       [0.94395405, 0.12948288],\n",
              "       [0.49241808, 0.99773645],\n",
              "       [0.17397146, 0.9672217 ],\n",
              "       [0.34097725, 0.86584914],\n",
              "       [0.24639255, 0.9198387 ],\n",
              "       [0.44748187, 0.6503047 ],\n",
              "       [0.7131681 , 0.3424223 ],\n",
              "       [0.7869222 , 0.28708088],\n",
              "       [0.5505948 , 0.75556177],\n",
              "       [0.48480847, 0.5949781 ],\n",
              "       [0.735796  , 0.32653964],\n",
              "       [0.3691791 , 0.80196667],\n",
              "       [0.5965344 , 0.42553055],\n",
              "       [0.4418091 , 0.6551487 ],\n",
              "       [0.8652847 , 0.21890569],\n",
              "       [0.427376  , 0.6794697 ],\n",
              "       [0.50046176, 0.52266717],\n",
              "       [0.41597763, 0.91353995],\n",
              "       [0.34818876, 0.8040559 ],\n",
              "       [0.83173054, 0.2489424 ],\n",
              "       [0.34726304, 0.80594295],\n",
              "       [0.4216176 , 0.71622527],\n",
              "       [0.8427997 , 0.2397346 ],\n",
              "       [0.27733555, 0.9061467 ],\n",
              "       [0.83208334, 0.24946351],\n",
              "       [0.66580534, 0.93667895],\n",
              "       [0.87240034, 0.21313049],\n",
              "       [0.53484714, 0.98219496],\n",
              "       [0.27295828, 0.8982073 ],\n",
              "       [0.80537266, 0.2719669 ],\n",
              "       [0.47607565, 0.64991057],\n",
              "       [0.87283885, 0.21144782],\n",
              "       [0.645846  , 0.9885507 ],\n",
              "       [0.74952495, 0.31696224],\n",
              "       [0.32580245, 0.87794286],\n",
              "       [0.61351126, 0.9677485 ],\n",
              "       [0.8191877 , 0.26040214],\n",
              "       [0.21820776, 0.94362867],\n",
              "       [0.46795237, 0.5814593 ],\n",
              "       [0.8411851 , 0.24125217],\n",
              "       [0.51106745, 0.50221616],\n",
              "       [0.31098136, 0.85619015],\n",
              "       [0.9797196 , 0.06944643],\n",
              "       [0.6579892 , 0.9732118 ],\n",
              "       [0.29638976, 0.87089103],\n",
              "       [0.5731902 , 0.4416991 ],\n",
              "       [0.47838035, 0.63833576],\n",
              "       [0.3044709 , 0.8604774 ],\n",
              "       [0.8114587 , 0.26704788],\n",
              "       [0.7446247 , 0.31992108],\n",
              "       [0.343484  , 0.80565804],\n",
              "       [0.9108621 , 0.17117056],\n",
              "       [0.6077256 , 0.87617874],\n",
              "       [0.8426388 , 0.23989193],\n",
              "       [0.2820779 , 0.9073032 ],\n",
              "       [0.51820505, 0.48228806]], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 51
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred_class = np.argmax(y_pred, axis=1)\n",
        "y_pred_class"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vjuYbN5P5X1n",
        "outputId": "b8d40af6-6d4a-42d2-e968-21f86233e810"
      },
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 0, 1, 0, 1, 1, 0, 1, 1, 0, 1, 1,\n",
              "       0, 1, 1, 1, 0, 1, 0, 0, 1, 0, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 0,\n",
              "       0, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 0, 0, 1, 1, 1, 0, 0, 0, 1, 0, 1,\n",
              "       1, 1, 1, 1, 0, 0, 1, 1, 0, 1, 0, 1, 0, 1, 1, 1, 1, 0, 1, 1, 0, 1,\n",
              "       0, 1, 0, 1, 1, 0, 1, 0, 1, 0, 1, 1, 0, 1, 1, 0, 0, 1, 0, 1, 1, 0,\n",
              "       1, 1, 0, 0, 1, 0, 1, 0, 1, 0])"
            ]
          },
          "metadata": {},
          "execution_count": 52
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd"
      ],
      "metadata": {
        "id": "f8qVaxk5MI_8"
      },
      "execution_count": 53,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_test  = y_test.to_numpy()\n",
        "y_test"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VmcisssuNsh0",
        "outputId": "44a5635b-6bd7-4129-bf55-859cd42f9949"
      },
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[1, 0],\n",
              "       [0, 1],\n",
              "       [0, 1],\n",
              "       [0, 1],\n",
              "       [1, 0],\n",
              "       [0, 1],\n",
              "       [0, 1],\n",
              "       [1, 0],\n",
              "       [0, 1],\n",
              "       [0, 1],\n",
              "       [1, 0],\n",
              "       [1, 0],\n",
              "       [1, 0],\n",
              "       [1, 0],\n",
              "       [0, 1],\n",
              "       [0, 1],\n",
              "       [1, 0],\n",
              "       [0, 1],\n",
              "       [0, 1],\n",
              "       [1, 0],\n",
              "       [0, 1],\n",
              "       [1, 0],\n",
              "       [1, 0],\n",
              "       [1, 0],\n",
              "       [0, 1],\n",
              "       [0, 1],\n",
              "       [1, 0],\n",
              "       [0, 1],\n",
              "       [1, 0],\n",
              "       [1, 0],\n",
              "       [0, 1],\n",
              "       [0, 1],\n",
              "       [1, 0],\n",
              "       [0, 1],\n",
              "       [0, 1],\n",
              "       [1, 0],\n",
              "       [0, 1],\n",
              "       [1, 0],\n",
              "       [0, 1],\n",
              "       [0, 1],\n",
              "       [0, 1],\n",
              "       [0, 1],\n",
              "       [0, 1],\n",
              "       [1, 0],\n",
              "       [1, 0],\n",
              "       [1, 0],\n",
              "       [0, 1],\n",
              "       [0, 1],\n",
              "       [0, 1],\n",
              "       [1, 0],\n",
              "       [0, 1],\n",
              "       [1, 0],\n",
              "       [0, 1],\n",
              "       [0, 1],\n",
              "       [0, 1],\n",
              "       [1, 0],\n",
              "       [1, 0],\n",
              "       [0, 1],\n",
              "       [0, 1],\n",
              "       [0, 1],\n",
              "       [1, 0],\n",
              "       [1, 0],\n",
              "       [1, 0],\n",
              "       [0, 1],\n",
              "       [1, 0],\n",
              "       [0, 1],\n",
              "       [0, 1],\n",
              "       [0, 1],\n",
              "       [0, 1],\n",
              "       [0, 1],\n",
              "       [1, 0],\n",
              "       [1, 0],\n",
              "       [0, 1],\n",
              "       [0, 1],\n",
              "       [1, 0],\n",
              "       [0, 1],\n",
              "       [1, 0],\n",
              "       [0, 1],\n",
              "       [1, 0],\n",
              "       [0, 1],\n",
              "       [0, 1],\n",
              "       [0, 1],\n",
              "       [0, 1],\n",
              "       [1, 0],\n",
              "       [0, 1],\n",
              "       [0, 1],\n",
              "       [1, 0],\n",
              "       [0, 1],\n",
              "       [1, 0],\n",
              "       [1, 0],\n",
              "       [0, 1],\n",
              "       [0, 1],\n",
              "       [0, 1],\n",
              "       [1, 0],\n",
              "       [1, 0],\n",
              "       [1, 0],\n",
              "       [0, 1],\n",
              "       [1, 0],\n",
              "       [0, 1],\n",
              "       [0, 1],\n",
              "       [1, 0],\n",
              "       [0, 1],\n",
              "       [0, 1],\n",
              "       [1, 0],\n",
              "       [0, 1],\n",
              "       [0, 1],\n",
              "       [1, 0],\n",
              "       [0, 1],\n",
              "       [0, 1],\n",
              "       [1, 0],\n",
              "       [0, 1],\n",
              "       [0, 1],\n",
              "       [1, 0],\n",
              "       [0, 1],\n",
              "       [0, 1],\n",
              "       [1, 0],\n",
              "       [0, 1],\n",
              "       [1, 0],\n",
              "       [0, 1],\n",
              "       [1, 0]], dtype=uint8)"
            ]
          },
          "metadata": {},
          "execution_count": 54
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_test = np.argmax(y_test,axis=1)\n",
        "y_test"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "g2IIs1UmN18s",
        "outputId": "e6a3c645-9e46-41ba-d34d-5c6af4d25ef6"
      },
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0, 1, 1, 1, 0, 1, 1, 0, 1, 1, 0, 0, 0, 0, 1, 1, 0, 1, 1, 0, 1, 0,\n",
              "       0, 0, 1, 1, 0, 1, 0, 0, 1, 1, 0, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 0,\n",
              "       0, 0, 1, 1, 1, 0, 1, 0, 1, 1, 1, 0, 0, 1, 1, 1, 0, 0, 0, 1, 0, 1,\n",
              "       1, 1, 1, 1, 0, 0, 1, 1, 0, 1, 0, 1, 0, 1, 1, 1, 1, 0, 1, 1, 0, 1,\n",
              "       0, 0, 1, 1, 1, 0, 0, 0, 1, 0, 1, 1, 0, 1, 1, 0, 1, 1, 0, 1, 1, 0,\n",
              "       1, 1, 0, 1, 1, 0, 1, 0, 1, 0])"
            ]
          },
          "metadata": {},
          "execution_count": 55
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import accuracy_score, recall_score, precision_score, f1_score\n",
        "\n",
        "np.mean(y_test == y_pred_class)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6kklgU4I5x5g",
        "outputId": "9aff0d25-f7ca-4141-ed48-ecd214700b17"
      },
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.8833333333333333"
            ]
          },
          "metadata": {},
          "execution_count": 56
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "fullscore=recall_score(y_test,y_pred_class)\n",
        "print(fullscore)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "o0tLNUJJEREZ",
        "outputId": "e5b61a02-ee14-4c42-a42c-5b30040e6b2a"
      },
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.9285714285714286\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "> ModelExceptAge\n",
        "\n"
      ],
      "metadata": {
        "id": "hSMjA9YG9H9-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "import keras\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Dropout, Activation\n",
        "\n",
        "heart['Age'] = 0\n",
        "\n",
        "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size = 0.13,shuffle=True, random_state = 42)\n",
        "\n",
        "print(\"X_train: \", x_train.shape)\n",
        "print(\"y_train: \", y_train.shape)\n",
        "\n",
        "print(\"X_test: \", x_test.shape)\n",
        "print(\"y_test: \", y_test.shape)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "ModelExceptAge = Sequential()\n",
        "\n",
        "\n",
        "ModelExceptAge.add(Dense(128, activation = \"relu\",input_dim=20))\n",
        "ModelExceptAge.add(Dropout(rate=0.2))\n",
        "ModelExceptAge.add(Dense(64, activation = \"relu\"))\n",
        "ModelExceptAge.add(Dropout(rate=0.2))\n",
        "ModelExceptAge.add(Dense(32, activation = \"relu\"))\n",
        "ModelExceptAge.add(Dropout(rate=0.1))\n",
        "ModelExceptAge.add(Dense(16, activation = \"relu\"))\n",
        "ModelExceptAge.add(Dense(8, activation = \"relu\"))\n",
        "ModelExceptAge.add(Dense(2, activation = \"sigmoid\"))\n",
        "\n",
        "ModelExceptAge.compile(optimizer = \"adam\", loss = \"categorical_crossentropy\", metrics = [\"accuracy\"])\n",
        "ModelExceptAge.summary()\n",
        "\n",
        "hin=ModelExceptAge.fit(x_train,y_train,epochs=200, validation_split=0.2)\n",
        "\n",
        "loss_and_metrics = ModelExceptAge.evaluate(x_test, y_test, batch_size=32)\n",
        "print('## evaluation loss and_metrics ##')\n",
        "print(loss_and_metrics)\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BJInXD_B3MC4",
        "outputId": "bcf77251-f114-4701-96e5-9e1a92f376f6"
      },
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "X_train:  (798, 20)\n",
            "y_train:  (798, 2)\n",
            "X_test:  (120, 20)\n",
            "y_test:  (120, 2)\n",
            "Model: \"sequential_4\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense_24 (Dense)            (None, 128)               2688      \n",
            "                                                                 \n",
            " dropout_12 (Dropout)        (None, 128)               0         \n",
            "                                                                 \n",
            " dense_25 (Dense)            (None, 64)                8256      \n",
            "                                                                 \n",
            " dropout_13 (Dropout)        (None, 64)                0         \n",
            "                                                                 \n",
            " dense_26 (Dense)            (None, 32)                2080      \n",
            "                                                                 \n",
            " dropout_14 (Dropout)        (None, 32)                0         \n",
            "                                                                 \n",
            " dense_27 (Dense)            (None, 16)                528       \n",
            "                                                                 \n",
            " dense_28 (Dense)            (None, 8)                 136       \n",
            "                                                                 \n",
            " dense_29 (Dense)            (None, 2)                 18        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 13,706\n",
            "Trainable params: 13,706\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/200\n",
            "20/20 [==============================] - 1s 13ms/step - loss: 1.4578 - accuracy: 0.5157 - val_loss: 0.7364 - val_accuracy: 0.4750\n",
            "Epoch 2/200\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.8607 - accuracy: 0.5408 - val_loss: 0.6811 - val_accuracy: 0.6062\n",
            "Epoch 3/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.6933 - accuracy: 0.5517 - val_loss: 0.6640 - val_accuracy: 0.4938\n",
            "Epoch 4/200\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.7326 - accuracy: 0.5408 - val_loss: 0.7079 - val_accuracy: 0.3688\n",
            "Epoch 5/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.7071 - accuracy: 0.5423 - val_loss: 0.6945 - val_accuracy: 0.4750\n",
            "Epoch 6/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.7276 - accuracy: 0.5439 - val_loss: 0.6910 - val_accuracy: 0.4938\n",
            "Epoch 7/200\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.6840 - accuracy: 0.5878 - val_loss: 0.6716 - val_accuracy: 0.5125\n",
            "Epoch 8/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.6870 - accuracy: 0.5737 - val_loss: 0.6572 - val_accuracy: 0.5688\n",
            "Epoch 9/200\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.6782 - accuracy: 0.5909 - val_loss: 0.6468 - val_accuracy: 0.6000\n",
            "Epoch 10/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.6778 - accuracy: 0.5987 - val_loss: 0.6236 - val_accuracy: 0.7500\n",
            "Epoch 11/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.6693 - accuracy: 0.5752 - val_loss: 0.6376 - val_accuracy: 0.4875\n",
            "Epoch 12/200\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.6457 - accuracy: 0.6050 - val_loss: 0.6018 - val_accuracy: 0.7563\n",
            "Epoch 13/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.6651 - accuracy: 0.5815 - val_loss: 0.6059 - val_accuracy: 0.7437\n",
            "Epoch 14/200\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.6583 - accuracy: 0.6364 - val_loss: 0.6070 - val_accuracy: 0.7437\n",
            "Epoch 15/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.6340 - accuracy: 0.6348 - val_loss: 0.5887 - val_accuracy: 0.7625\n",
            "Epoch 16/200\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.6668 - accuracy: 0.6160 - val_loss: 0.5831 - val_accuracy: 0.7375\n",
            "Epoch 17/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.6221 - accuracy: 0.6285 - val_loss: 0.5932 - val_accuracy: 0.6875\n",
            "Epoch 18/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.6349 - accuracy: 0.6364 - val_loss: 0.5623 - val_accuracy: 0.7563\n",
            "Epoch 19/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.6043 - accuracy: 0.6724 - val_loss: 0.5705 - val_accuracy: 0.7312\n",
            "Epoch 20/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.6132 - accuracy: 0.6834 - val_loss: 0.5430 - val_accuracy: 0.7250\n",
            "Epoch 21/200\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.6019 - accuracy: 0.6661 - val_loss: 0.5471 - val_accuracy: 0.7500\n",
            "Epoch 22/200\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.6109 - accuracy: 0.6771 - val_loss: 0.5306 - val_accuracy: 0.7375\n",
            "Epoch 23/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.5942 - accuracy: 0.6928 - val_loss: 0.5195 - val_accuracy: 0.7875\n",
            "Epoch 24/200\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.5976 - accuracy: 0.6850 - val_loss: 0.5853 - val_accuracy: 0.6562\n",
            "Epoch 25/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.5740 - accuracy: 0.7053 - val_loss: 0.5374 - val_accuracy: 0.7437\n",
            "Epoch 26/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.5949 - accuracy: 0.7038 - val_loss: 0.5028 - val_accuracy: 0.7688\n",
            "Epoch 27/200\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.5903 - accuracy: 0.6991 - val_loss: 0.5620 - val_accuracy: 0.6938\n",
            "Epoch 28/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.5799 - accuracy: 0.7085 - val_loss: 0.5047 - val_accuracy: 0.7688\n",
            "Epoch 29/200\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.5812 - accuracy: 0.6991 - val_loss: 0.5023 - val_accuracy: 0.7688\n",
            "Epoch 30/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.5554 - accuracy: 0.7226 - val_loss: 0.5063 - val_accuracy: 0.7500\n",
            "Epoch 31/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.5685 - accuracy: 0.7304 - val_loss: 0.5200 - val_accuracy: 0.7500\n",
            "Epoch 32/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.5551 - accuracy: 0.7461 - val_loss: 0.5291 - val_accuracy: 0.7500\n",
            "Epoch 33/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.5574 - accuracy: 0.7163 - val_loss: 0.5071 - val_accuracy: 0.7812\n",
            "Epoch 34/200\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.5466 - accuracy: 0.7492 - val_loss: 0.5396 - val_accuracy: 0.7437\n",
            "Epoch 35/200\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.5512 - accuracy: 0.7461 - val_loss: 0.4979 - val_accuracy: 0.7875\n",
            "Epoch 36/200\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.5330 - accuracy: 0.7461 - val_loss: 0.5017 - val_accuracy: 0.7625\n",
            "Epoch 37/200\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.5356 - accuracy: 0.7429 - val_loss: 0.5083 - val_accuracy: 0.7563\n",
            "Epoch 38/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.5405 - accuracy: 0.7476 - val_loss: 0.5052 - val_accuracy: 0.7563\n",
            "Epoch 39/200\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.5097 - accuracy: 0.7821 - val_loss: 0.4730 - val_accuracy: 0.7937\n",
            "Epoch 40/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.5229 - accuracy: 0.7602 - val_loss: 0.4840 - val_accuracy: 0.7812\n",
            "Epoch 41/200\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.5185 - accuracy: 0.7633 - val_loss: 0.4823 - val_accuracy: 0.7812\n",
            "Epoch 42/200\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.5186 - accuracy: 0.7696 - val_loss: 0.5047 - val_accuracy: 0.7563\n",
            "Epoch 43/200\n",
            "20/20 [==============================] - 0s 6ms/step - loss: 0.5226 - accuracy: 0.7633 - val_loss: 0.4988 - val_accuracy: 0.7625\n",
            "Epoch 44/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.4903 - accuracy: 0.7806 - val_loss: 0.5086 - val_accuracy: 0.7625\n",
            "Epoch 45/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.4913 - accuracy: 0.7806 - val_loss: 0.5070 - val_accuracy: 0.7625\n",
            "Epoch 46/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.4954 - accuracy: 0.7602 - val_loss: 0.4695 - val_accuracy: 0.7875\n",
            "Epoch 47/200\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.4737 - accuracy: 0.7853 - val_loss: 0.4897 - val_accuracy: 0.7750\n",
            "Epoch 48/200\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.4761 - accuracy: 0.7900 - val_loss: 0.5062 - val_accuracy: 0.7688\n",
            "Epoch 49/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.4849 - accuracy: 0.7931 - val_loss: 0.4529 - val_accuracy: 0.8125\n",
            "Epoch 50/200\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.4718 - accuracy: 0.7853 - val_loss: 0.4392 - val_accuracy: 0.8375\n",
            "Epoch 51/200\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.4752 - accuracy: 0.7853 - val_loss: 0.4471 - val_accuracy: 0.8375\n",
            "Epoch 52/200\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.4744 - accuracy: 0.8009 - val_loss: 0.4606 - val_accuracy: 0.8062\n",
            "Epoch 53/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.4478 - accuracy: 0.8150 - val_loss: 0.4205 - val_accuracy: 0.8125\n",
            "Epoch 54/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.4688 - accuracy: 0.8166 - val_loss: 0.4676 - val_accuracy: 0.7875\n",
            "Epoch 55/200\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.4730 - accuracy: 0.7868 - val_loss: 0.4665 - val_accuracy: 0.7875\n",
            "Epoch 56/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.4530 - accuracy: 0.8041 - val_loss: 0.4370 - val_accuracy: 0.8125\n",
            "Epoch 57/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.4417 - accuracy: 0.8229 - val_loss: 0.4468 - val_accuracy: 0.8062\n",
            "Epoch 58/200\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.4289 - accuracy: 0.8292 - val_loss: 0.5428 - val_accuracy: 0.7563\n",
            "Epoch 59/200\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.4431 - accuracy: 0.8119 - val_loss: 0.4750 - val_accuracy: 0.7937\n",
            "Epoch 60/200\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.4368 - accuracy: 0.8088 - val_loss: 0.4202 - val_accuracy: 0.8250\n",
            "Epoch 61/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.4270 - accuracy: 0.8307 - val_loss: 0.4111 - val_accuracy: 0.8250\n",
            "Epoch 62/200\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.4388 - accuracy: 0.8088 - val_loss: 0.4377 - val_accuracy: 0.8313\n",
            "Epoch 63/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.4284 - accuracy: 0.8213 - val_loss: 0.4548 - val_accuracy: 0.8188\n",
            "Epoch 64/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.4048 - accuracy: 0.8276 - val_loss: 0.3752 - val_accuracy: 0.8500\n",
            "Epoch 65/200\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.3936 - accuracy: 0.8323 - val_loss: 0.3731 - val_accuracy: 0.8562\n",
            "Epoch 66/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.4138 - accuracy: 0.8213 - val_loss: 0.3809 - val_accuracy: 0.8562\n",
            "Epoch 67/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.3919 - accuracy: 0.8448 - val_loss: 0.3922 - val_accuracy: 0.8438\n",
            "Epoch 68/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.3900 - accuracy: 0.8527 - val_loss: 0.3707 - val_accuracy: 0.8562\n",
            "Epoch 69/200\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.3863 - accuracy: 0.8464 - val_loss: 0.3656 - val_accuracy: 0.8687\n",
            "Epoch 70/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.3989 - accuracy: 0.8448 - val_loss: 0.3896 - val_accuracy: 0.8438\n",
            "Epoch 71/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.3740 - accuracy: 0.8354 - val_loss: 0.4408 - val_accuracy: 0.8250\n",
            "Epoch 72/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.3870 - accuracy: 0.8527 - val_loss: 0.3846 - val_accuracy: 0.8562\n",
            "Epoch 73/200\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.3800 - accuracy: 0.8401 - val_loss: 0.3977 - val_accuracy: 0.8562\n",
            "Epoch 74/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.3850 - accuracy: 0.8448 - val_loss: 0.3956 - val_accuracy: 0.8500\n",
            "Epoch 75/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.3745 - accuracy: 0.8511 - val_loss: 0.3483 - val_accuracy: 0.8625\n",
            "Epoch 76/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.3736 - accuracy: 0.8448 - val_loss: 0.3935 - val_accuracy: 0.8562\n",
            "Epoch 77/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.3619 - accuracy: 0.8605 - val_loss: 0.3875 - val_accuracy: 0.8500\n",
            "Epoch 78/200\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.3395 - accuracy: 0.8558 - val_loss: 0.3642 - val_accuracy: 0.8687\n",
            "Epoch 79/200\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.3542 - accuracy: 0.8495 - val_loss: 0.3780 - val_accuracy: 0.8500\n",
            "Epoch 80/200\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.3685 - accuracy: 0.8511 - val_loss: 0.3750 - val_accuracy: 0.8687\n",
            "Epoch 81/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.3625 - accuracy: 0.8605 - val_loss: 0.4207 - val_accuracy: 0.8125\n",
            "Epoch 82/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.3593 - accuracy: 0.8574 - val_loss: 0.3720 - val_accuracy: 0.8562\n",
            "Epoch 83/200\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.3492 - accuracy: 0.8589 - val_loss: 0.3700 - val_accuracy: 0.8562\n",
            "Epoch 84/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.3519 - accuracy: 0.8574 - val_loss: 0.3722 - val_accuracy: 0.8562\n",
            "Epoch 85/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.3604 - accuracy: 0.8480 - val_loss: 0.3397 - val_accuracy: 0.8750\n",
            "Epoch 86/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.3555 - accuracy: 0.8589 - val_loss: 0.3516 - val_accuracy: 0.8625\n",
            "Epoch 87/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.3519 - accuracy: 0.8621 - val_loss: 0.3629 - val_accuracy: 0.8687\n",
            "Epoch 88/200\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.3431 - accuracy: 0.8574 - val_loss: 0.3934 - val_accuracy: 0.8313\n",
            "Epoch 89/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.3422 - accuracy: 0.8574 - val_loss: 0.4128 - val_accuracy: 0.8313\n",
            "Epoch 90/200\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.3229 - accuracy: 0.8809 - val_loss: 0.3792 - val_accuracy: 0.8562\n",
            "Epoch 91/200\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.3267 - accuracy: 0.8668 - val_loss: 0.4032 - val_accuracy: 0.8250\n",
            "Epoch 92/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.3397 - accuracy: 0.8683 - val_loss: 0.4048 - val_accuracy: 0.8250\n",
            "Epoch 93/200\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.3386 - accuracy: 0.8683 - val_loss: 0.4445 - val_accuracy: 0.8062\n",
            "Epoch 94/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.3494 - accuracy: 0.8574 - val_loss: 0.3731 - val_accuracy: 0.8562\n",
            "Epoch 95/200\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.3208 - accuracy: 0.8730 - val_loss: 0.3820 - val_accuracy: 0.8562\n",
            "Epoch 96/200\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.3479 - accuracy: 0.8621 - val_loss: 0.3560 - val_accuracy: 0.8562\n",
            "Epoch 97/200\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.3190 - accuracy: 0.8746 - val_loss: 0.3586 - val_accuracy: 0.8562\n",
            "Epoch 98/200\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.3360 - accuracy: 0.8793 - val_loss: 0.4037 - val_accuracy: 0.8375\n",
            "Epoch 99/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.3181 - accuracy: 0.8683 - val_loss: 0.4713 - val_accuracy: 0.7875\n",
            "Epoch 100/200\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.3467 - accuracy: 0.8730 - val_loss: 0.4059 - val_accuracy: 0.8375\n",
            "Epoch 101/200\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.3261 - accuracy: 0.8621 - val_loss: 0.3498 - val_accuracy: 0.8813\n",
            "Epoch 102/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.3366 - accuracy: 0.8683 - val_loss: 0.3868 - val_accuracy: 0.8500\n",
            "Epoch 103/200\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.3262 - accuracy: 0.8777 - val_loss: 0.3514 - val_accuracy: 0.8562\n",
            "Epoch 104/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.3389 - accuracy: 0.8542 - val_loss: 0.3656 - val_accuracy: 0.8687\n",
            "Epoch 105/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.3241 - accuracy: 0.8683 - val_loss: 0.3703 - val_accuracy: 0.8562\n",
            "Epoch 106/200\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.3429 - accuracy: 0.8589 - val_loss: 0.3529 - val_accuracy: 0.8625\n",
            "Epoch 107/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.3322 - accuracy: 0.8777 - val_loss: 0.3546 - val_accuracy: 0.8562\n",
            "Epoch 108/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.3234 - accuracy: 0.8699 - val_loss: 0.3542 - val_accuracy: 0.8813\n",
            "Epoch 109/200\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.3421 - accuracy: 0.8589 - val_loss: 0.3571 - val_accuracy: 0.8687\n",
            "Epoch 110/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.3461 - accuracy: 0.8605 - val_loss: 0.3919 - val_accuracy: 0.8562\n",
            "Epoch 111/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.3189 - accuracy: 0.8762 - val_loss: 0.3589 - val_accuracy: 0.8687\n",
            "Epoch 112/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.3148 - accuracy: 0.8746 - val_loss: 0.3654 - val_accuracy: 0.8562\n",
            "Epoch 113/200\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.3087 - accuracy: 0.8730 - val_loss: 0.3647 - val_accuracy: 0.8625\n",
            "Epoch 114/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.3207 - accuracy: 0.8809 - val_loss: 0.4477 - val_accuracy: 0.8000\n",
            "Epoch 115/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.3333 - accuracy: 0.8730 - val_loss: 0.4073 - val_accuracy: 0.8375\n",
            "Epoch 116/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.2973 - accuracy: 0.8824 - val_loss: 0.3617 - val_accuracy: 0.8750\n",
            "Epoch 117/200\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.3297 - accuracy: 0.8699 - val_loss: 0.3757 - val_accuracy: 0.8625\n",
            "Epoch 118/200\n",
            "20/20 [==============================] - 0s 6ms/step - loss: 0.2975 - accuracy: 0.8840 - val_loss: 0.3947 - val_accuracy: 0.8562\n",
            "Epoch 119/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.3146 - accuracy: 0.8777 - val_loss: 0.3862 - val_accuracy: 0.8500\n",
            "Epoch 120/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.3045 - accuracy: 0.8793 - val_loss: 0.3805 - val_accuracy: 0.8500\n",
            "Epoch 121/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.3178 - accuracy: 0.8730 - val_loss: 0.3680 - val_accuracy: 0.8625\n",
            "Epoch 122/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.3123 - accuracy: 0.8730 - val_loss: 0.3608 - val_accuracy: 0.8687\n",
            "Epoch 123/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.3127 - accuracy: 0.8715 - val_loss: 0.3722 - val_accuracy: 0.8625\n",
            "Epoch 124/200\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.3080 - accuracy: 0.8762 - val_loss: 0.4228 - val_accuracy: 0.8313\n",
            "Epoch 125/200\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.3047 - accuracy: 0.8793 - val_loss: 0.3659 - val_accuracy: 0.8813\n",
            "Epoch 126/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.3217 - accuracy: 0.8542 - val_loss: 0.3583 - val_accuracy: 0.8813\n",
            "Epoch 127/200\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.3075 - accuracy: 0.8824 - val_loss: 0.3768 - val_accuracy: 0.8562\n",
            "Epoch 128/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.3175 - accuracy: 0.8683 - val_loss: 0.3719 - val_accuracy: 0.8625\n",
            "Epoch 129/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.3096 - accuracy: 0.8840 - val_loss: 0.3970 - val_accuracy: 0.8562\n",
            "Epoch 130/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.3129 - accuracy: 0.8918 - val_loss: 0.3800 - val_accuracy: 0.8375\n",
            "Epoch 131/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.2960 - accuracy: 0.8762 - val_loss: 0.3989 - val_accuracy: 0.8125\n",
            "Epoch 132/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.3302 - accuracy: 0.8668 - val_loss: 0.3999 - val_accuracy: 0.8375\n",
            "Epoch 133/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.3130 - accuracy: 0.8715 - val_loss: 0.3900 - val_accuracy: 0.8500\n",
            "Epoch 134/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.2948 - accuracy: 0.8793 - val_loss: 0.4072 - val_accuracy: 0.8250\n",
            "Epoch 135/200\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.3100 - accuracy: 0.8699 - val_loss: 0.3526 - val_accuracy: 0.8687\n",
            "Epoch 136/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.3152 - accuracy: 0.8777 - val_loss: 0.3914 - val_accuracy: 0.8500\n",
            "Epoch 137/200\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.2957 - accuracy: 0.8762 - val_loss: 0.3781 - val_accuracy: 0.8500\n",
            "Epoch 138/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.3061 - accuracy: 0.8683 - val_loss: 0.4205 - val_accuracy: 0.8375\n",
            "Epoch 139/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.3137 - accuracy: 0.8715 - val_loss: 0.3684 - val_accuracy: 0.8687\n",
            "Epoch 140/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.3027 - accuracy: 0.8715 - val_loss: 0.3870 - val_accuracy: 0.8562\n",
            "Epoch 141/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.3014 - accuracy: 0.8824 - val_loss: 0.3809 - val_accuracy: 0.8313\n",
            "Epoch 142/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.3107 - accuracy: 0.8840 - val_loss: 0.3896 - val_accuracy: 0.8313\n",
            "Epoch 143/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.3122 - accuracy: 0.8730 - val_loss: 0.3690 - val_accuracy: 0.8687\n",
            "Epoch 144/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.3089 - accuracy: 0.8730 - val_loss: 0.3740 - val_accuracy: 0.8687\n",
            "Epoch 145/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.3027 - accuracy: 0.8777 - val_loss: 0.3810 - val_accuracy: 0.8687\n",
            "Epoch 146/200\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.3080 - accuracy: 0.8699 - val_loss: 0.3789 - val_accuracy: 0.8438\n",
            "Epoch 147/200\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.2811 - accuracy: 0.8856 - val_loss: 0.4197 - val_accuracy: 0.8250\n",
            "Epoch 148/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.3042 - accuracy: 0.8824 - val_loss: 0.3710 - val_accuracy: 0.8687\n",
            "Epoch 149/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.2902 - accuracy: 0.8824 - val_loss: 0.3691 - val_accuracy: 0.8562\n",
            "Epoch 150/200\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.2932 - accuracy: 0.8903 - val_loss: 0.3938 - val_accuracy: 0.8687\n",
            "Epoch 151/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.2882 - accuracy: 0.8824 - val_loss: 0.4392 - val_accuracy: 0.8125\n",
            "Epoch 152/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.2895 - accuracy: 0.8856 - val_loss: 0.3891 - val_accuracy: 0.8500\n",
            "Epoch 153/200\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.2956 - accuracy: 0.8777 - val_loss: 0.3637 - val_accuracy: 0.8625\n",
            "Epoch 154/200\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.3023 - accuracy: 0.8809 - val_loss: 0.3634 - val_accuracy: 0.8687\n",
            "Epoch 155/200\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.2988 - accuracy: 0.8824 - val_loss: 0.4090 - val_accuracy: 0.8375\n",
            "Epoch 156/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.2989 - accuracy: 0.8730 - val_loss: 0.3706 - val_accuracy: 0.8625\n",
            "Epoch 157/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.2949 - accuracy: 0.8824 - val_loss: 0.3796 - val_accuracy: 0.8625\n",
            "Epoch 158/200\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.3043 - accuracy: 0.8715 - val_loss: 0.3646 - val_accuracy: 0.8687\n",
            "Epoch 159/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.3032 - accuracy: 0.8777 - val_loss: 0.3543 - val_accuracy: 0.8750\n",
            "Epoch 160/200\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.2888 - accuracy: 0.8887 - val_loss: 0.3509 - val_accuracy: 0.8750\n",
            "Epoch 161/200\n",
            "20/20 [==============================] - 0s 6ms/step - loss: 0.2980 - accuracy: 0.8871 - val_loss: 0.3775 - val_accuracy: 0.8500\n",
            "Epoch 162/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.2980 - accuracy: 0.8824 - val_loss: 0.4239 - val_accuracy: 0.7937\n",
            "Epoch 163/200\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.2866 - accuracy: 0.8762 - val_loss: 0.4630 - val_accuracy: 0.8000\n",
            "Epoch 164/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.3127 - accuracy: 0.8668 - val_loss: 0.3697 - val_accuracy: 0.8625\n",
            "Epoch 165/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.2955 - accuracy: 0.8903 - val_loss: 0.3988 - val_accuracy: 0.8500\n",
            "Epoch 166/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.2882 - accuracy: 0.8918 - val_loss: 0.4025 - val_accuracy: 0.8250\n",
            "Epoch 167/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.3034 - accuracy: 0.8730 - val_loss: 0.3647 - val_accuracy: 0.8687\n",
            "Epoch 168/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.3018 - accuracy: 0.8809 - val_loss: 0.3613 - val_accuracy: 0.8625\n",
            "Epoch 169/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.2839 - accuracy: 0.8762 - val_loss: 0.3804 - val_accuracy: 0.8438\n",
            "Epoch 170/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.2939 - accuracy: 0.8809 - val_loss: 0.3549 - val_accuracy: 0.8813\n",
            "Epoch 171/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.2867 - accuracy: 0.8856 - val_loss: 0.3710 - val_accuracy: 0.8562\n",
            "Epoch 172/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.3002 - accuracy: 0.8809 - val_loss: 0.4279 - val_accuracy: 0.8313\n",
            "Epoch 173/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.2816 - accuracy: 0.8871 - val_loss: 0.4230 - val_accuracy: 0.8375\n",
            "Epoch 174/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.2792 - accuracy: 0.8824 - val_loss: 0.3863 - val_accuracy: 0.8438\n",
            "Epoch 175/200\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.2675 - accuracy: 0.8856 - val_loss: 0.3910 - val_accuracy: 0.8750\n",
            "Epoch 176/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.3000 - accuracy: 0.8856 - val_loss: 0.3470 - val_accuracy: 0.8750\n",
            "Epoch 177/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.2882 - accuracy: 0.8762 - val_loss: 0.3952 - val_accuracy: 0.8375\n",
            "Epoch 178/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.2947 - accuracy: 0.8793 - val_loss: 0.3816 - val_accuracy: 0.8500\n",
            "Epoch 179/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.2747 - accuracy: 0.8856 - val_loss: 0.3743 - val_accuracy: 0.8562\n",
            "Epoch 180/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.2772 - accuracy: 0.8903 - val_loss: 0.4289 - val_accuracy: 0.8313\n",
            "Epoch 181/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.2814 - accuracy: 0.8903 - val_loss: 0.4535 - val_accuracy: 0.8188\n",
            "Epoch 182/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.2835 - accuracy: 0.8824 - val_loss: 0.3853 - val_accuracy: 0.8687\n",
            "Epoch 183/200\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.2784 - accuracy: 0.8840 - val_loss: 0.4056 - val_accuracy: 0.8250\n",
            "Epoch 184/200\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.2869 - accuracy: 0.8918 - val_loss: 0.3985 - val_accuracy: 0.8375\n",
            "Epoch 185/200\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.2763 - accuracy: 0.8966 - val_loss: 0.4298 - val_accuracy: 0.8375\n",
            "Epoch 186/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.2747 - accuracy: 0.8903 - val_loss: 0.3831 - val_accuracy: 0.8562\n",
            "Epoch 187/200\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.2889 - accuracy: 0.8887 - val_loss: 0.3697 - val_accuracy: 0.8500\n",
            "Epoch 188/200\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.2842 - accuracy: 0.8777 - val_loss: 0.4110 - val_accuracy: 0.8313\n",
            "Epoch 189/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.2641 - accuracy: 0.8809 - val_loss: 0.4007 - val_accuracy: 0.8438\n",
            "Epoch 190/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.2811 - accuracy: 0.8856 - val_loss: 0.4231 - val_accuracy: 0.8313\n",
            "Epoch 191/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.2661 - accuracy: 0.8950 - val_loss: 0.4131 - val_accuracy: 0.8500\n",
            "Epoch 192/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.2656 - accuracy: 0.8871 - val_loss: 0.3949 - val_accuracy: 0.8562\n",
            "Epoch 193/200\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.2753 - accuracy: 0.8903 - val_loss: 0.3897 - val_accuracy: 0.8500\n",
            "Epoch 194/200\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.2923 - accuracy: 0.8887 - val_loss: 0.3477 - val_accuracy: 0.8687\n",
            "Epoch 195/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.2910 - accuracy: 0.8840 - val_loss: 0.4215 - val_accuracy: 0.8125\n",
            "Epoch 196/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.2660 - accuracy: 0.8871 - val_loss: 0.4131 - val_accuracy: 0.8250\n",
            "Epoch 197/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.2721 - accuracy: 0.8840 - val_loss: 0.4233 - val_accuracy: 0.8562\n",
            "Epoch 198/200\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.2841 - accuracy: 0.8887 - val_loss: 0.4630 - val_accuracy: 0.8000\n",
            "Epoch 199/200\n",
            "20/20 [==============================] - 0s 6ms/step - loss: 0.2841 - accuracy: 0.8746 - val_loss: 0.4199 - val_accuracy: 0.8313\n",
            "Epoch 200/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.2739 - accuracy: 0.8809 - val_loss: 0.4532 - val_accuracy: 0.8062\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.3702 - accuracy: 0.8583\n",
            "## evaluation loss and_metrics ##\n",
            "[0.370191752910614, 0.8583333492279053]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "heart.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 299
        },
        "id": "SGIZQf2x4aoe",
        "outputId": "a5f0e6d0-f2e4-4175-a3eb-010e9a83aae1"
      },
      "execution_count": 59,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   Age  RestingBP  Cholesterol  FastingBS  MaxHR  Oldpeak  HeartDisease  \\\n",
              "0    0        140          289          0    172      0.0             0   \n",
              "1    0        160          180          0    156      1.0             1   \n",
              "2    0        130          283          0     98      0.0             0   \n",
              "3    0        138          214          0    108      1.5             1   \n",
              "4    0        150          195          0    122      0.0             0   \n",
              "\n",
              "   Sex_F  Sex_M  ChestPainType_ASY  ...  ChestPainType_NAP  ChestPainType_TA  \\\n",
              "0      0      1                  0  ...                  0                 0   \n",
              "1      1      0                  0  ...                  1                 0   \n",
              "2      0      1                  0  ...                  0                 0   \n",
              "3      1      0                  1  ...                  0                 0   \n",
              "4      0      1                  0  ...                  1                 0   \n",
              "\n",
              "   RestingECG_LVH  RestingECG_Normal  RestingECG_ST  ExerciseAngina_N  \\\n",
              "0               0                  1              0                 1   \n",
              "1               0                  1              0                 1   \n",
              "2               0                  0              1                 1   \n",
              "3               0                  1              0                 0   \n",
              "4               0                  1              0                 1   \n",
              "\n",
              "   ExerciseAngina_Y  ST_Slope_Down  ST_Slope_Flat  ST_Slope_Up  \n",
              "0                 0              0              0            1  \n",
              "1                 0              0              1            0  \n",
              "2                 0              0              0            1  \n",
              "3                 1              0              1            0  \n",
              "4                 0              0              0            1  \n",
              "\n",
              "[5 rows x 21 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-b0208770-4c0d-45b4-8a66-724235750f59\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Age</th>\n",
              "      <th>RestingBP</th>\n",
              "      <th>Cholesterol</th>\n",
              "      <th>FastingBS</th>\n",
              "      <th>MaxHR</th>\n",
              "      <th>Oldpeak</th>\n",
              "      <th>HeartDisease</th>\n",
              "      <th>Sex_F</th>\n",
              "      <th>Sex_M</th>\n",
              "      <th>ChestPainType_ASY</th>\n",
              "      <th>...</th>\n",
              "      <th>ChestPainType_NAP</th>\n",
              "      <th>ChestPainType_TA</th>\n",
              "      <th>RestingECG_LVH</th>\n",
              "      <th>RestingECG_Normal</th>\n",
              "      <th>RestingECG_ST</th>\n",
              "      <th>ExerciseAngina_N</th>\n",
              "      <th>ExerciseAngina_Y</th>\n",
              "      <th>ST_Slope_Down</th>\n",
              "      <th>ST_Slope_Flat</th>\n",
              "      <th>ST_Slope_Up</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>140</td>\n",
              "      <td>289</td>\n",
              "      <td>0</td>\n",
              "      <td>172</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0</td>\n",
              "      <td>160</td>\n",
              "      <td>180</td>\n",
              "      <td>0</td>\n",
              "      <td>156</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0</td>\n",
              "      <td>130</td>\n",
              "      <td>283</td>\n",
              "      <td>0</td>\n",
              "      <td>98</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0</td>\n",
              "      <td>138</td>\n",
              "      <td>214</td>\n",
              "      <td>0</td>\n",
              "      <td>108</td>\n",
              "      <td>1.5</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0</td>\n",
              "      <td>150</td>\n",
              "      <td>195</td>\n",
              "      <td>0</td>\n",
              "      <td>122</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows × 21 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-b0208770-4c0d-45b4-8a66-724235750f59')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-b0208770-4c0d-45b4-8a66-724235750f59 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-b0208770-4c0d-45b4-8a66-724235750f59');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 59
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_predAge = ModelExceptAge.predict(x_test)\n",
        "y_predAge\n",
        "\n",
        "y_pred_classAge = np.argmax(y_predAge, axis=1)\n",
        "y_pred_classAge\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "y_test  = y_test.to_numpy()\n",
        "y_test\n",
        "\n",
        "y_test = np.argmax(y_test,axis=1)\n",
        "y_test\n",
        "\n",
        "np.mean(y_test == y_pred_classAge)\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Hhxer-hI4FUs",
        "outputId": "4b6ec4a8-57f3-4444-87cb-decf17a0b353"
      },
      "execution_count": 60,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "4/4 [==============================] - 0s 3ms/step\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.8583333333333333"
            ]
          },
          "metadata": {},
          "execution_count": 60
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "np.mean(y_test == y_pred_classAge)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ms5zHBW8EIQ-",
        "outputId": "5ffc08f6-7e17-42e5-cfe5-bc62574ee44f"
      },
      "execution_count": 62,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.8583333333333333"
            ]
          },
          "metadata": {},
          "execution_count": 62
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "Agescore=recall_score(y_test,y_pred_classAge)\n",
        "print(Agescore)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aWLGzvJ0ETvS",
        "outputId": "27c96c1e-b1ca-47ca-da14-132ff2b338c8"
      },
      "execution_count": 64,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.9142857142857143\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "'ST_Slope_Up"
      ],
      "metadata": {
        "id": "p4U2wiaEZBw7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "heart = pd.read_csv(f_path)\n",
        "\n",
        "heart = pd.get_dummies(heart)\n",
        "heart.count()\n",
        "\n",
        "x = heart.drop('HeartDisease', axis=1)\n",
        "y = pd.get_dummies(heart[\"HeartDisease\"])"
      ],
      "metadata": {
        "id": "hYGXUFCw5tjZ"
      },
      "execution_count": 65,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "import keras\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Dropout, Activation\n",
        "\n",
        "heart['ST_Slope_Up'] = 0\n",
        "\n",
        "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size = 0.13,shuffle=True, random_state = 42)\n",
        "\n",
        "print(\"X_train: \", x_train.shape)\n",
        "print(\"y_train: \", y_train.shape)\n",
        "\n",
        "print(\"X_test: \", x_test.shape)\n",
        "print(\"y_test: \", y_test.shape)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "ModelExceptST_Slope_Up = Sequential()\n",
        "\n",
        "\n",
        "ModelExceptST_Slope_Up.add(Dense(128, activation = \"relu\",input_dim=20))\n",
        "ModelExceptST_Slope_Up.add(Dropout(rate=0.2))\n",
        "ModelExceptST_Slope_Up.add(Dense(64, activation = \"relu\"))\n",
        "ModelExceptST_Slope_Up.add(Dropout(rate=0.2))\n",
        "ModelExceptST_Slope_Up.add(Dense(32, activation = \"relu\"))\n",
        "ModelExceptST_Slope_Up.add(Dropout(rate=0.1))\n",
        "ModelExceptST_Slope_Up.add(Dense(16, activation = \"relu\"))\n",
        "ModelExceptST_Slope_Up.add(Dense(8, activation = \"relu\"))\n",
        "ModelExceptST_Slope_Up.add(Dense(2, activation = \"sigmoid\"))\n",
        "\n",
        "ModelExceptST_Slope_Up.compile(optimizer = \"adam\", loss = \"categorical_crossentropy\", metrics = [\"accuracy\"])\n",
        "ModelExceptST_Slope_Up.summary()\n",
        "\n",
        "hin=ModelExceptST_Slope_Up.fit(x_train,y_train,epochs=100, validation_split=0.2)\n",
        "\n",
        "loss_and_metrics = ModelExceptST_Slope_Up.evaluate(x_test, y_test, batch_size=32)\n",
        "print('## evaluation loss and_metrics ##')\n",
        "print(loss_and_metrics)\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GwMC0HJj7u_y",
        "outputId": "1bb4e8a9-7560-408d-f47a-b942419ebf5a"
      },
      "execution_count": 66,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "X_train:  (798, 20)\n",
            "y_train:  (798, 2)\n",
            "X_test:  (120, 20)\n",
            "y_test:  (120, 2)\n",
            "Model: \"sequential_5\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense_30 (Dense)            (None, 128)               2688      \n",
            "                                                                 \n",
            " dropout_15 (Dropout)        (None, 128)               0         \n",
            "                                                                 \n",
            " dense_31 (Dense)            (None, 64)                8256      \n",
            "                                                                 \n",
            " dropout_16 (Dropout)        (None, 64)                0         \n",
            "                                                                 \n",
            " dense_32 (Dense)            (None, 32)                2080      \n",
            "                                                                 \n",
            " dropout_17 (Dropout)        (None, 32)                0         \n",
            "                                                                 \n",
            " dense_33 (Dense)            (None, 16)                528       \n",
            "                                                                 \n",
            " dense_34 (Dense)            (None, 8)                 136       \n",
            "                                                                 \n",
            " dense_35 (Dense)            (None, 2)                 18        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 13,706\n",
            "Trainable params: 13,706\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/100\n",
            "20/20 [==============================] - 1s 13ms/step - loss: 4.4055 - accuracy: 0.5439 - val_loss: 0.8776 - val_accuracy: 0.5312\n",
            "Epoch 2/100\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 1.6137 - accuracy: 0.5784 - val_loss: 0.8612 - val_accuracy: 0.5250\n",
            "Epoch 3/100\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 1.1498 - accuracy: 0.5564 - val_loss: 0.8068 - val_accuracy: 0.4688\n",
            "Epoch 4/100\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.9959 - accuracy: 0.5345 - val_loss: 0.6102 - val_accuracy: 0.6187\n",
            "Epoch 5/100\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.8207 - accuracy: 0.5878 - val_loss: 0.6062 - val_accuracy: 0.6875\n",
            "Epoch 6/100\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.7059 - accuracy: 0.6003 - val_loss: 0.5937 - val_accuracy: 0.7250\n",
            "Epoch 7/100\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.7477 - accuracy: 0.5909 - val_loss: 0.6139 - val_accuracy: 0.6938\n",
            "Epoch 8/100\n",
            "20/20 [==============================] - 0s 6ms/step - loss: 0.6711 - accuracy: 0.6113 - val_loss: 0.6105 - val_accuracy: 0.5500\n",
            "Epoch 9/100\n",
            "20/20 [==============================] - 0s 8ms/step - loss: 0.7509 - accuracy: 0.5517 - val_loss: 0.6115 - val_accuracy: 0.4938\n",
            "Epoch 10/100\n",
            "20/20 [==============================] - 0s 8ms/step - loss: 0.6629 - accuracy: 0.6191 - val_loss: 0.6234 - val_accuracy: 0.7063\n",
            "Epoch 11/100\n",
            "20/20 [==============================] - 0s 8ms/step - loss: 0.6968 - accuracy: 0.5972 - val_loss: 0.6220 - val_accuracy: 0.4938\n",
            "Epoch 12/100\n",
            "20/20 [==============================] - 0s 9ms/step - loss: 0.6731 - accuracy: 0.5987 - val_loss: 0.6229 - val_accuracy: 0.4938\n",
            "Epoch 13/100\n",
            "20/20 [==============================] - 0s 9ms/step - loss: 0.6728 - accuracy: 0.6097 - val_loss: 0.6257 - val_accuracy: 0.4938\n",
            "Epoch 14/100\n",
            "20/20 [==============================] - 0s 8ms/step - loss: 0.6864 - accuracy: 0.5909 - val_loss: 0.6253 - val_accuracy: 0.4938\n",
            "Epoch 15/100\n",
            "20/20 [==============================] - 0s 15ms/step - loss: 0.6777 - accuracy: 0.6050 - val_loss: 0.6217 - val_accuracy: 0.5500\n",
            "Epoch 16/100\n",
            "20/20 [==============================] - 0s 12ms/step - loss: 0.6837 - accuracy: 0.6034 - val_loss: 0.6192 - val_accuracy: 0.6375\n",
            "Epoch 17/100\n",
            "20/20 [==============================] - 0s 14ms/step - loss: 0.6360 - accuracy: 0.6301 - val_loss: 0.6123 - val_accuracy: 0.7188\n",
            "Epoch 18/100\n",
            "20/20 [==============================] - 0s 6ms/step - loss: 0.6646 - accuracy: 0.5893 - val_loss: 0.6217 - val_accuracy: 0.5813\n",
            "Epoch 19/100\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.6622 - accuracy: 0.6097 - val_loss: 0.6246 - val_accuracy: 0.5063\n",
            "Epoch 20/100\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.6449 - accuracy: 0.6097 - val_loss: 0.6216 - val_accuracy: 0.4938\n",
            "Epoch 21/100\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.6756 - accuracy: 0.5752 - val_loss: 0.6165 - val_accuracy: 0.4938\n",
            "Epoch 22/100\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.6490 - accuracy: 0.5956 - val_loss: 0.6174 - val_accuracy: 0.4938\n",
            "Epoch 23/100\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.6486 - accuracy: 0.6003 - val_loss: 0.6104 - val_accuracy: 0.4938\n",
            "Epoch 24/100\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.6386 - accuracy: 0.6019 - val_loss: 0.6064 - val_accuracy: 0.4938\n",
            "Epoch 25/100\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.6485 - accuracy: 0.6003 - val_loss: 0.6079 - val_accuracy: 0.7500\n",
            "Epoch 26/100\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.6347 - accuracy: 0.6223 - val_loss: 0.6049 - val_accuracy: 0.7500\n",
            "Epoch 27/100\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.6346 - accuracy: 0.5987 - val_loss: 0.6074 - val_accuracy: 0.7563\n",
            "Epoch 28/100\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.6411 - accuracy: 0.6379 - val_loss: 0.6103 - val_accuracy: 0.7563\n",
            "Epoch 29/100\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.6255 - accuracy: 0.6207 - val_loss: 0.6085 - val_accuracy: 0.6125\n",
            "Epoch 30/100\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.6443 - accuracy: 0.6254 - val_loss: 0.6070 - val_accuracy: 0.7188\n",
            "Epoch 31/100\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.6257 - accuracy: 0.6505 - val_loss: 0.6008 - val_accuracy: 0.7437\n",
            "Epoch 32/100\n",
            "20/20 [==============================] - 0s 6ms/step - loss: 0.6131 - accuracy: 0.6614 - val_loss: 0.6022 - val_accuracy: 0.6375\n",
            "Epoch 33/100\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.6232 - accuracy: 0.6473 - val_loss: 0.5938 - val_accuracy: 0.6438\n",
            "Epoch 34/100\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.6255 - accuracy: 0.6583 - val_loss: 0.5796 - val_accuracy: 0.7250\n",
            "Epoch 35/100\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.6101 - accuracy: 0.6661 - val_loss: 0.5748 - val_accuracy: 0.7188\n",
            "Epoch 36/100\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.6095 - accuracy: 0.6724 - val_loss: 0.5706 - val_accuracy: 0.7188\n",
            "Epoch 37/100\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.5990 - accuracy: 0.6897 - val_loss: 0.5746 - val_accuracy: 0.6938\n",
            "Epoch 38/100\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.5972 - accuracy: 0.7179 - val_loss: 0.5873 - val_accuracy: 0.6438\n",
            "Epoch 39/100\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.5771 - accuracy: 0.7069 - val_loss: 0.5419 - val_accuracy: 0.7250\n",
            "Epoch 40/100\n",
            "20/20 [==============================] - 0s 6ms/step - loss: 0.5669 - accuracy: 0.7022 - val_loss: 0.5651 - val_accuracy: 0.7063\n",
            "Epoch 41/100\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.5731 - accuracy: 0.7100 - val_loss: 0.5579 - val_accuracy: 0.7063\n",
            "Epoch 42/100\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.5808 - accuracy: 0.7022 - val_loss: 0.5610 - val_accuracy: 0.7000\n",
            "Epoch 43/100\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.5832 - accuracy: 0.7226 - val_loss: 0.5507 - val_accuracy: 0.7188\n",
            "Epoch 44/100\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.5814 - accuracy: 0.7053 - val_loss: 0.5951 - val_accuracy: 0.6313\n",
            "Epoch 45/100\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.5604 - accuracy: 0.7006 - val_loss: 0.5956 - val_accuracy: 0.6187\n",
            "Epoch 46/100\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.5909 - accuracy: 0.6630 - val_loss: 0.5484 - val_accuracy: 0.7125\n",
            "Epoch 47/100\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.5832 - accuracy: 0.6975 - val_loss: 0.5956 - val_accuracy: 0.5875\n",
            "Epoch 48/100\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.5624 - accuracy: 0.7053 - val_loss: 0.5378 - val_accuracy: 0.7375\n",
            "Epoch 49/100\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.5658 - accuracy: 0.7257 - val_loss: 0.5458 - val_accuracy: 0.7250\n",
            "Epoch 50/100\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.5697 - accuracy: 0.6975 - val_loss: 0.5439 - val_accuracy: 0.7312\n",
            "Epoch 51/100\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.5642 - accuracy: 0.7226 - val_loss: 0.5196 - val_accuracy: 0.7625\n",
            "Epoch 52/100\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.5545 - accuracy: 0.7194 - val_loss: 0.5208 - val_accuracy: 0.7500\n",
            "Epoch 53/100\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.5349 - accuracy: 0.7571 - val_loss: 0.5185 - val_accuracy: 0.7500\n",
            "Epoch 54/100\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.5545 - accuracy: 0.7273 - val_loss: 0.5227 - val_accuracy: 0.7312\n",
            "Epoch 55/100\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.5478 - accuracy: 0.7398 - val_loss: 0.5193 - val_accuracy: 0.7625\n",
            "Epoch 56/100\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.5650 - accuracy: 0.7163 - val_loss: 0.5212 - val_accuracy: 0.7625\n",
            "Epoch 57/100\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.5399 - accuracy: 0.7288 - val_loss: 0.5182 - val_accuracy: 0.7437\n",
            "Epoch 58/100\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.5294 - accuracy: 0.7367 - val_loss: 0.5359 - val_accuracy: 0.7063\n",
            "Epoch 59/100\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.5397 - accuracy: 0.7257 - val_loss: 0.4951 - val_accuracy: 0.8062\n",
            "Epoch 60/100\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.5271 - accuracy: 0.7539 - val_loss: 0.5185 - val_accuracy: 0.7437\n",
            "Epoch 61/100\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.5297 - accuracy: 0.7618 - val_loss: 0.4997 - val_accuracy: 0.8062\n",
            "Epoch 62/100\n",
            "20/20 [==============================] - 0s 6ms/step - loss: 0.5333 - accuracy: 0.7461 - val_loss: 0.5093 - val_accuracy: 0.7937\n",
            "Epoch 63/100\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.5355 - accuracy: 0.7445 - val_loss: 0.4997 - val_accuracy: 0.7875\n",
            "Epoch 64/100\n",
            "20/20 [==============================] - 0s 6ms/step - loss: 0.5260 - accuracy: 0.7633 - val_loss: 0.5116 - val_accuracy: 0.7625\n",
            "Epoch 65/100\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.4975 - accuracy: 0.7743 - val_loss: 0.4913 - val_accuracy: 0.7937\n",
            "Epoch 66/100\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.4995 - accuracy: 0.7743 - val_loss: 0.5011 - val_accuracy: 0.7750\n",
            "Epoch 67/100\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.5271 - accuracy: 0.7492 - val_loss: 0.4961 - val_accuracy: 0.7750\n",
            "Epoch 68/100\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.5041 - accuracy: 0.7649 - val_loss: 0.5038 - val_accuracy: 0.7688\n",
            "Epoch 69/100\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.5195 - accuracy: 0.7712 - val_loss: 0.4897 - val_accuracy: 0.7937\n",
            "Epoch 70/100\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.5084 - accuracy: 0.7649 - val_loss: 0.4874 - val_accuracy: 0.8000\n",
            "Epoch 71/100\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.5172 - accuracy: 0.7555 - val_loss: 0.4955 - val_accuracy: 0.7750\n",
            "Epoch 72/100\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.4901 - accuracy: 0.7790 - val_loss: 0.4930 - val_accuracy: 0.7688\n",
            "Epoch 73/100\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.4999 - accuracy: 0.7633 - val_loss: 0.4998 - val_accuracy: 0.7688\n",
            "Epoch 74/100\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.4881 - accuracy: 0.7900 - val_loss: 0.4906 - val_accuracy: 0.7688\n",
            "Epoch 75/100\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.4959 - accuracy: 0.7696 - val_loss: 0.4776 - val_accuracy: 0.7812\n",
            "Epoch 76/100\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.5032 - accuracy: 0.7712 - val_loss: 0.4550 - val_accuracy: 0.8250\n",
            "Epoch 77/100\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.5105 - accuracy: 0.7806 - val_loss: 0.4975 - val_accuracy: 0.7750\n",
            "Epoch 78/100\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.4894 - accuracy: 0.7539 - val_loss: 0.4617 - val_accuracy: 0.8125\n",
            "Epoch 79/100\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.4596 - accuracy: 0.8041 - val_loss: 0.4660 - val_accuracy: 0.7875\n",
            "Epoch 80/100\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.4743 - accuracy: 0.7962 - val_loss: 0.4502 - val_accuracy: 0.8125\n",
            "Epoch 81/100\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.4637 - accuracy: 0.7978 - val_loss: 0.4797 - val_accuracy: 0.7875\n",
            "Epoch 82/100\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.4660 - accuracy: 0.7837 - val_loss: 0.4435 - val_accuracy: 0.8125\n",
            "Epoch 83/100\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.4477 - accuracy: 0.8135 - val_loss: 0.4345 - val_accuracy: 0.8250\n",
            "Epoch 84/100\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.4590 - accuracy: 0.8041 - val_loss: 0.4510 - val_accuracy: 0.8062\n",
            "Epoch 85/100\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.4450 - accuracy: 0.8056 - val_loss: 0.4303 - val_accuracy: 0.8250\n",
            "Epoch 86/100\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.4578 - accuracy: 0.7978 - val_loss: 0.4852 - val_accuracy: 0.7688\n",
            "Epoch 87/100\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.4465 - accuracy: 0.8103 - val_loss: 0.4504 - val_accuracy: 0.8062\n",
            "Epoch 88/100\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.4565 - accuracy: 0.8056 - val_loss: 0.4148 - val_accuracy: 0.8438\n",
            "Epoch 89/100\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.4407 - accuracy: 0.8119 - val_loss: 0.4326 - val_accuracy: 0.8250\n",
            "Epoch 90/100\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.4469 - accuracy: 0.8088 - val_loss: 0.4798 - val_accuracy: 0.7875\n",
            "Epoch 91/100\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.4192 - accuracy: 0.8213 - val_loss: 0.4236 - val_accuracy: 0.8250\n",
            "Epoch 92/100\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.4347 - accuracy: 0.8119 - val_loss: 0.4297 - val_accuracy: 0.8250\n",
            "Epoch 93/100\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.4344 - accuracy: 0.8150 - val_loss: 0.4047 - val_accuracy: 0.8375\n",
            "Epoch 94/100\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.4351 - accuracy: 0.8260 - val_loss: 0.4103 - val_accuracy: 0.8500\n",
            "Epoch 95/100\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.4295 - accuracy: 0.8166 - val_loss: 0.4058 - val_accuracy: 0.8438\n",
            "Epoch 96/100\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.4365 - accuracy: 0.8056 - val_loss: 0.4549 - val_accuracy: 0.8125\n",
            "Epoch 97/100\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.4413 - accuracy: 0.8041 - val_loss: 0.4477 - val_accuracy: 0.8250\n",
            "Epoch 98/100\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.4276 - accuracy: 0.8276 - val_loss: 0.4166 - val_accuracy: 0.8438\n",
            "Epoch 99/100\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.4021 - accuracy: 0.8417 - val_loss: 0.3975 - val_accuracy: 0.8438\n",
            "Epoch 100/100\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.3903 - accuracy: 0.8323 - val_loss: 0.3928 - val_accuracy: 0.8438\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 0.4145 - accuracy: 0.8000\n",
            "## evaluation loss and_metrics ##\n",
            "[0.4145258367061615, 0.800000011920929]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_predST_Slope_Up = ModelExceptST_Slope_Up.predict(x_test)\n",
        "y_predST_Slope_Up\n",
        "\n",
        "y_pred_classST_Slope_Up = np.argmax(y_predST_Slope_Up, axis=1)\n",
        "y_pred_classST_Slope_Up\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "y_test  = y_test.to_numpy()\n",
        "y_test\n",
        "\n",
        "y_test = np.argmax(y_test,axis=1)\n",
        "y_test\n",
        "\n",
        "np.mean(y_test == y_pred_classST_Slope_Up)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "u4A9cqf48VZq",
        "outputId": "7f1c620f-2be7-413a-a634-55a307d51bd6"
      },
      "execution_count": 67,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "4/4 [==============================] - 0s 3ms/step\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.8"
            ]
          },
          "metadata": {},
          "execution_count": 67
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "Slupscore=recall_score(y_test,y_pred_classST_Slope_Up)\n",
        "print(Slupscore)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8Ol4OHsZEdE1",
        "outputId": "4886cf62-0fe6-49b4-bcd3-2568017fc64a"
      },
      "execution_count": 68,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.8\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "RestingBP"
      ],
      "metadata": {
        "id": "hii32lFuEkRu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "heart = pd.read_csv(f_path)\n",
        "\n",
        "heart = pd.get_dummies(heart)\n",
        "\n",
        "x = heart.drop('HeartDisease', axis=1)\n",
        "y = pd.get_dummies(heart[\"HeartDisease\"])\n",
        "\n",
        "heart['RestingBP'] = 0\n",
        "\n",
        "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size = 0.13,shuffle=True, random_state = 42)\n",
        "\n",
        "print(\"X_train: \", x_train.shape)\n",
        "print(\"y_train: \", y_train.shape)\n",
        "\n",
        "print(\"X_test: \", x_test.shape)\n",
        "print(\"y_test: \", y_test.shape)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "ModelExceptRestingBP = Sequential()\n",
        "\n",
        "\n",
        "ModelExceptRestingBP.add(Dense(128, activation = \"relu\",input_dim=20))\n",
        "ModelExceptRestingBP.add(Dropout(rate=0.2))\n",
        "ModelExceptRestingBP.add(Dense(64, activation = \"relu\"))\n",
        "ModelExceptRestingBP.add(Dropout(rate=0.2))\n",
        "ModelExceptRestingBP.add(Dense(32, activation = \"relu\"))\n",
        "ModelExceptRestingBP.add(Dropout(rate=0.1))\n",
        "ModelExceptRestingBP.add(Dense(16, activation = \"relu\"))\n",
        "ModelExceptRestingBP.add(Dense(8, activation = \"relu\"))\n",
        "ModelExceptRestingBP.add(Dense(2, activation = \"sigmoid\"))\n",
        "\n",
        "ModelExceptRestingBP.compile(optimizer = \"adam\", loss = \"categorical_crossentropy\", metrics = [\"accuracy\"])\n",
        "ModelExceptRestingBP.summary()\n",
        "\n",
        "hin=ModelExceptRestingBP.fit(x_train,y_train,epochs=200, validation_split=0.2)\n",
        "\n",
        "loss_and_metrics = ModelExceptRestingBP.evaluate(x_test, y_test, batch_size=32)\n",
        "print('## evaluation loss and_metrics ##')\n",
        "print(loss_and_metrics)\n",
        "\n",
        "y_predRestingBP = ModelExceptRestingBP.predict(x_test)\n",
        "y_predRestingBP\n",
        "\n",
        "y_pred_classRestingBP = np.argmax(y_predRestingBP, axis=1)\n",
        "y_pred_classRestingBP\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "y_test  = y_test.to_numpy()\n",
        "y_test\n",
        "\n",
        "y_test = np.argmax(y_test,axis=1)\n",
        "y_test\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Dj2LIX5KEs6M",
        "outputId": "14ecb7b1-aa31-4bd6-c54a-301bb599dd20"
      },
      "execution_count": 69,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "X_train:  (798, 20)\n",
            "y_train:  (798, 2)\n",
            "X_test:  (120, 20)\n",
            "y_test:  (120, 2)\n",
            "Model: \"sequential_6\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense_36 (Dense)            (None, 128)               2688      \n",
            "                                                                 \n",
            " dropout_18 (Dropout)        (None, 128)               0         \n",
            "                                                                 \n",
            " dense_37 (Dense)            (None, 64)                8256      \n",
            "                                                                 \n",
            " dropout_19 (Dropout)        (None, 64)                0         \n",
            "                                                                 \n",
            " dense_38 (Dense)            (None, 32)                2080      \n",
            "                                                                 \n",
            " dropout_20 (Dropout)        (None, 32)                0         \n",
            "                                                                 \n",
            " dense_39 (Dense)            (None, 16)                528       \n",
            "                                                                 \n",
            " dense_40 (Dense)            (None, 8)                 136       \n",
            "                                                                 \n",
            " dense_41 (Dense)            (None, 2)                 18        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 13,706\n",
            "Trainable params: 13,706\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/200\n",
            "20/20 [==============================] - 1s 13ms/step - loss: 2.5545 - accuracy: 0.4843 - val_loss: 0.8849 - val_accuracy: 0.5063\n",
            "Epoch 2/200\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 1.1696 - accuracy: 0.5282 - val_loss: 0.7414 - val_accuracy: 0.4563\n",
            "Epoch 3/200\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.9626 - accuracy: 0.5533 - val_loss: 0.6170 - val_accuracy: 0.6625\n",
            "Epoch 4/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.8414 - accuracy: 0.5737 - val_loss: 0.5877 - val_accuracy: 0.6750\n",
            "Epoch 5/200\n",
            "20/20 [==============================] - 0s 6ms/step - loss: 0.7516 - accuracy: 0.5987 - val_loss: 0.5769 - val_accuracy: 0.7188\n",
            "Epoch 6/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.7421 - accuracy: 0.5925 - val_loss: 0.5866 - val_accuracy: 0.7437\n",
            "Epoch 7/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.6966 - accuracy: 0.6097 - val_loss: 0.6144 - val_accuracy: 0.6250\n",
            "Epoch 8/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.7085 - accuracy: 0.5925 - val_loss: 0.5813 - val_accuracy: 0.7500\n",
            "Epoch 9/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.6792 - accuracy: 0.6160 - val_loss: 0.5775 - val_accuracy: 0.7188\n",
            "Epoch 10/200\n",
            "20/20 [==============================] - 0s 6ms/step - loss: 0.7085 - accuracy: 0.6034 - val_loss: 0.5610 - val_accuracy: 0.7250\n",
            "Epoch 11/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.6591 - accuracy: 0.6097 - val_loss: 0.5665 - val_accuracy: 0.7312\n",
            "Epoch 12/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.6480 - accuracy: 0.6176 - val_loss: 0.5774 - val_accuracy: 0.7188\n",
            "Epoch 13/200\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.6373 - accuracy: 0.6505 - val_loss: 0.5693 - val_accuracy: 0.7375\n",
            "Epoch 14/200\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.6574 - accuracy: 0.5987 - val_loss: 0.5828 - val_accuracy: 0.7250\n",
            "Epoch 15/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.6483 - accuracy: 0.6176 - val_loss: 0.5534 - val_accuracy: 0.7437\n",
            "Epoch 16/200\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.6586 - accuracy: 0.6019 - val_loss: 0.5559 - val_accuracy: 0.7500\n",
            "Epoch 17/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.6288 - accuracy: 0.6332 - val_loss: 0.5490 - val_accuracy: 0.7688\n",
            "Epoch 18/200\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.6044 - accuracy: 0.6489 - val_loss: 0.5523 - val_accuracy: 0.7312\n",
            "Epoch 19/200\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.6060 - accuracy: 0.6630 - val_loss: 0.5340 - val_accuracy: 0.7563\n",
            "Epoch 20/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.6334 - accuracy: 0.6630 - val_loss: 0.5533 - val_accuracy: 0.7375\n",
            "Epoch 21/200\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.6191 - accuracy: 0.6505 - val_loss: 0.5591 - val_accuracy: 0.7375\n",
            "Epoch 22/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.6465 - accuracy: 0.6552 - val_loss: 0.5418 - val_accuracy: 0.7312\n",
            "Epoch 23/200\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.6123 - accuracy: 0.6865 - val_loss: 0.5335 - val_accuracy: 0.7437\n",
            "Epoch 24/200\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.6003 - accuracy: 0.6755 - val_loss: 0.5789 - val_accuracy: 0.6875\n",
            "Epoch 25/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.6130 - accuracy: 0.6536 - val_loss: 0.5995 - val_accuracy: 0.6313\n",
            "Epoch 26/200\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.6103 - accuracy: 0.6614 - val_loss: 0.5307 - val_accuracy: 0.7563\n",
            "Epoch 27/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.5959 - accuracy: 0.6818 - val_loss: 0.5333 - val_accuracy: 0.7437\n",
            "Epoch 28/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.5870 - accuracy: 0.7100 - val_loss: 0.5445 - val_accuracy: 0.7500\n",
            "Epoch 29/200\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.5539 - accuracy: 0.7304 - val_loss: 0.5183 - val_accuracy: 0.7375\n",
            "Epoch 30/200\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.5815 - accuracy: 0.7241 - val_loss: 0.5260 - val_accuracy: 0.7500\n",
            "Epoch 31/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.5682 - accuracy: 0.7210 - val_loss: 0.5353 - val_accuracy: 0.7500\n",
            "Epoch 32/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.5598 - accuracy: 0.7116 - val_loss: 0.5305 - val_accuracy: 0.7500\n",
            "Epoch 33/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.5859 - accuracy: 0.7194 - val_loss: 0.5378 - val_accuracy: 0.7437\n",
            "Epoch 34/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.5566 - accuracy: 0.7398 - val_loss: 0.5147 - val_accuracy: 0.7375\n",
            "Epoch 35/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.5541 - accuracy: 0.7273 - val_loss: 0.5121 - val_accuracy: 0.7500\n",
            "Epoch 36/200\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.5478 - accuracy: 0.7367 - val_loss: 0.5365 - val_accuracy: 0.7437\n",
            "Epoch 37/200\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.5610 - accuracy: 0.7163 - val_loss: 0.5286 - val_accuracy: 0.7375\n",
            "Epoch 38/200\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.5557 - accuracy: 0.7461 - val_loss: 0.5061 - val_accuracy: 0.7750\n",
            "Epoch 39/200\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.5495 - accuracy: 0.7288 - val_loss: 0.4940 - val_accuracy: 0.7750\n",
            "Epoch 40/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.5567 - accuracy: 0.7320 - val_loss: 0.5107 - val_accuracy: 0.7875\n",
            "Epoch 41/200\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.5360 - accuracy: 0.7524 - val_loss: 0.4998 - val_accuracy: 0.7750\n",
            "Epoch 42/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.5320 - accuracy: 0.7414 - val_loss: 0.4892 - val_accuracy: 0.7750\n",
            "Epoch 43/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.5349 - accuracy: 0.7508 - val_loss: 0.5131 - val_accuracy: 0.7563\n",
            "Epoch 44/200\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.5066 - accuracy: 0.7649 - val_loss: 0.4887 - val_accuracy: 0.7937\n",
            "Epoch 45/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.5249 - accuracy: 0.7571 - val_loss: 0.4908 - val_accuracy: 0.7937\n",
            "Epoch 46/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.5133 - accuracy: 0.7602 - val_loss: 0.4991 - val_accuracy: 0.7688\n",
            "Epoch 47/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.5214 - accuracy: 0.7868 - val_loss: 0.4881 - val_accuracy: 0.7875\n",
            "Epoch 48/200\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.5132 - accuracy: 0.7571 - val_loss: 0.4770 - val_accuracy: 0.8062\n",
            "Epoch 49/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.5078 - accuracy: 0.7571 - val_loss: 0.5019 - val_accuracy: 0.7688\n",
            "Epoch 50/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.5115 - accuracy: 0.7618 - val_loss: 0.4794 - val_accuracy: 0.7937\n",
            "Epoch 51/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.5114 - accuracy: 0.7790 - val_loss: 0.4812 - val_accuracy: 0.8000\n",
            "Epoch 52/200\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.4969 - accuracy: 0.7900 - val_loss: 0.4685 - val_accuracy: 0.8188\n",
            "Epoch 53/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.4975 - accuracy: 0.7853 - val_loss: 0.4987 - val_accuracy: 0.7688\n",
            "Epoch 54/200\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.4978 - accuracy: 0.7774 - val_loss: 0.4589 - val_accuracy: 0.8062\n",
            "Epoch 55/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.5004 - accuracy: 0.7759 - val_loss: 0.4617 - val_accuracy: 0.8188\n",
            "Epoch 56/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.4893 - accuracy: 0.7790 - val_loss: 0.4728 - val_accuracy: 0.8062\n",
            "Epoch 57/200\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.4894 - accuracy: 0.7743 - val_loss: 0.4651 - val_accuracy: 0.8188\n",
            "Epoch 58/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.4992 - accuracy: 0.7806 - val_loss: 0.4937 - val_accuracy: 0.7812\n",
            "Epoch 59/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.4978 - accuracy: 0.7774 - val_loss: 0.5035 - val_accuracy: 0.7812\n",
            "Epoch 60/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.4713 - accuracy: 0.7900 - val_loss: 0.4634 - val_accuracy: 0.8062\n",
            "Epoch 61/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.4731 - accuracy: 0.7962 - val_loss: 0.4610 - val_accuracy: 0.8062\n",
            "Epoch 62/200\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.4809 - accuracy: 0.7900 - val_loss: 0.4488 - val_accuracy: 0.8375\n",
            "Epoch 63/200\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.4642 - accuracy: 0.7821 - val_loss: 0.4392 - val_accuracy: 0.8438\n",
            "Epoch 64/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.4483 - accuracy: 0.8088 - val_loss: 0.4387 - val_accuracy: 0.8438\n",
            "Epoch 65/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.4517 - accuracy: 0.8041 - val_loss: 0.5003 - val_accuracy: 0.7812\n",
            "Epoch 66/200\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.4565 - accuracy: 0.8072 - val_loss: 0.4614 - val_accuracy: 0.8062\n",
            "Epoch 67/200\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.4518 - accuracy: 0.8072 - val_loss: 0.4258 - val_accuracy: 0.8438\n",
            "Epoch 68/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.4542 - accuracy: 0.8025 - val_loss: 0.4810 - val_accuracy: 0.7937\n",
            "Epoch 69/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.4532 - accuracy: 0.7947 - val_loss: 0.5105 - val_accuracy: 0.7750\n",
            "Epoch 70/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.4383 - accuracy: 0.8088 - val_loss: 0.4370 - val_accuracy: 0.8313\n",
            "Epoch 71/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.4401 - accuracy: 0.8276 - val_loss: 0.4113 - val_accuracy: 0.8438\n",
            "Epoch 72/200\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.4440 - accuracy: 0.8119 - val_loss: 0.4605 - val_accuracy: 0.8125\n",
            "Epoch 73/200\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.4300 - accuracy: 0.8213 - val_loss: 0.4165 - val_accuracy: 0.8438\n",
            "Epoch 74/200\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.4165 - accuracy: 0.8229 - val_loss: 0.4013 - val_accuracy: 0.8438\n",
            "Epoch 75/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.4323 - accuracy: 0.8135 - val_loss: 0.4199 - val_accuracy: 0.8438\n",
            "Epoch 76/200\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.4231 - accuracy: 0.8229 - val_loss: 0.4087 - val_accuracy: 0.8500\n",
            "Epoch 77/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.4145 - accuracy: 0.8354 - val_loss: 0.3913 - val_accuracy: 0.8313\n",
            "Epoch 78/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.4221 - accuracy: 0.8245 - val_loss: 0.4266 - val_accuracy: 0.8375\n",
            "Epoch 79/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.4199 - accuracy: 0.8339 - val_loss: 0.4278 - val_accuracy: 0.8375\n",
            "Epoch 80/200\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.3995 - accuracy: 0.8417 - val_loss: 0.4056 - val_accuracy: 0.8375\n",
            "Epoch 81/200\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.3934 - accuracy: 0.8370 - val_loss: 0.4030 - val_accuracy: 0.8375\n",
            "Epoch 82/200\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.3956 - accuracy: 0.8417 - val_loss: 0.4374 - val_accuracy: 0.8313\n",
            "Epoch 83/200\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.4128 - accuracy: 0.8386 - val_loss: 0.3829 - val_accuracy: 0.8500\n",
            "Epoch 84/200\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.3915 - accuracy: 0.8401 - val_loss: 0.3972 - val_accuracy: 0.8562\n",
            "Epoch 85/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.3864 - accuracy: 0.8386 - val_loss: 0.5123 - val_accuracy: 0.8062\n",
            "Epoch 86/200\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.4164 - accuracy: 0.8323 - val_loss: 0.3930 - val_accuracy: 0.8562\n",
            "Epoch 87/200\n",
            "20/20 [==============================] - 0s 6ms/step - loss: 0.3891 - accuracy: 0.8386 - val_loss: 0.3659 - val_accuracy: 0.8562\n",
            "Epoch 88/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.3958 - accuracy: 0.8433 - val_loss: 0.3652 - val_accuracy: 0.8625\n",
            "Epoch 89/200\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.3877 - accuracy: 0.8542 - val_loss: 0.3795 - val_accuracy: 0.8625\n",
            "Epoch 90/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.3736 - accuracy: 0.8433 - val_loss: 0.3639 - val_accuracy: 0.8687\n",
            "Epoch 91/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.3809 - accuracy: 0.8370 - val_loss: 0.3923 - val_accuracy: 0.8438\n",
            "Epoch 92/200\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.3808 - accuracy: 0.8480 - val_loss: 0.3895 - val_accuracy: 0.8438\n",
            "Epoch 93/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.3739 - accuracy: 0.8307 - val_loss: 0.3857 - val_accuracy: 0.8438\n",
            "Epoch 94/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.3657 - accuracy: 0.8621 - val_loss: 0.3884 - val_accuracy: 0.8438\n",
            "Epoch 95/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.3614 - accuracy: 0.8542 - val_loss: 0.3673 - val_accuracy: 0.8687\n",
            "Epoch 96/200\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.3610 - accuracy: 0.8448 - val_loss: 0.3773 - val_accuracy: 0.8500\n",
            "Epoch 97/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.3673 - accuracy: 0.8354 - val_loss: 0.3497 - val_accuracy: 0.8750\n",
            "Epoch 98/200\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.3749 - accuracy: 0.8464 - val_loss: 0.3514 - val_accuracy: 0.8687\n",
            "Epoch 99/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.3724 - accuracy: 0.8417 - val_loss: 0.3713 - val_accuracy: 0.8500\n",
            "Epoch 100/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.3433 - accuracy: 0.8699 - val_loss: 0.3757 - val_accuracy: 0.8500\n",
            "Epoch 101/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.3615 - accuracy: 0.8589 - val_loss: 0.3859 - val_accuracy: 0.8562\n",
            "Epoch 102/200\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.3394 - accuracy: 0.8605 - val_loss: 0.3975 - val_accuracy: 0.8500\n",
            "Epoch 103/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.3697 - accuracy: 0.8495 - val_loss: 0.4223 - val_accuracy: 0.8375\n",
            "Epoch 104/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.3513 - accuracy: 0.8621 - val_loss: 0.3664 - val_accuracy: 0.8625\n",
            "Epoch 105/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.3596 - accuracy: 0.8495 - val_loss: 0.3454 - val_accuracy: 0.8750\n",
            "Epoch 106/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.3597 - accuracy: 0.8511 - val_loss: 0.3984 - val_accuracy: 0.8438\n",
            "Epoch 107/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.3503 - accuracy: 0.8574 - val_loss: 0.4516 - val_accuracy: 0.8000\n",
            "Epoch 108/200\n",
            "20/20 [==============================] - 0s 7ms/step - loss: 0.3728 - accuracy: 0.8589 - val_loss: 0.4173 - val_accuracy: 0.8313\n",
            "Epoch 109/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.3603 - accuracy: 0.8511 - val_loss: 0.3507 - val_accuracy: 0.8750\n",
            "Epoch 110/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.3243 - accuracy: 0.8668 - val_loss: 0.3679 - val_accuracy: 0.8687\n",
            "Epoch 111/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.3576 - accuracy: 0.8511 - val_loss: 0.4384 - val_accuracy: 0.8000\n",
            "Epoch 112/200\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.3314 - accuracy: 0.8574 - val_loss: 0.3977 - val_accuracy: 0.8250\n",
            "Epoch 113/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.3463 - accuracy: 0.8574 - val_loss: 0.4278 - val_accuracy: 0.8188\n",
            "Epoch 114/200\n",
            "20/20 [==============================] - 0s 6ms/step - loss: 0.3511 - accuracy: 0.8589 - val_loss: 0.4031 - val_accuracy: 0.8250\n",
            "Epoch 115/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.3391 - accuracy: 0.8683 - val_loss: 0.3449 - val_accuracy: 0.8625\n",
            "Epoch 116/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.3321 - accuracy: 0.8699 - val_loss: 0.3917 - val_accuracy: 0.8500\n",
            "Epoch 117/200\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.3434 - accuracy: 0.8589 - val_loss: 0.3554 - val_accuracy: 0.8687\n",
            "Epoch 118/200\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.3344 - accuracy: 0.8605 - val_loss: 0.4199 - val_accuracy: 0.8188\n",
            "Epoch 119/200\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.3352 - accuracy: 0.8668 - val_loss: 0.4675 - val_accuracy: 0.8125\n",
            "Epoch 120/200\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.3413 - accuracy: 0.8683 - val_loss: 0.3691 - val_accuracy: 0.8625\n",
            "Epoch 121/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.3345 - accuracy: 0.8589 - val_loss: 0.3755 - val_accuracy: 0.8562\n",
            "Epoch 122/200\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.3225 - accuracy: 0.8558 - val_loss: 0.3712 - val_accuracy: 0.8562\n",
            "Epoch 123/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.3333 - accuracy: 0.8652 - val_loss: 0.3984 - val_accuracy: 0.8313\n",
            "Epoch 124/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.3401 - accuracy: 0.8621 - val_loss: 0.3660 - val_accuracy: 0.8625\n",
            "Epoch 125/200\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.3136 - accuracy: 0.8793 - val_loss: 0.3401 - val_accuracy: 0.8750\n",
            "Epoch 126/200\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.3450 - accuracy: 0.8574 - val_loss: 0.4055 - val_accuracy: 0.8250\n",
            "Epoch 127/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.3308 - accuracy: 0.8574 - val_loss: 0.4084 - val_accuracy: 0.8188\n",
            "Epoch 128/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.3261 - accuracy: 0.8683 - val_loss: 0.3546 - val_accuracy: 0.8750\n",
            "Epoch 129/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.3157 - accuracy: 0.8715 - val_loss: 0.4186 - val_accuracy: 0.8188\n",
            "Epoch 130/200\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.3383 - accuracy: 0.8621 - val_loss: 0.3780 - val_accuracy: 0.8562\n",
            "Epoch 131/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.3145 - accuracy: 0.8809 - val_loss: 0.3717 - val_accuracy: 0.8625\n",
            "Epoch 132/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.3171 - accuracy: 0.8652 - val_loss: 0.4114 - val_accuracy: 0.8313\n",
            "Epoch 133/200\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.3363 - accuracy: 0.8715 - val_loss: 0.4261 - val_accuracy: 0.8062\n",
            "Epoch 134/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.3083 - accuracy: 0.8762 - val_loss: 0.3959 - val_accuracy: 0.8562\n",
            "Epoch 135/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.3181 - accuracy: 0.8636 - val_loss: 0.3535 - val_accuracy: 0.8750\n",
            "Epoch 136/200\n",
            "20/20 [==============================] - 0s 8ms/step - loss: 0.3137 - accuracy: 0.8777 - val_loss: 0.3793 - val_accuracy: 0.8687\n",
            "Epoch 137/200\n",
            "20/20 [==============================] - 0s 10ms/step - loss: 0.3329 - accuracy: 0.8621 - val_loss: 0.3486 - val_accuracy: 0.8687\n",
            "Epoch 138/200\n",
            "20/20 [==============================] - 0s 9ms/step - loss: 0.3013 - accuracy: 0.8715 - val_loss: 0.3849 - val_accuracy: 0.8500\n",
            "Epoch 139/200\n",
            "20/20 [==============================] - 0s 8ms/step - loss: 0.3288 - accuracy: 0.8668 - val_loss: 0.3754 - val_accuracy: 0.8438\n",
            "Epoch 140/200\n",
            "20/20 [==============================] - 0s 9ms/step - loss: 0.3132 - accuracy: 0.8793 - val_loss: 0.3411 - val_accuracy: 0.8813\n",
            "Epoch 141/200\n",
            "20/20 [==============================] - 0s 8ms/step - loss: 0.3122 - accuracy: 0.8636 - val_loss: 0.3931 - val_accuracy: 0.8313\n",
            "Epoch 142/200\n",
            "20/20 [==============================] - 0s 7ms/step - loss: 0.3225 - accuracy: 0.8777 - val_loss: 0.3877 - val_accuracy: 0.8313\n",
            "Epoch 143/200\n",
            "20/20 [==============================] - 0s 7ms/step - loss: 0.3302 - accuracy: 0.8574 - val_loss: 0.4324 - val_accuracy: 0.8062\n",
            "Epoch 144/200\n",
            "20/20 [==============================] - 0s 7ms/step - loss: 0.3138 - accuracy: 0.8762 - val_loss: 0.4264 - val_accuracy: 0.8125\n",
            "Epoch 145/200\n",
            "20/20 [==============================] - 0s 8ms/step - loss: 0.3155 - accuracy: 0.8715 - val_loss: 0.4113 - val_accuracy: 0.8375\n",
            "Epoch 146/200\n",
            "20/20 [==============================] - 0s 8ms/step - loss: 0.3236 - accuracy: 0.8683 - val_loss: 0.3522 - val_accuracy: 0.8750\n",
            "Epoch 147/200\n",
            "20/20 [==============================] - 0s 7ms/step - loss: 0.3132 - accuracy: 0.8762 - val_loss: 0.3856 - val_accuracy: 0.8562\n",
            "Epoch 148/200\n",
            "20/20 [==============================] - 0s 7ms/step - loss: 0.2954 - accuracy: 0.8840 - val_loss: 0.3825 - val_accuracy: 0.8375\n",
            "Epoch 149/200\n",
            "20/20 [==============================] - 0s 7ms/step - loss: 0.3182 - accuracy: 0.8777 - val_loss: 0.3683 - val_accuracy: 0.8687\n",
            "Epoch 150/200\n",
            "20/20 [==============================] - 0s 7ms/step - loss: 0.3352 - accuracy: 0.8746 - val_loss: 0.4045 - val_accuracy: 0.8313\n",
            "Epoch 151/200\n",
            "20/20 [==============================] - 0s 6ms/step - loss: 0.3162 - accuracy: 0.8730 - val_loss: 0.3640 - val_accuracy: 0.8500\n",
            "Epoch 152/200\n",
            "20/20 [==============================] - 0s 7ms/step - loss: 0.3068 - accuracy: 0.8762 - val_loss: 0.3693 - val_accuracy: 0.8687\n",
            "Epoch 153/200\n",
            "20/20 [==============================] - 0s 7ms/step - loss: 0.3056 - accuracy: 0.8730 - val_loss: 0.4085 - val_accuracy: 0.8188\n",
            "Epoch 154/200\n",
            "20/20 [==============================] - 0s 7ms/step - loss: 0.3152 - accuracy: 0.8746 - val_loss: 0.3589 - val_accuracy: 0.8687\n",
            "Epoch 155/200\n",
            "20/20 [==============================] - 0s 6ms/step - loss: 0.2834 - accuracy: 0.8887 - val_loss: 0.4606 - val_accuracy: 0.8062\n",
            "Epoch 156/200\n",
            "20/20 [==============================] - 0s 7ms/step - loss: 0.3304 - accuracy: 0.8558 - val_loss: 0.3725 - val_accuracy: 0.8562\n",
            "Epoch 157/200\n",
            "20/20 [==============================] - 0s 6ms/step - loss: 0.3216 - accuracy: 0.8636 - val_loss: 0.4223 - val_accuracy: 0.8125\n",
            "Epoch 158/200\n",
            "20/20 [==============================] - 0s 6ms/step - loss: 0.3120 - accuracy: 0.8699 - val_loss: 0.4011 - val_accuracy: 0.8250\n",
            "Epoch 159/200\n",
            "20/20 [==============================] - 0s 7ms/step - loss: 0.2994 - accuracy: 0.8699 - val_loss: 0.3618 - val_accuracy: 0.8687\n",
            "Epoch 160/200\n",
            "20/20 [==============================] - 0s 8ms/step - loss: 0.3116 - accuracy: 0.8683 - val_loss: 0.3653 - val_accuracy: 0.8687\n",
            "Epoch 161/200\n",
            "20/20 [==============================] - 0s 7ms/step - loss: 0.2986 - accuracy: 0.8809 - val_loss: 0.3625 - val_accuracy: 0.8813\n",
            "Epoch 162/200\n",
            "20/20 [==============================] - 0s 7ms/step - loss: 0.3110 - accuracy: 0.8699 - val_loss: 0.3624 - val_accuracy: 0.8750\n",
            "Epoch 163/200\n",
            "20/20 [==============================] - 0s 6ms/step - loss: 0.3118 - accuracy: 0.8715 - val_loss: 0.3953 - val_accuracy: 0.8250\n",
            "Epoch 164/200\n",
            "20/20 [==============================] - 0s 6ms/step - loss: 0.3122 - accuracy: 0.8683 - val_loss: 0.3957 - val_accuracy: 0.8188\n",
            "Epoch 165/200\n",
            "20/20 [==============================] - 0s 7ms/step - loss: 0.3009 - accuracy: 0.8809 - val_loss: 0.3794 - val_accuracy: 0.8500\n",
            "Epoch 166/200\n",
            "20/20 [==============================] - 0s 6ms/step - loss: 0.3056 - accuracy: 0.8809 - val_loss: 0.3781 - val_accuracy: 0.8562\n",
            "Epoch 167/200\n",
            "20/20 [==============================] - 0s 8ms/step - loss: 0.3060 - accuracy: 0.8777 - val_loss: 0.4080 - val_accuracy: 0.8375\n",
            "Epoch 168/200\n",
            "20/20 [==============================] - 0s 6ms/step - loss: 0.3052 - accuracy: 0.8668 - val_loss: 0.4084 - val_accuracy: 0.8375\n",
            "Epoch 169/200\n",
            "20/20 [==============================] - 0s 6ms/step - loss: 0.2829 - accuracy: 0.8840 - val_loss: 0.3783 - val_accuracy: 0.8500\n",
            "Epoch 170/200\n",
            "20/20 [==============================] - 0s 7ms/step - loss: 0.3101 - accuracy: 0.8746 - val_loss: 0.3688 - val_accuracy: 0.8562\n",
            "Epoch 171/200\n",
            "20/20 [==============================] - 0s 6ms/step - loss: 0.2976 - accuracy: 0.8918 - val_loss: 0.3862 - val_accuracy: 0.8438\n",
            "Epoch 172/200\n",
            "20/20 [==============================] - 0s 7ms/step - loss: 0.3119 - accuracy: 0.8699 - val_loss: 0.3785 - val_accuracy: 0.8562\n",
            "Epoch 173/200\n",
            "20/20 [==============================] - 0s 7ms/step - loss: 0.2973 - accuracy: 0.8730 - val_loss: 0.3782 - val_accuracy: 0.8500\n",
            "Epoch 174/200\n",
            "20/20 [==============================] - 0s 8ms/step - loss: 0.2913 - accuracy: 0.8777 - val_loss: 0.4115 - val_accuracy: 0.8562\n",
            "Epoch 175/200\n",
            "20/20 [==============================] - 0s 7ms/step - loss: 0.3109 - accuracy: 0.8636 - val_loss: 0.3713 - val_accuracy: 0.8625\n",
            "Epoch 176/200\n",
            "20/20 [==============================] - 0s 8ms/step - loss: 0.2931 - accuracy: 0.8840 - val_loss: 0.3932 - val_accuracy: 0.8500\n",
            "Epoch 177/200\n",
            "20/20 [==============================] - 0s 6ms/step - loss: 0.2887 - accuracy: 0.8809 - val_loss: 0.4636 - val_accuracy: 0.8188\n",
            "Epoch 178/200\n",
            "20/20 [==============================] - 0s 6ms/step - loss: 0.2917 - accuracy: 0.8793 - val_loss: 0.3898 - val_accuracy: 0.8250\n",
            "Epoch 179/200\n",
            "20/20 [==============================] - 0s 6ms/step - loss: 0.3024 - accuracy: 0.8746 - val_loss: 0.4099 - val_accuracy: 0.8313\n",
            "Epoch 180/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.3000 - accuracy: 0.8699 - val_loss: 0.3816 - val_accuracy: 0.8562\n",
            "Epoch 181/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.2919 - accuracy: 0.8887 - val_loss: 0.3769 - val_accuracy: 0.8375\n",
            "Epoch 182/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.3053 - accuracy: 0.8762 - val_loss: 0.3718 - val_accuracy: 0.8625\n",
            "Epoch 183/200\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.2936 - accuracy: 0.8762 - val_loss: 0.4131 - val_accuracy: 0.8313\n",
            "Epoch 184/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.2958 - accuracy: 0.8840 - val_loss: 0.3864 - val_accuracy: 0.8500\n",
            "Epoch 185/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.3032 - accuracy: 0.8730 - val_loss: 0.4296 - val_accuracy: 0.8250\n",
            "Epoch 186/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.3044 - accuracy: 0.8746 - val_loss: 0.4250 - val_accuracy: 0.8313\n",
            "Epoch 187/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.2781 - accuracy: 0.8871 - val_loss: 0.3714 - val_accuracy: 0.8750\n",
            "Epoch 188/200\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.2983 - accuracy: 0.8730 - val_loss: 0.3670 - val_accuracy: 0.8687\n",
            "Epoch 189/200\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.2899 - accuracy: 0.8793 - val_loss: 0.3845 - val_accuracy: 0.8625\n",
            "Epoch 190/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.3106 - accuracy: 0.8668 - val_loss: 0.4219 - val_accuracy: 0.8250\n",
            "Epoch 191/200\n",
            "20/20 [==============================] - 0s 6ms/step - loss: 0.3109 - accuracy: 0.8762 - val_loss: 0.3881 - val_accuracy: 0.8750\n",
            "Epoch 192/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.3091 - accuracy: 0.8699 - val_loss: 0.4251 - val_accuracy: 0.8438\n",
            "Epoch 193/200\n",
            "20/20 [==============================] - 0s 6ms/step - loss: 0.2812 - accuracy: 0.8856 - val_loss: 0.3902 - val_accuracy: 0.8562\n",
            "Epoch 194/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.2952 - accuracy: 0.8887 - val_loss: 0.3907 - val_accuracy: 0.8375\n",
            "Epoch 195/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.2906 - accuracy: 0.8856 - val_loss: 0.3549 - val_accuracy: 0.8875\n",
            "Epoch 196/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.3139 - accuracy: 0.8621 - val_loss: 0.4122 - val_accuracy: 0.8438\n",
            "Epoch 197/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.2931 - accuracy: 0.8840 - val_loss: 0.3989 - val_accuracy: 0.8687\n",
            "Epoch 198/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.2931 - accuracy: 0.8746 - val_loss: 0.3808 - val_accuracy: 0.8687\n",
            "Epoch 199/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.2845 - accuracy: 0.8730 - val_loss: 0.4172 - val_accuracy: 0.8375\n",
            "Epoch 200/200\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.2851 - accuracy: 0.8856 - val_loss: 0.3912 - val_accuracy: 0.8500\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.3890 - accuracy: 0.8500\n",
            "## evaluation loss and_metrics ##\n",
            "[0.38903892040252686, 0.8500000238418579]\n",
            "4/4 [==============================] - 0s 3ms/step\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0, 1, 1, 1, 0, 1, 1, 0, 1, 1, 0, 0, 0, 0, 1, 1, 0, 1, 1, 0, 1, 0,\n",
              "       0, 0, 1, 1, 0, 1, 0, 0, 1, 1, 0, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 0,\n",
              "       0, 0, 1, 1, 1, 0, 1, 0, 1, 1, 1, 0, 0, 1, 1, 1, 0, 0, 0, 1, 0, 1,\n",
              "       1, 1, 1, 1, 0, 0, 1, 1, 0, 1, 0, 1, 0, 1, 1, 1, 1, 0, 1, 1, 0, 1,\n",
              "       0, 0, 1, 1, 1, 0, 0, 0, 1, 0, 1, 1, 0, 1, 1, 0, 1, 1, 0, 1, 1, 0,\n",
              "       1, 1, 0, 1, 1, 0, 1, 0, 1, 0])"
            ]
          },
          "metadata": {},
          "execution_count": 69
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "np.mean(y_test == y_pred_classRestingBP)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "j72L0LljWKfa",
        "outputId": "fc70f896-e320-445b-ef65-bcbbe2e086cb"
      },
      "execution_count": 70,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.85"
            ]
          },
          "metadata": {},
          "execution_count": 70
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "RestingBP=recall_score(y_test,y_pred_classRestingBP)\n",
        "print(RestingBP)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FTyeapMhV_-6",
        "outputId": "ec57b5d2-b744-451d-a0de-74f57b1aa0ea"
      },
      "execution_count": 72,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.8857142857142857\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Cholesterol"
      ],
      "metadata": {
        "id": "syaIv2QcWpur"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "heart = pd.read_csv(f_path)\n",
        "\n",
        "heart = pd.get_dummies(heart)\n",
        "\n",
        "x = heart.drop('HeartDisease', axis=1)\n",
        "y = pd.get_dummies(heart[\"HeartDisease\"])\n",
        "\n",
        "heart['Cholesterol'] = 0\n",
        "\n",
        "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size = 0.13,shuffle=True, random_state = 42)\n",
        "\n",
        "print(\"X_train: \", x_train.shape)\n",
        "print(\"y_train: \", y_train.shape)\n",
        "\n",
        "print(\"X_test: \", x_test.shape)\n",
        "print(\"y_test: \", y_test.shape)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "ModelExceptCholesterol = Sequential()\n",
        "\n",
        "\n",
        "ModelExceptCholesterol.add(Dense(128, activation = \"relu\",input_dim=20))\n",
        "ModelExceptCholesterol.add(Dropout(rate=0.2))\n",
        "ModelExceptCholesterol.add(Dense(64, activation = \"relu\"))\n",
        "ModelExceptCholesterol.add(Dropout(rate=0.2))\n",
        "ModelExceptCholesterol.add(Dense(32, activation = \"relu\"))\n",
        "ModelExceptCholesterol.add(Dropout(rate=0.1))\n",
        "ModelExceptCholesterol.add(Dense(16, activation = \"relu\"))\n",
        "ModelExceptCholesterol.add(Dense(8, activation = \"relu\"))\n",
        "ModelExceptCholesterol.add(Dense(2, activation = \"sigmoid\"))\n",
        "\n",
        "ModelExceptCholesterol.compile(optimizer = \"adam\", loss = \"categorical_crossentropy\", metrics = [\"accuracy\"])\n",
        "ModelExceptCholesterol.summary()\n",
        "\n",
        "hin=ModelExceptCholesterol.fit(x_train,y_train,epochs=200, validation_split=0.2)\n",
        "\n",
        "loss_and_metrics = ModelExceptCholesterol.evaluate(x_test, y_test, batch_size=32)\n",
        "print('## evaluation loss and_metrics ##')\n",
        "print(loss_and_metrics)\n",
        "\n",
        "y_predCholesterol = ModelExceptCholesterol.predict(x_test)\n",
        "y_predCholesterol\n",
        "\n",
        "y_pred_classCholesterol = np.argmax(y_predCholesterol, axis=1)\n",
        "y_pred_classCholesterol\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "y_test  = y_test.to_numpy()\n",
        "y_test\n",
        "\n",
        "y_test = np.argmax(y_test,axis=1)\n",
        "y_test\n",
        "\n"
      ],
      "metadata": {
        "id": "V57JspM-WqNr",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6e5f84dd-f962-41e1-95b7-7a3e5fde6d18"
      },
      "execution_count": 73,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "X_train:  (798, 20)\n",
            "y_train:  (798, 2)\n",
            "X_test:  (120, 20)\n",
            "y_test:  (120, 2)\n",
            "Model: \"sequential_7\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense_42 (Dense)            (None, 128)               2688      \n",
            "                                                                 \n",
            " dropout_21 (Dropout)        (None, 128)               0         \n",
            "                                                                 \n",
            " dense_43 (Dense)            (None, 64)                8256      \n",
            "                                                                 \n",
            " dropout_22 (Dropout)        (None, 64)                0         \n",
            "                                                                 \n",
            " dense_44 (Dense)            (None, 32)                2080      \n",
            "                                                                 \n",
            " dropout_23 (Dropout)        (None, 32)                0         \n",
            "                                                                 \n",
            " dense_45 (Dense)            (None, 16)                528       \n",
            "                                                                 \n",
            " dense_46 (Dense)            (None, 8)                 136       \n",
            "                                                                 \n",
            " dense_47 (Dense)            (None, 2)                 18        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 13,706\n",
            "Trainable params: 13,706\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/200\n",
            "20/20 [==============================] - 1s 12ms/step - loss: 1.3513 - accuracy: 0.5627 - val_loss: 0.7116 - val_accuracy: 0.4125\n",
            "Epoch 2/200\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.7387 - accuracy: 0.5549 - val_loss: 0.6167 - val_accuracy: 0.6750\n",
            "Epoch 3/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.6791 - accuracy: 0.5533 - val_loss: 0.6165 - val_accuracy: 0.6750\n",
            "Epoch 4/200\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.6761 - accuracy: 0.5486 - val_loss: 0.6167 - val_accuracy: 0.6750\n",
            "Epoch 5/200\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.6477 - accuracy: 0.5737 - val_loss: 0.6181 - val_accuracy: 0.6750\n",
            "Epoch 6/200\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.6799 - accuracy: 0.5611 - val_loss: 0.6180 - val_accuracy: 0.6750\n",
            "Epoch 7/200\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.6734 - accuracy: 0.5752 - val_loss: 0.6181 - val_accuracy: 0.6750\n",
            "Epoch 8/200\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.6685 - accuracy: 0.5643 - val_loss: 0.6193 - val_accuracy: 0.6750\n",
            "Epoch 9/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.6494 - accuracy: 0.5564 - val_loss: 0.6200 - val_accuracy: 0.6750\n",
            "Epoch 10/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.6523 - accuracy: 0.5502 - val_loss: 0.6189 - val_accuracy: 0.4938\n",
            "Epoch 11/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.6499 - accuracy: 0.5721 - val_loss: 0.6192 - val_accuracy: 0.4938\n",
            "Epoch 12/200\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.6509 - accuracy: 0.5658 - val_loss: 0.6203 - val_accuracy: 0.4938\n",
            "Epoch 13/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.6575 - accuracy: 0.5752 - val_loss: 0.6205 - val_accuracy: 0.4938\n",
            "Epoch 14/200\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.6416 - accuracy: 0.5831 - val_loss: 0.6223 - val_accuracy: 0.5000\n",
            "Epoch 15/200\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.6350 - accuracy: 0.5784 - val_loss: 0.6213 - val_accuracy: 0.5125\n",
            "Epoch 16/200\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.6365 - accuracy: 0.6050 - val_loss: 0.6036 - val_accuracy: 0.7250\n",
            "Epoch 17/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.6451 - accuracy: 0.5909 - val_loss: 0.6227 - val_accuracy: 0.5063\n",
            "Epoch 18/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.6430 - accuracy: 0.6066 - val_loss: 0.6206 - val_accuracy: 0.5250\n",
            "Epoch 19/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.6433 - accuracy: 0.5815 - val_loss: 0.6205 - val_accuracy: 0.6000\n",
            "Epoch 20/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.6454 - accuracy: 0.6113 - val_loss: 0.6210 - val_accuracy: 0.6125\n",
            "Epoch 21/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.6300 - accuracy: 0.6191 - val_loss: 0.6151 - val_accuracy: 0.5750\n",
            "Epoch 22/200\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.6262 - accuracy: 0.6223 - val_loss: 0.5834 - val_accuracy: 0.7188\n",
            "Epoch 23/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.6305 - accuracy: 0.6552 - val_loss: 0.5902 - val_accuracy: 0.7000\n",
            "Epoch 24/200\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.6093 - accuracy: 0.6567 - val_loss: 0.5953 - val_accuracy: 0.6938\n",
            "Epoch 25/200\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.6207 - accuracy: 0.6520 - val_loss: 0.5800 - val_accuracy: 0.7125\n",
            "Epoch 26/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.6193 - accuracy: 0.6536 - val_loss: 0.5843 - val_accuracy: 0.7188\n",
            "Epoch 27/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.6197 - accuracy: 0.6270 - val_loss: 0.5683 - val_accuracy: 0.7250\n",
            "Epoch 28/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.6206 - accuracy: 0.6661 - val_loss: 0.5780 - val_accuracy: 0.7188\n",
            "Epoch 29/200\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.6358 - accuracy: 0.6301 - val_loss: 0.5787 - val_accuracy: 0.7437\n",
            "Epoch 30/200\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.6130 - accuracy: 0.6818 - val_loss: 0.5663 - val_accuracy: 0.7500\n",
            "Epoch 31/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.6142 - accuracy: 0.6614 - val_loss: 0.5710 - val_accuracy: 0.6375\n",
            "Epoch 32/200\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.6173 - accuracy: 0.6881 - val_loss: 0.5380 - val_accuracy: 0.7375\n",
            "Epoch 33/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.5887 - accuracy: 0.7085 - val_loss: 0.5638 - val_accuracy: 0.6938\n",
            "Epoch 34/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.5855 - accuracy: 0.6693 - val_loss: 0.5319 - val_accuracy: 0.7625\n",
            "Epoch 35/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.5753 - accuracy: 0.6865 - val_loss: 0.5814 - val_accuracy: 0.6187\n",
            "Epoch 36/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.5700 - accuracy: 0.6912 - val_loss: 0.5205 - val_accuracy: 0.7563\n",
            "Epoch 37/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.5619 - accuracy: 0.7163 - val_loss: 0.5132 - val_accuracy: 0.7625\n",
            "Epoch 38/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.5610 - accuracy: 0.7132 - val_loss: 0.5392 - val_accuracy: 0.6875\n",
            "Epoch 39/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.5675 - accuracy: 0.7257 - val_loss: 0.4951 - val_accuracy: 0.7812\n",
            "Epoch 40/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.5779 - accuracy: 0.7100 - val_loss: 0.5278 - val_accuracy: 0.7312\n",
            "Epoch 41/200\n",
            "20/20 [==============================] - 0s 6ms/step - loss: 0.5391 - accuracy: 0.7320 - val_loss: 0.4950 - val_accuracy: 0.7812\n",
            "Epoch 42/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.5533 - accuracy: 0.7100 - val_loss: 0.5440 - val_accuracy: 0.7000\n",
            "Epoch 43/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.5486 - accuracy: 0.7335 - val_loss: 0.5144 - val_accuracy: 0.7500\n",
            "Epoch 44/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.5270 - accuracy: 0.7445 - val_loss: 0.5060 - val_accuracy: 0.7500\n",
            "Epoch 45/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.5347 - accuracy: 0.7555 - val_loss: 0.4891 - val_accuracy: 0.8000\n",
            "Epoch 46/200\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.5149 - accuracy: 0.7524 - val_loss: 0.4896 - val_accuracy: 0.7875\n",
            "Epoch 47/200\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.5222 - accuracy: 0.7696 - val_loss: 0.4771 - val_accuracy: 0.7875\n",
            "Epoch 48/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.5079 - accuracy: 0.7649 - val_loss: 0.5016 - val_accuracy: 0.7625\n",
            "Epoch 49/200\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.5173 - accuracy: 0.7680 - val_loss: 0.4648 - val_accuracy: 0.8062\n",
            "Epoch 50/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.5204 - accuracy: 0.7492 - val_loss: 0.4947 - val_accuracy: 0.7937\n",
            "Epoch 51/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.5042 - accuracy: 0.7900 - val_loss: 0.5019 - val_accuracy: 0.7812\n",
            "Epoch 52/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.5114 - accuracy: 0.7727 - val_loss: 0.4676 - val_accuracy: 0.8062\n",
            "Epoch 53/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.4820 - accuracy: 0.7790 - val_loss: 0.4922 - val_accuracy: 0.7812\n",
            "Epoch 54/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.4640 - accuracy: 0.8009 - val_loss: 0.4698 - val_accuracy: 0.8000\n",
            "Epoch 55/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.4793 - accuracy: 0.7900 - val_loss: 0.4662 - val_accuracy: 0.8125\n",
            "Epoch 56/200\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.4726 - accuracy: 0.7900 - val_loss: 0.4527 - val_accuracy: 0.8125\n",
            "Epoch 57/200\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.4695 - accuracy: 0.7900 - val_loss: 0.4702 - val_accuracy: 0.7937\n",
            "Epoch 58/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.4632 - accuracy: 0.7947 - val_loss: 0.4542 - val_accuracy: 0.8000\n",
            "Epoch 59/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.4516 - accuracy: 0.8103 - val_loss: 0.4400 - val_accuracy: 0.8000\n",
            "Epoch 60/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.4837 - accuracy: 0.7947 - val_loss: 0.5166 - val_accuracy: 0.7375\n",
            "Epoch 61/200\n",
            "20/20 [==============================] - 0s 6ms/step - loss: 0.4825 - accuracy: 0.7884 - val_loss: 0.4576 - val_accuracy: 0.7875\n",
            "Epoch 62/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.4612 - accuracy: 0.8041 - val_loss: 0.4710 - val_accuracy: 0.7812\n",
            "Epoch 63/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.4652 - accuracy: 0.8009 - val_loss: 0.4304 - val_accuracy: 0.8438\n",
            "Epoch 64/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.4294 - accuracy: 0.8119 - val_loss: 0.4270 - val_accuracy: 0.8313\n",
            "Epoch 65/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.4476 - accuracy: 0.8197 - val_loss: 0.4487 - val_accuracy: 0.8000\n",
            "Epoch 66/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.4441 - accuracy: 0.8182 - val_loss: 0.4872 - val_accuracy: 0.7875\n",
            "Epoch 67/200\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.4469 - accuracy: 0.8103 - val_loss: 0.4333 - val_accuracy: 0.8188\n",
            "Epoch 68/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.4356 - accuracy: 0.8323 - val_loss: 0.4214 - val_accuracy: 0.8313\n",
            "Epoch 69/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.4220 - accuracy: 0.8292 - val_loss: 0.4427 - val_accuracy: 0.8250\n",
            "Epoch 70/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.4239 - accuracy: 0.8229 - val_loss: 0.3916 - val_accuracy: 0.8438\n",
            "Epoch 71/200\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.4196 - accuracy: 0.8166 - val_loss: 0.4130 - val_accuracy: 0.8438\n",
            "Epoch 72/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.4223 - accuracy: 0.8229 - val_loss: 0.3968 - val_accuracy: 0.8438\n",
            "Epoch 73/200\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.4195 - accuracy: 0.8339 - val_loss: 0.3914 - val_accuracy: 0.8500\n",
            "Epoch 74/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.4076 - accuracy: 0.8339 - val_loss: 0.4057 - val_accuracy: 0.8375\n",
            "Epoch 75/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.4044 - accuracy: 0.8292 - val_loss: 0.4739 - val_accuracy: 0.7937\n",
            "Epoch 76/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.3887 - accuracy: 0.8417 - val_loss: 0.4288 - val_accuracy: 0.8375\n",
            "Epoch 77/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.4208 - accuracy: 0.8307 - val_loss: 0.4294 - val_accuracy: 0.8375\n",
            "Epoch 78/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.4054 - accuracy: 0.8370 - val_loss: 0.3756 - val_accuracy: 0.8500\n",
            "Epoch 79/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.3865 - accuracy: 0.8480 - val_loss: 0.3880 - val_accuracy: 0.8562\n",
            "Epoch 80/200\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.3727 - accuracy: 0.8558 - val_loss: 0.3637 - val_accuracy: 0.8625\n",
            "Epoch 81/200\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.3691 - accuracy: 0.8511 - val_loss: 0.3629 - val_accuracy: 0.8625\n",
            "Epoch 82/200\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.3777 - accuracy: 0.8542 - val_loss: 0.3898 - val_accuracy: 0.8500\n",
            "Epoch 83/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.3716 - accuracy: 0.8511 - val_loss: 0.3975 - val_accuracy: 0.8375\n",
            "Epoch 84/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.3770 - accuracy: 0.8527 - val_loss: 0.3966 - val_accuracy: 0.8500\n",
            "Epoch 85/200\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.3641 - accuracy: 0.8542 - val_loss: 0.4109 - val_accuracy: 0.8313\n",
            "Epoch 86/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.3622 - accuracy: 0.8464 - val_loss: 0.3967 - val_accuracy: 0.8438\n",
            "Epoch 87/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.3725 - accuracy: 0.8511 - val_loss: 0.3628 - val_accuracy: 0.8625\n",
            "Epoch 88/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.3576 - accuracy: 0.8433 - val_loss: 0.3861 - val_accuracy: 0.8500\n",
            "Epoch 89/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.3607 - accuracy: 0.8542 - val_loss: 0.3523 - val_accuracy: 0.8813\n",
            "Epoch 90/200\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.3577 - accuracy: 0.8480 - val_loss: 0.3620 - val_accuracy: 0.8625\n",
            "Epoch 91/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.3696 - accuracy: 0.8401 - val_loss: 0.3517 - val_accuracy: 0.8813\n",
            "Epoch 92/200\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.3715 - accuracy: 0.8417 - val_loss: 0.4125 - val_accuracy: 0.8313\n",
            "Epoch 93/200\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.3541 - accuracy: 0.8605 - val_loss: 0.3642 - val_accuracy: 0.8562\n",
            "Epoch 94/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.3388 - accuracy: 0.8652 - val_loss: 0.3432 - val_accuracy: 0.8687\n",
            "Epoch 95/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.3622 - accuracy: 0.8621 - val_loss: 0.3799 - val_accuracy: 0.8500\n",
            "Epoch 96/200\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.3345 - accuracy: 0.8746 - val_loss: 0.3477 - val_accuracy: 0.8687\n",
            "Epoch 97/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.3450 - accuracy: 0.8652 - val_loss: 0.3550 - val_accuracy: 0.8687\n",
            "Epoch 98/200\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.3815 - accuracy: 0.8433 - val_loss: 0.3511 - val_accuracy: 0.8750\n",
            "Epoch 99/200\n",
            "20/20 [==============================] - 0s 6ms/step - loss: 0.3551 - accuracy: 0.8652 - val_loss: 0.3573 - val_accuracy: 0.8750\n",
            "Epoch 100/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.3403 - accuracy: 0.8668 - val_loss: 0.4328 - val_accuracy: 0.8188\n",
            "Epoch 101/200\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.3454 - accuracy: 0.8589 - val_loss: 0.3661 - val_accuracy: 0.8500\n",
            "Epoch 102/200\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.3196 - accuracy: 0.8683 - val_loss: 0.4264 - val_accuracy: 0.8313\n",
            "Epoch 103/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.3337 - accuracy: 0.8683 - val_loss: 0.3584 - val_accuracy: 0.8625\n",
            "Epoch 104/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.3421 - accuracy: 0.8668 - val_loss: 0.3660 - val_accuracy: 0.8625\n",
            "Epoch 105/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.3411 - accuracy: 0.8652 - val_loss: 0.3557 - val_accuracy: 0.8625\n",
            "Epoch 106/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.3346 - accuracy: 0.8652 - val_loss: 0.3598 - val_accuracy: 0.8625\n",
            "Epoch 107/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.3236 - accuracy: 0.8746 - val_loss: 0.3676 - val_accuracy: 0.8562\n",
            "Epoch 108/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.3452 - accuracy: 0.8730 - val_loss: 0.3436 - val_accuracy: 0.8750\n",
            "Epoch 109/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.3505 - accuracy: 0.8558 - val_loss: 0.3535 - val_accuracy: 0.8750\n",
            "Epoch 110/200\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.3254 - accuracy: 0.8558 - val_loss: 0.3769 - val_accuracy: 0.8562\n",
            "Epoch 111/200\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.3327 - accuracy: 0.8699 - val_loss: 0.3634 - val_accuracy: 0.8750\n",
            "Epoch 112/200\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.3255 - accuracy: 0.8683 - val_loss: 0.3750 - val_accuracy: 0.8562\n",
            "Epoch 113/200\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.3426 - accuracy: 0.8730 - val_loss: 0.3818 - val_accuracy: 0.8562\n",
            "Epoch 114/200\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.3274 - accuracy: 0.8871 - val_loss: 0.3525 - val_accuracy: 0.8687\n",
            "Epoch 115/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.3321 - accuracy: 0.8542 - val_loss: 0.3569 - val_accuracy: 0.8687\n",
            "Epoch 116/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.3385 - accuracy: 0.8589 - val_loss: 0.3586 - val_accuracy: 0.8687\n",
            "Epoch 117/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.3187 - accuracy: 0.8699 - val_loss: 0.3700 - val_accuracy: 0.8562\n",
            "Epoch 118/200\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.3264 - accuracy: 0.8668 - val_loss: 0.4008 - val_accuracy: 0.8313\n",
            "Epoch 119/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.3106 - accuracy: 0.8746 - val_loss: 0.3526 - val_accuracy: 0.8813\n",
            "Epoch 120/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.3090 - accuracy: 0.8824 - val_loss: 0.3933 - val_accuracy: 0.8438\n",
            "Epoch 121/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.3174 - accuracy: 0.8777 - val_loss: 0.4387 - val_accuracy: 0.8000\n",
            "Epoch 122/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.3302 - accuracy: 0.8777 - val_loss: 0.3648 - val_accuracy: 0.8687\n",
            "Epoch 123/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.3106 - accuracy: 0.8809 - val_loss: 0.3692 - val_accuracy: 0.8562\n",
            "Epoch 124/200\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.3065 - accuracy: 0.8793 - val_loss: 0.3996 - val_accuracy: 0.8313\n",
            "Epoch 125/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.3144 - accuracy: 0.8746 - val_loss: 0.3713 - val_accuracy: 0.8438\n",
            "Epoch 126/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.3212 - accuracy: 0.8683 - val_loss: 0.3680 - val_accuracy: 0.8687\n",
            "Epoch 127/200\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.3268 - accuracy: 0.8730 - val_loss: 0.4120 - val_accuracy: 0.8313\n",
            "Epoch 128/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.3242 - accuracy: 0.8793 - val_loss: 0.3698 - val_accuracy: 0.8625\n",
            "Epoch 129/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.3098 - accuracy: 0.8762 - val_loss: 0.3878 - val_accuracy: 0.8562\n",
            "Epoch 130/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.2962 - accuracy: 0.8746 - val_loss: 0.3693 - val_accuracy: 0.8750\n",
            "Epoch 131/200\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.3273 - accuracy: 0.8824 - val_loss: 0.3917 - val_accuracy: 0.8313\n",
            "Epoch 132/200\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.3094 - accuracy: 0.8856 - val_loss: 0.3599 - val_accuracy: 0.8625\n",
            "Epoch 133/200\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.3179 - accuracy: 0.8636 - val_loss: 0.3428 - val_accuracy: 0.8813\n",
            "Epoch 134/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.3268 - accuracy: 0.8730 - val_loss: 0.3608 - val_accuracy: 0.8687\n",
            "Epoch 135/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.3082 - accuracy: 0.8746 - val_loss: 0.3577 - val_accuracy: 0.8562\n",
            "Epoch 136/200\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.3073 - accuracy: 0.8777 - val_loss: 0.3991 - val_accuracy: 0.8250\n",
            "Epoch 137/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.3296 - accuracy: 0.8683 - val_loss: 0.3943 - val_accuracy: 0.8375\n",
            "Epoch 138/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.3150 - accuracy: 0.8668 - val_loss: 0.4304 - val_accuracy: 0.8062\n",
            "Epoch 139/200\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.3194 - accuracy: 0.8652 - val_loss: 0.3658 - val_accuracy: 0.8500\n",
            "Epoch 140/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.3007 - accuracy: 0.8856 - val_loss: 0.3878 - val_accuracy: 0.8438\n",
            "Epoch 141/200\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.3183 - accuracy: 0.8668 - val_loss: 0.3750 - val_accuracy: 0.8500\n",
            "Epoch 142/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.3142 - accuracy: 0.8793 - val_loss: 0.4452 - val_accuracy: 0.8062\n",
            "Epoch 143/200\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.2987 - accuracy: 0.8840 - val_loss: 0.3718 - val_accuracy: 0.8438\n",
            "Epoch 144/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.3060 - accuracy: 0.8793 - val_loss: 0.3935 - val_accuracy: 0.8125\n",
            "Epoch 145/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.2980 - accuracy: 0.8824 - val_loss: 0.4045 - val_accuracy: 0.8062\n",
            "Epoch 146/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.2971 - accuracy: 0.8824 - val_loss: 0.4188 - val_accuracy: 0.8125\n",
            "Epoch 147/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.3235 - accuracy: 0.8699 - val_loss: 0.4148 - val_accuracy: 0.8125\n",
            "Epoch 148/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.3058 - accuracy: 0.8746 - val_loss: 0.3527 - val_accuracy: 0.8750\n",
            "Epoch 149/200\n",
            "20/20 [==============================] - 0s 6ms/step - loss: 0.3079 - accuracy: 0.8777 - val_loss: 0.3703 - val_accuracy: 0.8625\n",
            "Epoch 150/200\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.3027 - accuracy: 0.8683 - val_loss: 0.3921 - val_accuracy: 0.8375\n",
            "Epoch 151/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.2991 - accuracy: 0.8856 - val_loss: 0.4007 - val_accuracy: 0.8375\n",
            "Epoch 152/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.3039 - accuracy: 0.8762 - val_loss: 0.4257 - val_accuracy: 0.8188\n",
            "Epoch 153/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.3148 - accuracy: 0.8621 - val_loss: 0.4254 - val_accuracy: 0.8250\n",
            "Epoch 154/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.3062 - accuracy: 0.8715 - val_loss: 0.4382 - val_accuracy: 0.8062\n",
            "Epoch 155/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.3146 - accuracy: 0.8605 - val_loss: 0.3925 - val_accuracy: 0.8313\n",
            "Epoch 156/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.3026 - accuracy: 0.8777 - val_loss: 0.3651 - val_accuracy: 0.8562\n",
            "Epoch 157/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.2974 - accuracy: 0.8809 - val_loss: 0.3793 - val_accuracy: 0.8438\n",
            "Epoch 158/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.2966 - accuracy: 0.8793 - val_loss: 0.4195 - val_accuracy: 0.8188\n",
            "Epoch 159/200\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.3010 - accuracy: 0.8668 - val_loss: 0.4507 - val_accuracy: 0.7812\n",
            "Epoch 160/200\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.2939 - accuracy: 0.8793 - val_loss: 0.3930 - val_accuracy: 0.8250\n",
            "Epoch 161/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.2895 - accuracy: 0.8809 - val_loss: 0.3777 - val_accuracy: 0.8438\n",
            "Epoch 162/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.2924 - accuracy: 0.8840 - val_loss: 0.3917 - val_accuracy: 0.8500\n",
            "Epoch 163/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.3128 - accuracy: 0.8762 - val_loss: 0.3547 - val_accuracy: 0.8687\n",
            "Epoch 164/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.2830 - accuracy: 0.8840 - val_loss: 0.4276 - val_accuracy: 0.8313\n",
            "Epoch 165/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.2979 - accuracy: 0.8840 - val_loss: 0.3759 - val_accuracy: 0.8438\n",
            "Epoch 166/200\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.3016 - accuracy: 0.8777 - val_loss: 0.4216 - val_accuracy: 0.8313\n",
            "Epoch 167/200\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.2865 - accuracy: 0.8903 - val_loss: 0.4108 - val_accuracy: 0.8500\n",
            "Epoch 168/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.2863 - accuracy: 0.8809 - val_loss: 0.3523 - val_accuracy: 0.8750\n",
            "Epoch 169/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.2761 - accuracy: 0.8950 - val_loss: 0.4084 - val_accuracy: 0.8375\n",
            "Epoch 170/200\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.2879 - accuracy: 0.8746 - val_loss: 0.3805 - val_accuracy: 0.8625\n",
            "Epoch 171/200\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.3070 - accuracy: 0.8746 - val_loss: 0.3580 - val_accuracy: 0.8562\n",
            "Epoch 172/200\n",
            "20/20 [==============================] - 0s 6ms/step - loss: 0.2969 - accuracy: 0.8668 - val_loss: 0.3796 - val_accuracy: 0.8500\n",
            "Epoch 173/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.2837 - accuracy: 0.8746 - val_loss: 0.3773 - val_accuracy: 0.8813\n",
            "Epoch 174/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.2935 - accuracy: 0.8746 - val_loss: 0.4235 - val_accuracy: 0.8250\n",
            "Epoch 175/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.3035 - accuracy: 0.8809 - val_loss: 0.4424 - val_accuracy: 0.8125\n",
            "Epoch 176/200\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.2777 - accuracy: 0.8934 - val_loss: 0.3925 - val_accuracy: 0.8438\n",
            "Epoch 177/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.2896 - accuracy: 0.8683 - val_loss: 0.3890 - val_accuracy: 0.8687\n",
            "Epoch 178/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.3012 - accuracy: 0.8824 - val_loss: 0.4031 - val_accuracy: 0.8313\n",
            "Epoch 179/200\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.2951 - accuracy: 0.8746 - val_loss: 0.4457 - val_accuracy: 0.8188\n",
            "Epoch 180/200\n",
            "20/20 [==============================] - 0s 6ms/step - loss: 0.2936 - accuracy: 0.8762 - val_loss: 0.3566 - val_accuracy: 0.8625\n",
            "Epoch 181/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.2873 - accuracy: 0.8762 - val_loss: 0.3543 - val_accuracy: 0.8813\n",
            "Epoch 182/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.3015 - accuracy: 0.8746 - val_loss: 0.3939 - val_accuracy: 0.8375\n",
            "Epoch 183/200\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.2831 - accuracy: 0.8793 - val_loss: 0.4067 - val_accuracy: 0.8313\n",
            "Epoch 184/200\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.2921 - accuracy: 0.8746 - val_loss: 0.3878 - val_accuracy: 0.8313\n",
            "Epoch 185/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.2801 - accuracy: 0.8918 - val_loss: 0.4057 - val_accuracy: 0.8313\n",
            "Epoch 186/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.2875 - accuracy: 0.8762 - val_loss: 0.4032 - val_accuracy: 0.8562\n",
            "Epoch 187/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.2833 - accuracy: 0.8824 - val_loss: 0.3831 - val_accuracy: 0.8500\n",
            "Epoch 188/200\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.2700 - accuracy: 0.8856 - val_loss: 0.4099 - val_accuracy: 0.8250\n",
            "Epoch 189/200\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.2602 - accuracy: 0.8887 - val_loss: 0.3603 - val_accuracy: 0.8750\n",
            "Epoch 190/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.2831 - accuracy: 0.8762 - val_loss: 0.4209 - val_accuracy: 0.8313\n",
            "Epoch 191/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.2831 - accuracy: 0.8793 - val_loss: 0.3814 - val_accuracy: 0.8562\n",
            "Epoch 192/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.2811 - accuracy: 0.8903 - val_loss: 0.3794 - val_accuracy: 0.8750\n",
            "Epoch 193/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.2771 - accuracy: 0.8918 - val_loss: 0.3896 - val_accuracy: 0.8562\n",
            "Epoch 194/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.2769 - accuracy: 0.8918 - val_loss: 0.3737 - val_accuracy: 0.8813\n",
            "Epoch 195/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.2852 - accuracy: 0.8777 - val_loss: 0.4242 - val_accuracy: 0.8313\n",
            "Epoch 196/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.2772 - accuracy: 0.8793 - val_loss: 0.4180 - val_accuracy: 0.8188\n",
            "Epoch 197/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.2797 - accuracy: 0.8824 - val_loss: 0.4035 - val_accuracy: 0.8438\n",
            "Epoch 198/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.2801 - accuracy: 0.8809 - val_loss: 0.3636 - val_accuracy: 0.8813\n",
            "Epoch 199/200\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.2894 - accuracy: 0.8715 - val_loss: 0.3945 - val_accuracy: 0.8687\n",
            "Epoch 200/200\n",
            "20/20 [==============================] - 0s 6ms/step - loss: 0.2834 - accuracy: 0.8793 - val_loss: 0.4156 - val_accuracy: 0.8562\n",
            "4/4 [==============================] - 0s 8ms/step - loss: 0.4109 - accuracy: 0.8500\n",
            "## evaluation loss and_metrics ##\n",
            "[0.4109276533126831, 0.8500000238418579]\n",
            "4/4 [==============================] - 0s 3ms/step\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0, 1, 1, 1, 0, 1, 1, 0, 1, 1, 0, 0, 0, 0, 1, 1, 0, 1, 1, 0, 1, 0,\n",
              "       0, 0, 1, 1, 0, 1, 0, 0, 1, 1, 0, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 0,\n",
              "       0, 0, 1, 1, 1, 0, 1, 0, 1, 1, 1, 0, 0, 1, 1, 1, 0, 0, 0, 1, 0, 1,\n",
              "       1, 1, 1, 1, 0, 0, 1, 1, 0, 1, 0, 1, 0, 1, 1, 1, 1, 0, 1, 1, 0, 1,\n",
              "       0, 0, 1, 1, 1, 0, 0, 0, 1, 0, 1, 1, 0, 1, 1, 0, 1, 1, 0, 1, 1, 0,\n",
              "       1, 1, 0, 1, 1, 0, 1, 0, 1, 0])"
            ]
          },
          "metadata": {},
          "execution_count": 73
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "np.mean(y_test == y_pred_classCholesterol)"
      ],
      "metadata": {
        "id": "UUQUyL_RXErk",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5d0058b6-9b04-419d-a3fb-a7ea43d4727e"
      },
      "execution_count": 74,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.85"
            ]
          },
          "metadata": {},
          "execution_count": 74
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "Cholesterolscore=recall_score(y_test,y_pred_classCholesterol)\n",
        "print(Cholesterolscore)"
      ],
      "metadata": {
        "id": "1kOl15oCXGKI",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b5fb849b-58f4-4482-f6df-6ad7e06fcc35"
      },
      "execution_count": 75,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.9\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "FastingBS"
      ],
      "metadata": {
        "id": "pDZwbQXVXKuf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "heart = pd.read_csv(f_path)\n",
        "\n",
        "heart = pd.get_dummies(heart)\n",
        "\n",
        "x = heart.drop('HeartDisease', axis=1)\n",
        "y = pd.get_dummies(heart[\"HeartDisease\"])\n",
        "\n",
        "heart['FastingBS'] = 0\n",
        "\n",
        "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size = 0.13,shuffle=True, random_state = 42)\n",
        "\n",
        "print(\"X_train: \", x_train.shape)\n",
        "print(\"y_train: \", y_train.shape)\n",
        "\n",
        "print(\"X_test: \", x_test.shape)\n",
        "print(\"y_test: \", y_test.shape)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "ModelExceptFastingBS = Sequential()\n",
        "\n",
        "\n",
        "ModelExceptFastingBS.add(Dense(128, activation = \"relu\",input_dim=20))\n",
        "ModelExceptFastingBS.add(Dropout(rate=0.2))\n",
        "ModelExceptFastingBS.add(Dense(64, activation = \"relu\"))\n",
        "ModelExceptFastingBS.add(Dropout(rate=0.2))\n",
        "ModelExceptFastingBS.add(Dense(32, activation = \"relu\"))\n",
        "ModelExceptFastingBS.add(Dropout(rate=0.1))\n",
        "ModelExceptFastingBS.add(Dense(16, activation = \"relu\"))\n",
        "ModelExceptFastingBS.add(Dense(8, activation = \"relu\"))\n",
        "ModelExceptFastingBS.add(Dense(2, activation = \"sigmoid\"))\n",
        "\n",
        "ModelExceptFastingBS.compile(optimizer = \"adam\", loss = \"categorical_crossentropy\", metrics = [\"accuracy\"])\n",
        "ModelExceptFastingBS.summary()\n",
        "\n",
        "hin=ModelExceptFastingBS.fit(x_train,y_train,epochs=200, validation_split=0.2)\n",
        "\n",
        "loss_and_metrics = ModelExceptFastingBS.evaluate(x_test, y_test, batch_size=32)\n",
        "print('## evaluation loss and_metrics ##')\n",
        "print(loss_and_metrics)\n",
        "\n",
        "y_predFastingBS = ModelExceptFastingBS.predict(x_test)\n",
        "y_predFastingBS\n",
        "\n",
        "y_pred_classFastingBS = np.argmax(y_predFastingBS, axis=1)\n",
        "y_pred_classFastingBS\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "y_test  = y_test.to_numpy()\n",
        "y_test\n",
        "\n",
        "y_test = np.argmax(y_test,axis=1)\n",
        "y_test\n",
        "\n"
      ],
      "metadata": {
        "id": "T5Nvn3l5X7lJ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "928e92e9-cff6-4d06-c4ba-1cd5b72b5596"
      },
      "execution_count": 76,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "X_train:  (798, 20)\n",
            "y_train:  (798, 2)\n",
            "X_test:  (120, 20)\n",
            "y_test:  (120, 2)\n",
            "Model: \"sequential_8\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense_48 (Dense)            (None, 128)               2688      \n",
            "                                                                 \n",
            " dropout_24 (Dropout)        (None, 128)               0         \n",
            "                                                                 \n",
            " dense_49 (Dense)            (None, 64)                8256      \n",
            "                                                                 \n",
            " dropout_25 (Dropout)        (None, 64)                0         \n",
            "                                                                 \n",
            " dense_50 (Dense)            (None, 32)                2080      \n",
            "                                                                 \n",
            " dropout_26 (Dropout)        (None, 32)                0         \n",
            "                                                                 \n",
            " dense_51 (Dense)            (None, 16)                528       \n",
            "                                                                 \n",
            " dense_52 (Dense)            (None, 8)                 136       \n",
            "                                                                 \n",
            " dense_53 (Dense)            (None, 2)                 18        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 13,706\n",
            "Trainable params: 13,706\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/200\n",
            "20/20 [==============================] - 1s 13ms/step - loss: 2.9580 - accuracy: 0.5125 - val_loss: 1.0912 - val_accuracy: 0.4938\n",
            "Epoch 2/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 1.1583 - accuracy: 0.5455 - val_loss: 0.6510 - val_accuracy: 0.6125\n",
            "Epoch 3/200\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.7980 - accuracy: 0.5157 - val_loss: 0.6837 - val_accuracy: 0.4437\n",
            "Epoch 4/200\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.7500 - accuracy: 0.5188 - val_loss: 0.6863 - val_accuracy: 0.4250\n",
            "Epoch 5/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.7021 - accuracy: 0.5470 - val_loss: 0.6506 - val_accuracy: 0.4938\n",
            "Epoch 6/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.7033 - accuracy: 0.5674 - val_loss: 0.6539 - val_accuracy: 0.4938\n",
            "Epoch 7/200\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.6914 - accuracy: 0.5047 - val_loss: 0.6929 - val_accuracy: 0.4125\n",
            "Epoch 8/200\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.7012 - accuracy: 0.5266 - val_loss: 0.6816 - val_accuracy: 0.4313\n",
            "Epoch 9/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.6748 - accuracy: 0.5627 - val_loss: 0.6414 - val_accuracy: 0.4938\n",
            "Epoch 10/200\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.6835 - accuracy: 0.5627 - val_loss: 0.6345 - val_accuracy: 0.5000\n",
            "Epoch 11/200\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.6875 - accuracy: 0.5658 - val_loss: 0.6328 - val_accuracy: 0.5000\n",
            "Epoch 12/200\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.7000 - accuracy: 0.5313 - val_loss: 0.6335 - val_accuracy: 0.4938\n",
            "Epoch 13/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.6672 - accuracy: 0.5705 - val_loss: 0.6345 - val_accuracy: 0.4938\n",
            "Epoch 14/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.6694 - accuracy: 0.5376 - val_loss: 0.6306 - val_accuracy: 0.4938\n",
            "Epoch 15/200\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.6557 - accuracy: 0.5643 - val_loss: 0.6314 - val_accuracy: 0.4938\n",
            "Epoch 16/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.6502 - accuracy: 0.5533 - val_loss: 0.6268 - val_accuracy: 0.5000\n",
            "Epoch 17/200\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.6812 - accuracy: 0.5768 - val_loss: 0.6261 - val_accuracy: 0.4938\n",
            "Epoch 18/200\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.6643 - accuracy: 0.5502 - val_loss: 0.6240 - val_accuracy: 0.5000\n",
            "Epoch 19/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.6443 - accuracy: 0.5799 - val_loss: 0.6267 - val_accuracy: 0.4875\n",
            "Epoch 20/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.6582 - accuracy: 0.5799 - val_loss: 0.6292 - val_accuracy: 0.4938\n",
            "Epoch 21/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.6582 - accuracy: 0.5674 - val_loss: 0.6343 - val_accuracy: 0.4938\n",
            "Epoch 22/200\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.6623 - accuracy: 0.5705 - val_loss: 0.6303 - val_accuracy: 0.4938\n",
            "Epoch 23/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.6553 - accuracy: 0.5611 - val_loss: 0.6264 - val_accuracy: 0.5000\n",
            "Epoch 24/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.6424 - accuracy: 0.5925 - val_loss: 0.6307 - val_accuracy: 0.5000\n",
            "Epoch 25/200\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.6656 - accuracy: 0.5564 - val_loss: 0.6234 - val_accuracy: 0.4938\n",
            "Epoch 26/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.6550 - accuracy: 0.6019 - val_loss: 0.6239 - val_accuracy: 0.4938\n",
            "Epoch 27/200\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.6563 - accuracy: 0.5627 - val_loss: 0.6273 - val_accuracy: 0.4938\n",
            "Epoch 28/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.6656 - accuracy: 0.5674 - val_loss: 0.6245 - val_accuracy: 0.4938\n",
            "Epoch 29/200\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.6450 - accuracy: 0.6003 - val_loss: 0.6269 - val_accuracy: 0.4938\n",
            "Epoch 30/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.6573 - accuracy: 0.5831 - val_loss: 0.6333 - val_accuracy: 0.4938\n",
            "Epoch 31/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.6515 - accuracy: 0.5549 - val_loss: 0.6550 - val_accuracy: 0.5000\n",
            "Epoch 32/200\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.6429 - accuracy: 0.5423 - val_loss: 0.6252 - val_accuracy: 0.5000\n",
            "Epoch 33/200\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.6495 - accuracy: 0.5956 - val_loss: 0.6254 - val_accuracy: 0.5000\n",
            "Epoch 34/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.6546 - accuracy: 0.5533 - val_loss: 0.6239 - val_accuracy: 0.4938\n",
            "Epoch 35/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.6446 - accuracy: 0.5831 - val_loss: 0.6247 - val_accuracy: 0.4938\n",
            "Epoch 36/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.6512 - accuracy: 0.5674 - val_loss: 0.6265 - val_accuracy: 0.4812\n",
            "Epoch 37/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.6473 - accuracy: 0.5392 - val_loss: 0.6297 - val_accuracy: 0.4938\n",
            "Epoch 38/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.6471 - accuracy: 0.5408 - val_loss: 0.6288 - val_accuracy: 0.5000\n",
            "Epoch 39/200\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.6425 - accuracy: 0.5784 - val_loss: 0.6290 - val_accuracy: 0.5000\n",
            "Epoch 40/200\n",
            "20/20 [==============================] - 0s 6ms/step - loss: 0.6551 - accuracy: 0.5893 - val_loss: 0.6275 - val_accuracy: 0.4938\n",
            "Epoch 41/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.6336 - accuracy: 0.5846 - val_loss: 0.6283 - val_accuracy: 0.5000\n",
            "Epoch 42/200\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.6540 - accuracy: 0.5580 - val_loss: 0.6203 - val_accuracy: 0.4938\n",
            "Epoch 43/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.6447 - accuracy: 0.5956 - val_loss: 0.6207 - val_accuracy: 0.4938\n",
            "Epoch 44/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.6455 - accuracy: 0.5940 - val_loss: 0.6208 - val_accuracy: 0.4938\n",
            "Epoch 45/200\n",
            "20/20 [==============================] - 0s 6ms/step - loss: 0.6386 - accuracy: 0.6003 - val_loss: 0.6207 - val_accuracy: 0.4938\n",
            "Epoch 46/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.6483 - accuracy: 0.5831 - val_loss: 0.6206 - val_accuracy: 0.4938\n",
            "Epoch 47/200\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.6404 - accuracy: 0.5862 - val_loss: 0.6181 - val_accuracy: 0.5688\n",
            "Epoch 48/200\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.6477 - accuracy: 0.5784 - val_loss: 0.6194 - val_accuracy: 0.5312\n",
            "Epoch 49/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.6408 - accuracy: 0.5799 - val_loss: 0.6174 - val_accuracy: 0.6062\n",
            "Epoch 50/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.6329 - accuracy: 0.6207 - val_loss: 0.6157 - val_accuracy: 0.6500\n",
            "Epoch 51/200\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.6388 - accuracy: 0.5784 - val_loss: 0.6133 - val_accuracy: 0.7250\n",
            "Epoch 52/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.6396 - accuracy: 0.6082 - val_loss: 0.6007 - val_accuracy: 0.6812\n",
            "Epoch 53/200\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.6392 - accuracy: 0.5862 - val_loss: 0.6057 - val_accuracy: 0.7000\n",
            "Epoch 54/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.6503 - accuracy: 0.6144 - val_loss: 0.6187 - val_accuracy: 0.7563\n",
            "Epoch 55/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.6414 - accuracy: 0.5815 - val_loss: 0.6078 - val_accuracy: 0.7625\n",
            "Epoch 56/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.6405 - accuracy: 0.6066 - val_loss: 0.6093 - val_accuracy: 0.7750\n",
            "Epoch 57/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.6541 - accuracy: 0.6113 - val_loss: 0.6121 - val_accuracy: 0.7500\n",
            "Epoch 58/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.6406 - accuracy: 0.5972 - val_loss: 0.6062 - val_accuracy: 0.7937\n",
            "Epoch 59/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.6395 - accuracy: 0.6191 - val_loss: 0.6026 - val_accuracy: 0.7937\n",
            "Epoch 60/200\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.6334 - accuracy: 0.6066 - val_loss: 0.6011 - val_accuracy: 0.7750\n",
            "Epoch 61/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.6217 - accuracy: 0.6379 - val_loss: 0.5877 - val_accuracy: 0.7625\n",
            "Epoch 62/200\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.6285 - accuracy: 0.6254 - val_loss: 0.6056 - val_accuracy: 0.6250\n",
            "Epoch 63/200\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.6162 - accuracy: 0.6348 - val_loss: 0.5941 - val_accuracy: 0.7188\n",
            "Epoch 64/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.6148 - accuracy: 0.6599 - val_loss: 0.5752 - val_accuracy: 0.7437\n",
            "Epoch 65/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.6137 - accuracy: 0.6708 - val_loss: 0.5951 - val_accuracy: 0.6750\n",
            "Epoch 66/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.6305 - accuracy: 0.6552 - val_loss: 0.5558 - val_accuracy: 0.7625\n",
            "Epoch 67/200\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.6014 - accuracy: 0.6928 - val_loss: 0.5565 - val_accuracy: 0.7812\n",
            "Epoch 68/200\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.6143 - accuracy: 0.6865 - val_loss: 0.6005 - val_accuracy: 0.6375\n",
            "Epoch 69/200\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.5983 - accuracy: 0.6928 - val_loss: 0.5466 - val_accuracy: 0.7563\n",
            "Epoch 70/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.5900 - accuracy: 0.6787 - val_loss: 0.5479 - val_accuracy: 0.7500\n",
            "Epoch 71/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.5769 - accuracy: 0.7100 - val_loss: 0.5706 - val_accuracy: 0.7000\n",
            "Epoch 72/200\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.5817 - accuracy: 0.7038 - val_loss: 0.5151 - val_accuracy: 0.7750\n",
            "Epoch 73/200\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.6042 - accuracy: 0.6865 - val_loss: 0.5232 - val_accuracy: 0.7688\n",
            "Epoch 74/200\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.5532 - accuracy: 0.7492 - val_loss: 0.5608 - val_accuracy: 0.7000\n",
            "Epoch 75/200\n",
            "20/20 [==============================] - 0s 6ms/step - loss: 0.5818 - accuracy: 0.6865 - val_loss: 0.5002 - val_accuracy: 0.7688\n",
            "Epoch 76/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.5440 - accuracy: 0.7335 - val_loss: 0.5300 - val_accuracy: 0.7312\n",
            "Epoch 77/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.5574 - accuracy: 0.7226 - val_loss: 0.5306 - val_accuracy: 0.7437\n",
            "Epoch 78/200\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.5406 - accuracy: 0.7320 - val_loss: 0.5001 - val_accuracy: 0.8125\n",
            "Epoch 79/200\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.5382 - accuracy: 0.7461 - val_loss: 0.5214 - val_accuracy: 0.7375\n",
            "Epoch 80/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.5568 - accuracy: 0.7320 - val_loss: 0.5101 - val_accuracy: 0.7750\n",
            "Epoch 81/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.5331 - accuracy: 0.7429 - val_loss: 0.5023 - val_accuracy: 0.7937\n",
            "Epoch 82/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.5144 - accuracy: 0.7602 - val_loss: 0.4741 - val_accuracy: 0.7937\n",
            "Epoch 83/200\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.5290 - accuracy: 0.7806 - val_loss: 0.4668 - val_accuracy: 0.8000\n",
            "Epoch 84/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.5354 - accuracy: 0.7398 - val_loss: 0.4882 - val_accuracy: 0.7812\n",
            "Epoch 85/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.5108 - accuracy: 0.7743 - val_loss: 0.4718 - val_accuracy: 0.8125\n",
            "Epoch 86/200\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.5161 - accuracy: 0.7743 - val_loss: 0.5124 - val_accuracy: 0.7500\n",
            "Epoch 87/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.5077 - accuracy: 0.7837 - val_loss: 0.4655 - val_accuracy: 0.8062\n",
            "Epoch 88/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.5172 - accuracy: 0.7743 - val_loss: 0.5034 - val_accuracy: 0.7688\n",
            "Epoch 89/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.5072 - accuracy: 0.7727 - val_loss: 0.4885 - val_accuracy: 0.7750\n",
            "Epoch 90/200\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.4960 - accuracy: 0.7774 - val_loss: 0.4607 - val_accuracy: 0.8062\n",
            "Epoch 91/200\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.5044 - accuracy: 0.7774 - val_loss: 0.4520 - val_accuracy: 0.8438\n",
            "Epoch 92/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.4882 - accuracy: 0.7900 - val_loss: 0.4446 - val_accuracy: 0.8250\n",
            "Epoch 93/200\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.5037 - accuracy: 0.7962 - val_loss: 0.4472 - val_accuracy: 0.8125\n",
            "Epoch 94/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.4868 - accuracy: 0.7868 - val_loss: 0.5250 - val_accuracy: 0.7250\n",
            "Epoch 95/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.4868 - accuracy: 0.7806 - val_loss: 0.4345 - val_accuracy: 0.8438\n",
            "Epoch 96/200\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.4718 - accuracy: 0.7821 - val_loss: 0.4302 - val_accuracy: 0.8438\n",
            "Epoch 97/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.4864 - accuracy: 0.7868 - val_loss: 0.4390 - val_accuracy: 0.8438\n",
            "Epoch 98/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.4712 - accuracy: 0.7806 - val_loss: 0.4600 - val_accuracy: 0.7937\n",
            "Epoch 99/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.4656 - accuracy: 0.8025 - val_loss: 0.4494 - val_accuracy: 0.7875\n",
            "Epoch 100/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.4659 - accuracy: 0.8088 - val_loss: 0.4360 - val_accuracy: 0.8188\n",
            "Epoch 101/200\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.4477 - accuracy: 0.8056 - val_loss: 0.5059 - val_accuracy: 0.7750\n",
            "Epoch 102/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.4568 - accuracy: 0.8009 - val_loss: 0.4659 - val_accuracy: 0.7875\n",
            "Epoch 103/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.4413 - accuracy: 0.8182 - val_loss: 0.4235 - val_accuracy: 0.8438\n",
            "Epoch 104/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.4360 - accuracy: 0.7994 - val_loss: 0.4606 - val_accuracy: 0.7937\n",
            "Epoch 105/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.4496 - accuracy: 0.7962 - val_loss: 0.4243 - val_accuracy: 0.8250\n",
            "Epoch 106/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.4433 - accuracy: 0.8135 - val_loss: 0.4199 - val_accuracy: 0.8250\n",
            "Epoch 107/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.4237 - accuracy: 0.8150 - val_loss: 0.4198 - val_accuracy: 0.8313\n",
            "Epoch 108/200\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.4464 - accuracy: 0.8182 - val_loss: 0.4542 - val_accuracy: 0.8062\n",
            "Epoch 109/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.4262 - accuracy: 0.8135 - val_loss: 0.4104 - val_accuracy: 0.8375\n",
            "Epoch 110/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.4325 - accuracy: 0.8229 - val_loss: 0.4308 - val_accuracy: 0.8438\n",
            "Epoch 111/200\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.4123 - accuracy: 0.8354 - val_loss: 0.4039 - val_accuracy: 0.8313\n",
            "Epoch 112/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.4097 - accuracy: 0.8323 - val_loss: 0.4046 - val_accuracy: 0.8375\n",
            "Epoch 113/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.4030 - accuracy: 0.8417 - val_loss: 0.4381 - val_accuracy: 0.8250\n",
            "Epoch 114/200\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.3959 - accuracy: 0.8464 - val_loss: 0.4134 - val_accuracy: 0.8375\n",
            "Epoch 115/200\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.3931 - accuracy: 0.8511 - val_loss: 0.4320 - val_accuracy: 0.8313\n",
            "Epoch 116/200\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.4192 - accuracy: 0.8292 - val_loss: 0.3936 - val_accuracy: 0.8438\n",
            "Epoch 117/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.4019 - accuracy: 0.8401 - val_loss: 0.3788 - val_accuracy: 0.8562\n",
            "Epoch 118/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.3993 - accuracy: 0.8511 - val_loss: 0.3983 - val_accuracy: 0.8438\n",
            "Epoch 119/200\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.3777 - accuracy: 0.8433 - val_loss: 0.4040 - val_accuracy: 0.8375\n",
            "Epoch 120/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.3885 - accuracy: 0.8495 - val_loss: 0.4329 - val_accuracy: 0.8125\n",
            "Epoch 121/200\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.3617 - accuracy: 0.8448 - val_loss: 0.3684 - val_accuracy: 0.8562\n",
            "Epoch 122/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.3635 - accuracy: 0.8386 - val_loss: 0.4197 - val_accuracy: 0.8125\n",
            "Epoch 123/200\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.3586 - accuracy: 0.8464 - val_loss: 0.3932 - val_accuracy: 0.8375\n",
            "Epoch 124/200\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.3858 - accuracy: 0.8417 - val_loss: 0.4751 - val_accuracy: 0.8000\n",
            "Epoch 125/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.3935 - accuracy: 0.8417 - val_loss: 0.4155 - val_accuracy: 0.8313\n",
            "Epoch 126/200\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.3656 - accuracy: 0.8511 - val_loss: 0.3593 - val_accuracy: 0.8687\n",
            "Epoch 127/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.3646 - accuracy: 0.8589 - val_loss: 0.4404 - val_accuracy: 0.8125\n",
            "Epoch 128/200\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.3682 - accuracy: 0.8574 - val_loss: 0.4112 - val_accuracy: 0.8313\n",
            "Epoch 129/200\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.3549 - accuracy: 0.8574 - val_loss: 0.4121 - val_accuracy: 0.8375\n",
            "Epoch 130/200\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.3615 - accuracy: 0.8542 - val_loss: 0.4046 - val_accuracy: 0.8375\n",
            "Epoch 131/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.3595 - accuracy: 0.8558 - val_loss: 0.3657 - val_accuracy: 0.8625\n",
            "Epoch 132/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.3460 - accuracy: 0.8589 - val_loss: 0.4280 - val_accuracy: 0.8250\n",
            "Epoch 133/200\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.3661 - accuracy: 0.8464 - val_loss: 0.3862 - val_accuracy: 0.8438\n",
            "Epoch 134/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.3732 - accuracy: 0.8464 - val_loss: 0.4489 - val_accuracy: 0.8000\n",
            "Epoch 135/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.3615 - accuracy: 0.8495 - val_loss: 0.4255 - val_accuracy: 0.8250\n",
            "Epoch 136/200\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.3475 - accuracy: 0.8652 - val_loss: 0.3951 - val_accuracy: 0.8375\n",
            "Epoch 137/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.3596 - accuracy: 0.8621 - val_loss: 0.3601 - val_accuracy: 0.8687\n",
            "Epoch 138/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.3679 - accuracy: 0.8511 - val_loss: 0.3589 - val_accuracy: 0.8687\n",
            "Epoch 139/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.3578 - accuracy: 0.8668 - val_loss: 0.3981 - val_accuracy: 0.8438\n",
            "Epoch 140/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.3621 - accuracy: 0.8558 - val_loss: 0.3763 - val_accuracy: 0.8438\n",
            "Epoch 141/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.3423 - accuracy: 0.8589 - val_loss: 0.3891 - val_accuracy: 0.8375\n",
            "Epoch 142/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.3346 - accuracy: 0.8668 - val_loss: 0.3882 - val_accuracy: 0.8438\n",
            "Epoch 143/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.3356 - accuracy: 0.8605 - val_loss: 0.4062 - val_accuracy: 0.8375\n",
            "Epoch 144/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.3363 - accuracy: 0.8746 - val_loss: 0.3456 - val_accuracy: 0.8813\n",
            "Epoch 145/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.3677 - accuracy: 0.8511 - val_loss: 0.3735 - val_accuracy: 0.8562\n",
            "Epoch 146/200\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.3531 - accuracy: 0.8652 - val_loss: 0.4075 - val_accuracy: 0.8250\n",
            "Epoch 147/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.3538 - accuracy: 0.8636 - val_loss: 0.3881 - val_accuracy: 0.8438\n",
            "Epoch 148/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.3314 - accuracy: 0.8730 - val_loss: 0.4123 - val_accuracy: 0.8250\n",
            "Epoch 149/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.3269 - accuracy: 0.8793 - val_loss: 0.4255 - val_accuracy: 0.8188\n",
            "Epoch 150/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.3290 - accuracy: 0.8715 - val_loss: 0.3697 - val_accuracy: 0.8500\n",
            "Epoch 151/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.3310 - accuracy: 0.8777 - val_loss: 0.3697 - val_accuracy: 0.8625\n",
            "Epoch 152/200\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.3554 - accuracy: 0.8668 - val_loss: 0.3824 - val_accuracy: 0.8562\n",
            "Epoch 153/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.3439 - accuracy: 0.8636 - val_loss: 0.3573 - val_accuracy: 0.8687\n",
            "Epoch 154/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.3122 - accuracy: 0.8856 - val_loss: 0.3825 - val_accuracy: 0.8687\n",
            "Epoch 155/200\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.3198 - accuracy: 0.8699 - val_loss: 0.4299 - val_accuracy: 0.8313\n",
            "Epoch 156/200\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.3283 - accuracy: 0.8668 - val_loss: 0.3914 - val_accuracy: 0.8313\n",
            "Epoch 157/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.3394 - accuracy: 0.8605 - val_loss: 0.3812 - val_accuracy: 0.8625\n",
            "Epoch 158/200\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.3360 - accuracy: 0.8636 - val_loss: 0.3583 - val_accuracy: 0.8750\n",
            "Epoch 159/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.3439 - accuracy: 0.8636 - val_loss: 0.4474 - val_accuracy: 0.8188\n",
            "Epoch 160/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.3413 - accuracy: 0.8621 - val_loss: 0.3933 - val_accuracy: 0.8562\n",
            "Epoch 161/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.3301 - accuracy: 0.8668 - val_loss: 0.3661 - val_accuracy: 0.8562\n",
            "Epoch 162/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.3436 - accuracy: 0.8699 - val_loss: 0.3805 - val_accuracy: 0.8500\n",
            "Epoch 163/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.3400 - accuracy: 0.8636 - val_loss: 0.4201 - val_accuracy: 0.8250\n",
            "Epoch 164/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.3373 - accuracy: 0.8668 - val_loss: 0.4197 - val_accuracy: 0.8125\n",
            "Epoch 165/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.3182 - accuracy: 0.8699 - val_loss: 0.3749 - val_accuracy: 0.8625\n",
            "Epoch 166/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.3270 - accuracy: 0.8730 - val_loss: 0.3523 - val_accuracy: 0.8687\n",
            "Epoch 167/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.3348 - accuracy: 0.8652 - val_loss: 0.3843 - val_accuracy: 0.8375\n",
            "Epoch 168/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.3208 - accuracy: 0.8746 - val_loss: 0.3716 - val_accuracy: 0.8562\n",
            "Epoch 169/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.3057 - accuracy: 0.8824 - val_loss: 0.3896 - val_accuracy: 0.8250\n",
            "Epoch 170/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.3121 - accuracy: 0.8746 - val_loss: 0.3801 - val_accuracy: 0.8562\n",
            "Epoch 171/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.3198 - accuracy: 0.8621 - val_loss: 0.3616 - val_accuracy: 0.8687\n",
            "Epoch 172/200\n",
            "20/20 [==============================] - 0s 6ms/step - loss: 0.3314 - accuracy: 0.8730 - val_loss: 0.3919 - val_accuracy: 0.8313\n",
            "Epoch 173/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.3328 - accuracy: 0.8652 - val_loss: 0.4117 - val_accuracy: 0.8313\n",
            "Epoch 174/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.3142 - accuracy: 0.8730 - val_loss: 0.3775 - val_accuracy: 0.8500\n",
            "Epoch 175/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.3039 - accuracy: 0.8824 - val_loss: 0.3705 - val_accuracy: 0.8687\n",
            "Epoch 176/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.3208 - accuracy: 0.8668 - val_loss: 0.3865 - val_accuracy: 0.8375\n",
            "Epoch 177/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.3137 - accuracy: 0.8715 - val_loss: 0.3772 - val_accuracy: 0.8500\n",
            "Epoch 178/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.3052 - accuracy: 0.8809 - val_loss: 0.3972 - val_accuracy: 0.8438\n",
            "Epoch 179/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.3170 - accuracy: 0.8809 - val_loss: 0.3643 - val_accuracy: 0.8500\n",
            "Epoch 180/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.3205 - accuracy: 0.8699 - val_loss: 0.3924 - val_accuracy: 0.8375\n",
            "Epoch 181/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.3160 - accuracy: 0.8683 - val_loss: 0.3891 - val_accuracy: 0.8438\n",
            "Epoch 182/200\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.3138 - accuracy: 0.8777 - val_loss: 0.3934 - val_accuracy: 0.8250\n",
            "Epoch 183/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.3093 - accuracy: 0.8715 - val_loss: 0.3579 - val_accuracy: 0.8625\n",
            "Epoch 184/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.3110 - accuracy: 0.8762 - val_loss: 0.3975 - val_accuracy: 0.8250\n",
            "Epoch 185/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.3170 - accuracy: 0.8793 - val_loss: 0.3842 - val_accuracy: 0.8250\n",
            "Epoch 186/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.3233 - accuracy: 0.8668 - val_loss: 0.3909 - val_accuracy: 0.8250\n",
            "Epoch 187/200\n",
            "20/20 [==============================] - 0s 6ms/step - loss: 0.3081 - accuracy: 0.8903 - val_loss: 0.3640 - val_accuracy: 0.8500\n",
            "Epoch 188/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.2999 - accuracy: 0.8824 - val_loss: 0.3922 - val_accuracy: 0.8250\n",
            "Epoch 189/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.3322 - accuracy: 0.8762 - val_loss: 0.4164 - val_accuracy: 0.8188\n",
            "Epoch 190/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.3129 - accuracy: 0.8762 - val_loss: 0.4136 - val_accuracy: 0.8125\n",
            "Epoch 191/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.3029 - accuracy: 0.8715 - val_loss: 0.3952 - val_accuracy: 0.8313\n",
            "Epoch 192/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.3043 - accuracy: 0.8777 - val_loss: 0.4129 - val_accuracy: 0.8313\n",
            "Epoch 193/200\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.3016 - accuracy: 0.8824 - val_loss: 0.4076 - val_accuracy: 0.8313\n",
            "Epoch 194/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.3007 - accuracy: 0.8746 - val_loss: 0.3830 - val_accuracy: 0.8375\n",
            "Epoch 195/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.3061 - accuracy: 0.8762 - val_loss: 0.3953 - val_accuracy: 0.8313\n",
            "Epoch 196/200\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.3221 - accuracy: 0.8652 - val_loss: 0.4486 - val_accuracy: 0.8125\n",
            "Epoch 197/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.3162 - accuracy: 0.8824 - val_loss: 0.4029 - val_accuracy: 0.8375\n",
            "Epoch 198/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.3064 - accuracy: 0.8856 - val_loss: 0.3778 - val_accuracy: 0.8562\n",
            "Epoch 199/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.3163 - accuracy: 0.8746 - val_loss: 0.4008 - val_accuracy: 0.8313\n",
            "Epoch 200/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.2901 - accuracy: 0.8762 - val_loss: 0.3482 - val_accuracy: 0.8813\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.3722 - accuracy: 0.8500\n",
            "## evaluation loss and_metrics ##\n",
            "[0.3721942901611328, 0.8500000238418579]\n",
            "4/4 [==============================] - 0s 4ms/step\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0, 1, 1, 1, 0, 1, 1, 0, 1, 1, 0, 0, 0, 0, 1, 1, 0, 1, 1, 0, 1, 0,\n",
              "       0, 0, 1, 1, 0, 1, 0, 0, 1, 1, 0, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 0,\n",
              "       0, 0, 1, 1, 1, 0, 1, 0, 1, 1, 1, 0, 0, 1, 1, 1, 0, 0, 0, 1, 0, 1,\n",
              "       1, 1, 1, 1, 0, 0, 1, 1, 0, 1, 0, 1, 0, 1, 1, 1, 1, 0, 1, 1, 0, 1,\n",
              "       0, 0, 1, 1, 1, 0, 0, 0, 1, 0, 1, 1, 0, 1, 1, 0, 1, 1, 0, 1, 1, 0,\n",
              "       1, 1, 0, 1, 1, 0, 1, 0, 1, 0])"
            ]
          },
          "metadata": {},
          "execution_count": 76
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "np.mean(y_test == y_pred_classCholesterol)"
      ],
      "metadata": {
        "id": "NY7Co3WrX9th",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "04cb9059-26e9-4a0c-f54d-63f413b63e23"
      },
      "execution_count": 77,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.85"
            ]
          },
          "metadata": {},
          "execution_count": 77
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "FastingBSscore=recall_score(y_test,y_pred_classFastingBS)\n",
        "print(FastingBSscore)"
      ],
      "metadata": {
        "id": "zQM03_q_X96u",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a6df8b8e-f302-4518-b32d-ef4d8d9a6d1b"
      },
      "execution_count": 78,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.8714285714285714\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "MaxHR"
      ],
      "metadata": {
        "id": "HG-5BvPphNG6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "heart = pd.read_csv(f_path)\n",
        "\n",
        "heart = pd.get_dummies(heart)\n",
        "\n",
        "x = heart.drop('HeartDisease', axis=1)\n",
        "y = pd.get_dummies(heart[\"HeartDisease\"])\n",
        "\n",
        "heart['MaxHR'] = 0\n",
        "\n",
        "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size = 0.13,shuffle=True, random_state = 42)\n",
        "\n",
        "print(\"X_train: \", x_train.shape)\n",
        "print(\"y_train: \", y_train.shape)\n",
        "\n",
        "print(\"X_test: \", x_test.shape)\n",
        "print(\"y_test: \", y_test.shape)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "ModelExceptMaxHR = Sequential()\n",
        "\n",
        "\n",
        "ModelExceptMaxHR.add(Dense(128, activation = \"relu\",input_dim=20))\n",
        "ModelExceptMaxHR.add(Dropout(rate=0.2))\n",
        "ModelExceptMaxHR.add(Dense(64, activation = \"relu\"))\n",
        "ModelExceptMaxHR.add(Dropout(rate=0.2))\n",
        "ModelExceptMaxHR.add(Dense(32, activation = \"relu\"))\n",
        "ModelExceptMaxHR.add(Dropout(rate=0.1))\n",
        "ModelExceptMaxHR.add(Dense(16, activation = \"relu\"))\n",
        "ModelExceptMaxHR.add(Dense(8, activation = \"relu\"))\n",
        "ModelExceptMaxHR.add(Dense(2, activation = \"sigmoid\"))\n",
        "\n",
        "ModelExceptMaxHR.compile(optimizer = \"adam\", loss = \"categorical_crossentropy\", metrics = [\"accuracy\"])\n",
        "ModelExceptMaxHR.summary()\n",
        "\n",
        "hin=ModelExceptMaxHR.fit(x_train,y_train,epochs=200, validation_split=0.2)\n",
        "\n",
        "loss_and_metrics = ModelExceptMaxHR.evaluate(x_test, y_test, batch_size=32)\n",
        "print('## evaluation loss and_metrics ##')\n",
        "print(loss_and_metrics)\n",
        "\n",
        "y_predMaxHR = ModelExceptMaxHR.predict(x_test)\n",
        "y_predMaxHR\n",
        "\n",
        "y_pred_classMaxHR = np.argmax(y_predMaxHR, axis=1)\n",
        "y_pred_classMaxHR\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "y_test  = y_test.to_numpy()\n",
        "y_test\n",
        "\n",
        "y_test = np.argmax(y_test,axis=1)\n",
        "y_test\n",
        "\n"
      ],
      "metadata": {
        "id": "83f1SNiMhKbX",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "29e3009f-e705-426e-d04c-eabd0606c90a"
      },
      "execution_count": 79,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "X_train:  (798, 20)\n",
            "y_train:  (798, 2)\n",
            "X_test:  (120, 20)\n",
            "y_test:  (120, 2)\n",
            "Model: \"sequential_9\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense_54 (Dense)            (None, 128)               2688      \n",
            "                                                                 \n",
            " dropout_27 (Dropout)        (None, 128)               0         \n",
            "                                                                 \n",
            " dense_55 (Dense)            (None, 64)                8256      \n",
            "                                                                 \n",
            " dropout_28 (Dropout)        (None, 64)                0         \n",
            "                                                                 \n",
            " dense_56 (Dense)            (None, 32)                2080      \n",
            "                                                                 \n",
            " dropout_29 (Dropout)        (None, 32)                0         \n",
            "                                                                 \n",
            " dense_57 (Dense)            (None, 16)                528       \n",
            "                                                                 \n",
            " dense_58 (Dense)            (None, 8)                 136       \n",
            "                                                                 \n",
            " dense_59 (Dense)            (None, 2)                 18        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 13,706\n",
            "Trainable params: 13,706\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/200\n",
            "20/20 [==============================] - 1s 12ms/step - loss: 4.4875 - accuracy: 0.4922 - val_loss: 0.6017 - val_accuracy: 0.6687\n",
            "Epoch 2/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 1.4638 - accuracy: 0.5313 - val_loss: 0.8669 - val_accuracy: 0.4938\n",
            "Epoch 3/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 1.0231 - accuracy: 0.4937 - val_loss: 0.6733 - val_accuracy: 0.4688\n",
            "Epoch 4/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.7974 - accuracy: 0.5455 - val_loss: 0.7424 - val_accuracy: 0.3562\n",
            "Epoch 5/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.7749 - accuracy: 0.5251 - val_loss: 0.7131 - val_accuracy: 0.3750\n",
            "Epoch 6/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.7143 - accuracy: 0.5423 - val_loss: 0.6456 - val_accuracy: 0.6500\n",
            "Epoch 7/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.7272 - accuracy: 0.5361 - val_loss: 0.6428 - val_accuracy: 0.6187\n",
            "Epoch 8/200\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.7235 - accuracy: 0.5596 - val_loss: 0.6571 - val_accuracy: 0.6562\n",
            "Epoch 9/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.7255 - accuracy: 0.5721 - val_loss: 0.6495 - val_accuracy: 0.6687\n",
            "Epoch 10/200\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.7141 - accuracy: 0.5266 - val_loss: 0.6561 - val_accuracy: 0.6500\n",
            "Epoch 11/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.6845 - accuracy: 0.6003 - val_loss: 0.6424 - val_accuracy: 0.6750\n",
            "Epoch 12/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.6878 - accuracy: 0.5705 - val_loss: 0.6394 - val_accuracy: 0.7125\n",
            "Epoch 13/200\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.6823 - accuracy: 0.5611 - val_loss: 0.6386 - val_accuracy: 0.6750\n",
            "Epoch 14/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.6921 - accuracy: 0.5705 - val_loss: 0.6350 - val_accuracy: 0.7063\n",
            "Epoch 15/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.6734 - accuracy: 0.5752 - val_loss: 0.6336 - val_accuracy: 0.6500\n",
            "Epoch 16/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.6739 - accuracy: 0.5815 - val_loss: 0.6382 - val_accuracy: 0.5875\n",
            "Epoch 17/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.6740 - accuracy: 0.5674 - val_loss: 0.6004 - val_accuracy: 0.6750\n",
            "Epoch 18/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.6865 - accuracy: 0.5705 - val_loss: 0.6141 - val_accuracy: 0.6750\n",
            "Epoch 19/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.6612 - accuracy: 0.5784 - val_loss: 0.6108 - val_accuracy: 0.7250\n",
            "Epoch 20/200\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.6575 - accuracy: 0.5878 - val_loss: 0.6110 - val_accuracy: 0.6938\n",
            "Epoch 21/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.6831 - accuracy: 0.5361 - val_loss: 0.6148 - val_accuracy: 0.7063\n",
            "Epoch 22/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.6490 - accuracy: 0.6050 - val_loss: 0.6027 - val_accuracy: 0.6750\n",
            "Epoch 23/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.6568 - accuracy: 0.6082 - val_loss: 0.5991 - val_accuracy: 0.6750\n",
            "Epoch 24/200\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.6398 - accuracy: 0.6160 - val_loss: 0.6021 - val_accuracy: 0.7437\n",
            "Epoch 25/200\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.6559 - accuracy: 0.5893 - val_loss: 0.5922 - val_accuracy: 0.7625\n",
            "Epoch 26/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.6546 - accuracy: 0.5862 - val_loss: 0.5864 - val_accuracy: 0.7437\n",
            "Epoch 27/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.6440 - accuracy: 0.6129 - val_loss: 0.5870 - val_accuracy: 0.7625\n",
            "Epoch 28/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.6290 - accuracy: 0.6285 - val_loss: 0.5864 - val_accuracy: 0.7688\n",
            "Epoch 29/200\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.6413 - accuracy: 0.6160 - val_loss: 0.6040 - val_accuracy: 0.6375\n",
            "Epoch 30/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.6440 - accuracy: 0.6332 - val_loss: 0.5748 - val_accuracy: 0.7312\n",
            "Epoch 31/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.6475 - accuracy: 0.6285 - val_loss: 0.5961 - val_accuracy: 0.7125\n",
            "Epoch 32/200\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.6198 - accuracy: 0.6661 - val_loss: 0.5746 - val_accuracy: 0.7563\n",
            "Epoch 33/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.6149 - accuracy: 0.6630 - val_loss: 0.5696 - val_accuracy: 0.7625\n",
            "Epoch 34/200\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.6221 - accuracy: 0.6442 - val_loss: 0.5806 - val_accuracy: 0.7250\n",
            "Epoch 35/200\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.6192 - accuracy: 0.6630 - val_loss: 0.5697 - val_accuracy: 0.7125\n",
            "Epoch 36/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.6089 - accuracy: 0.6583 - val_loss: 0.5495 - val_accuracy: 0.7250\n",
            "Epoch 37/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.6272 - accuracy: 0.6583 - val_loss: 0.5646 - val_accuracy: 0.7250\n",
            "Epoch 38/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.5944 - accuracy: 0.6897 - val_loss: 0.5594 - val_accuracy: 0.7250\n",
            "Epoch 39/200\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.6291 - accuracy: 0.6536 - val_loss: 0.5543 - val_accuracy: 0.7312\n",
            "Epoch 40/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.6036 - accuracy: 0.6724 - val_loss: 0.5485 - val_accuracy: 0.7312\n",
            "Epoch 41/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.5926 - accuracy: 0.6693 - val_loss: 0.5621 - val_accuracy: 0.7250\n",
            "Epoch 42/200\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.5871 - accuracy: 0.6959 - val_loss: 0.5586 - val_accuracy: 0.7312\n",
            "Epoch 43/200\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.5942 - accuracy: 0.6991 - val_loss: 0.5621 - val_accuracy: 0.7188\n",
            "Epoch 44/200\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.5817 - accuracy: 0.6928 - val_loss: 0.5460 - val_accuracy: 0.7437\n",
            "Epoch 45/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.5933 - accuracy: 0.7006 - val_loss: 0.5513 - val_accuracy: 0.7312\n",
            "Epoch 46/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.6034 - accuracy: 0.6787 - val_loss: 0.5356 - val_accuracy: 0.7500\n",
            "Epoch 47/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.5781 - accuracy: 0.7069 - val_loss: 0.5178 - val_accuracy: 0.7500\n",
            "Epoch 48/200\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.5662 - accuracy: 0.7351 - val_loss: 0.5261 - val_accuracy: 0.7500\n",
            "Epoch 49/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.5807 - accuracy: 0.7006 - val_loss: 0.5490 - val_accuracy: 0.7375\n",
            "Epoch 50/200\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.5764 - accuracy: 0.7320 - val_loss: 0.5084 - val_accuracy: 0.7875\n",
            "Epoch 51/200\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.5914 - accuracy: 0.7085 - val_loss: 0.5323 - val_accuracy: 0.7625\n",
            "Epoch 52/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.5702 - accuracy: 0.7038 - val_loss: 0.5083 - val_accuracy: 0.7812\n",
            "Epoch 53/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.5637 - accuracy: 0.7226 - val_loss: 0.5368 - val_accuracy: 0.7437\n",
            "Epoch 54/200\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.5716 - accuracy: 0.7241 - val_loss: 0.5147 - val_accuracy: 0.7750\n",
            "Epoch 55/200\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.5582 - accuracy: 0.7304 - val_loss: 0.5368 - val_accuracy: 0.7500\n",
            "Epoch 56/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.5460 - accuracy: 0.7398 - val_loss: 0.4973 - val_accuracy: 0.7750\n",
            "Epoch 57/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.5431 - accuracy: 0.7414 - val_loss: 0.5660 - val_accuracy: 0.7125\n",
            "Epoch 58/200\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.5498 - accuracy: 0.7382 - val_loss: 0.4822 - val_accuracy: 0.8000\n",
            "Epoch 59/200\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.5378 - accuracy: 0.7429 - val_loss: 0.5254 - val_accuracy: 0.7500\n",
            "Epoch 60/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.5353 - accuracy: 0.7524 - val_loss: 0.5073 - val_accuracy: 0.7750\n",
            "Epoch 61/200\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.5366 - accuracy: 0.7571 - val_loss: 0.5093 - val_accuracy: 0.7625\n",
            "Epoch 62/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.5202 - accuracy: 0.7696 - val_loss: 0.5069 - val_accuracy: 0.7625\n",
            "Epoch 63/200\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.5281 - accuracy: 0.7555 - val_loss: 0.4826 - val_accuracy: 0.7937\n",
            "Epoch 64/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.5181 - accuracy: 0.7696 - val_loss: 0.4873 - val_accuracy: 0.7812\n",
            "Epoch 65/200\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.5119 - accuracy: 0.7633 - val_loss: 0.4884 - val_accuracy: 0.7812\n",
            "Epoch 66/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.5163 - accuracy: 0.7602 - val_loss: 0.5269 - val_accuracy: 0.7375\n",
            "Epoch 67/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.5119 - accuracy: 0.7571 - val_loss: 0.4956 - val_accuracy: 0.7688\n",
            "Epoch 68/200\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.5200 - accuracy: 0.7665 - val_loss: 0.4659 - val_accuracy: 0.8125\n",
            "Epoch 69/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.5204 - accuracy: 0.7602 - val_loss: 0.4579 - val_accuracy: 0.8188\n",
            "Epoch 70/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.5003 - accuracy: 0.7759 - val_loss: 0.5353 - val_accuracy: 0.7375\n",
            "Epoch 71/200\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.5303 - accuracy: 0.7524 - val_loss: 0.4543 - val_accuracy: 0.8250\n",
            "Epoch 72/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.4885 - accuracy: 0.7727 - val_loss: 0.4509 - val_accuracy: 0.8250\n",
            "Epoch 73/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.4965 - accuracy: 0.7790 - val_loss: 0.4778 - val_accuracy: 0.7812\n",
            "Epoch 74/200\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.4768 - accuracy: 0.7978 - val_loss: 0.4491 - val_accuracy: 0.8188\n",
            "Epoch 75/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.4792 - accuracy: 0.7821 - val_loss: 0.4787 - val_accuracy: 0.7812\n",
            "Epoch 76/200\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.4946 - accuracy: 0.7696 - val_loss: 0.4814 - val_accuracy: 0.7812\n",
            "Epoch 77/200\n",
            "20/20 [==============================] - 0s 6ms/step - loss: 0.4782 - accuracy: 0.8009 - val_loss: 0.5085 - val_accuracy: 0.7688\n",
            "Epoch 78/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.4637 - accuracy: 0.7931 - val_loss: 0.4363 - val_accuracy: 0.8313\n",
            "Epoch 79/200\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.4750 - accuracy: 0.7790 - val_loss: 0.4262 - val_accuracy: 0.8438\n",
            "Epoch 80/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.4729 - accuracy: 0.7931 - val_loss: 0.4314 - val_accuracy: 0.8313\n",
            "Epoch 81/200\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.4645 - accuracy: 0.7994 - val_loss: 0.4354 - val_accuracy: 0.8188\n",
            "Epoch 82/200\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.4561 - accuracy: 0.8150 - val_loss: 0.4647 - val_accuracy: 0.7937\n",
            "Epoch 83/200\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.4455 - accuracy: 0.8150 - val_loss: 0.4123 - val_accuracy: 0.8438\n",
            "Epoch 84/200\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.4501 - accuracy: 0.8103 - val_loss: 0.4831 - val_accuracy: 0.7875\n",
            "Epoch 85/200\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.4458 - accuracy: 0.8213 - val_loss: 0.4361 - val_accuracy: 0.8125\n",
            "Epoch 86/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.4382 - accuracy: 0.8245 - val_loss: 0.4637 - val_accuracy: 0.8000\n",
            "Epoch 87/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.4279 - accuracy: 0.8197 - val_loss: 0.4669 - val_accuracy: 0.8188\n",
            "Epoch 88/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.4311 - accuracy: 0.8025 - val_loss: 0.4096 - val_accuracy: 0.8313\n",
            "Epoch 89/200\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.4227 - accuracy: 0.8213 - val_loss: 0.4373 - val_accuracy: 0.8250\n",
            "Epoch 90/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.4178 - accuracy: 0.8323 - val_loss: 0.4076 - val_accuracy: 0.8375\n",
            "Epoch 91/200\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.4208 - accuracy: 0.8260 - val_loss: 0.4421 - val_accuracy: 0.8313\n",
            "Epoch 92/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.4073 - accuracy: 0.8401 - val_loss: 0.4401 - val_accuracy: 0.8313\n",
            "Epoch 93/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.4044 - accuracy: 0.8354 - val_loss: 0.4534 - val_accuracy: 0.8250\n",
            "Epoch 94/200\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.4281 - accuracy: 0.8292 - val_loss: 0.4600 - val_accuracy: 0.8250\n",
            "Epoch 95/200\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.4150 - accuracy: 0.8276 - val_loss: 0.4435 - val_accuracy: 0.8313\n",
            "Epoch 96/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.3990 - accuracy: 0.8354 - val_loss: 0.4417 - val_accuracy: 0.8375\n",
            "Epoch 97/200\n",
            "20/20 [==============================] - 0s 6ms/step - loss: 0.4125 - accuracy: 0.8370 - val_loss: 0.4343 - val_accuracy: 0.8375\n",
            "Epoch 98/200\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.4044 - accuracy: 0.8260 - val_loss: 0.3783 - val_accuracy: 0.8500\n",
            "Epoch 99/200\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.4216 - accuracy: 0.8245 - val_loss: 0.4175 - val_accuracy: 0.8500\n",
            "Epoch 100/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.4165 - accuracy: 0.8354 - val_loss: 0.3846 - val_accuracy: 0.8562\n",
            "Epoch 101/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.3974 - accuracy: 0.8433 - val_loss: 0.4379 - val_accuracy: 0.8313\n",
            "Epoch 102/200\n",
            "20/20 [==============================] - 0s 6ms/step - loss: 0.3863 - accuracy: 0.8417 - val_loss: 0.4260 - val_accuracy: 0.8313\n",
            "Epoch 103/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.3990 - accuracy: 0.8448 - val_loss: 0.4448 - val_accuracy: 0.8313\n",
            "Epoch 104/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.4198 - accuracy: 0.8433 - val_loss: 0.3872 - val_accuracy: 0.8625\n",
            "Epoch 105/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.3979 - accuracy: 0.8480 - val_loss: 0.3782 - val_accuracy: 0.8562\n",
            "Epoch 106/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.3897 - accuracy: 0.8448 - val_loss: 0.4378 - val_accuracy: 0.8250\n",
            "Epoch 107/200\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.3706 - accuracy: 0.8668 - val_loss: 0.4174 - val_accuracy: 0.8375\n",
            "Epoch 108/200\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.3716 - accuracy: 0.8511 - val_loss: 0.3658 - val_accuracy: 0.8687\n",
            "Epoch 109/200\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.3779 - accuracy: 0.8386 - val_loss: 0.3769 - val_accuracy: 0.8625\n",
            "Epoch 110/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.3869 - accuracy: 0.8433 - val_loss: 0.4046 - val_accuracy: 0.8500\n",
            "Epoch 111/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.3562 - accuracy: 0.8636 - val_loss: 0.3643 - val_accuracy: 0.8687\n",
            "Epoch 112/200\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.3664 - accuracy: 0.8558 - val_loss: 0.3622 - val_accuracy: 0.8750\n",
            "Epoch 113/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.3892 - accuracy: 0.8495 - val_loss: 0.3643 - val_accuracy: 0.8625\n",
            "Epoch 114/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.3682 - accuracy: 0.8636 - val_loss: 0.3741 - val_accuracy: 0.8687\n",
            "Epoch 115/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.3832 - accuracy: 0.8464 - val_loss: 0.3643 - val_accuracy: 0.8687\n",
            "Epoch 116/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.3816 - accuracy: 0.8605 - val_loss: 0.3811 - val_accuracy: 0.8687\n",
            "Epoch 117/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.3850 - accuracy: 0.8589 - val_loss: 0.4763 - val_accuracy: 0.8188\n",
            "Epoch 118/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.3880 - accuracy: 0.8527 - val_loss: 0.4269 - val_accuracy: 0.8375\n",
            "Epoch 119/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.3674 - accuracy: 0.8464 - val_loss: 0.4285 - val_accuracy: 0.8500\n",
            "Epoch 120/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.3779 - accuracy: 0.8448 - val_loss: 0.3847 - val_accuracy: 0.8500\n",
            "Epoch 121/200\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.3697 - accuracy: 0.8354 - val_loss: 0.3952 - val_accuracy: 0.8500\n",
            "Epoch 122/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.3593 - accuracy: 0.8621 - val_loss: 0.3743 - val_accuracy: 0.8562\n",
            "Epoch 123/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.3652 - accuracy: 0.8480 - val_loss: 0.3713 - val_accuracy: 0.8562\n",
            "Epoch 124/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.3602 - accuracy: 0.8605 - val_loss: 0.3688 - val_accuracy: 0.8625\n",
            "Epoch 125/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.3624 - accuracy: 0.8636 - val_loss: 0.4136 - val_accuracy: 0.8438\n",
            "Epoch 126/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.3472 - accuracy: 0.8589 - val_loss: 0.3734 - val_accuracy: 0.8500\n",
            "Epoch 127/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.3670 - accuracy: 0.8542 - val_loss: 0.3821 - val_accuracy: 0.8562\n",
            "Epoch 128/200\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.3699 - accuracy: 0.8495 - val_loss: 0.3865 - val_accuracy: 0.8438\n",
            "Epoch 129/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.3671 - accuracy: 0.8558 - val_loss: 0.3806 - val_accuracy: 0.8438\n",
            "Epoch 130/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.3446 - accuracy: 0.8605 - val_loss: 0.3435 - val_accuracy: 0.8875\n",
            "Epoch 131/200\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.3713 - accuracy: 0.8558 - val_loss: 0.4373 - val_accuracy: 0.8125\n",
            "Epoch 132/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.3475 - accuracy: 0.8542 - val_loss: 0.3969 - val_accuracy: 0.8438\n",
            "Epoch 133/200\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.3511 - accuracy: 0.8495 - val_loss: 0.3799 - val_accuracy: 0.8687\n",
            "Epoch 134/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.3424 - accuracy: 0.8683 - val_loss: 0.3717 - val_accuracy: 0.8750\n",
            "Epoch 135/200\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.3504 - accuracy: 0.8699 - val_loss: 0.4375 - val_accuracy: 0.8062\n",
            "Epoch 136/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.3556 - accuracy: 0.8480 - val_loss: 0.3864 - val_accuracy: 0.8375\n",
            "Epoch 137/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.3536 - accuracy: 0.8589 - val_loss: 0.4037 - val_accuracy: 0.8500\n",
            "Epoch 138/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.3309 - accuracy: 0.8636 - val_loss: 0.4074 - val_accuracy: 0.8188\n",
            "Epoch 139/200\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.3624 - accuracy: 0.8558 - val_loss: 0.4152 - val_accuracy: 0.8250\n",
            "Epoch 140/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.3323 - accuracy: 0.8636 - val_loss: 0.3978 - val_accuracy: 0.8188\n",
            "Epoch 141/200\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.3440 - accuracy: 0.8636 - val_loss: 0.4030 - val_accuracy: 0.8250\n",
            "Epoch 142/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.3287 - accuracy: 0.8762 - val_loss: 0.3754 - val_accuracy: 0.8625\n",
            "Epoch 143/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.3382 - accuracy: 0.8605 - val_loss: 0.3933 - val_accuracy: 0.8375\n",
            "Epoch 144/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.3395 - accuracy: 0.8621 - val_loss: 0.3766 - val_accuracy: 0.8625\n",
            "Epoch 145/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.3391 - accuracy: 0.8715 - val_loss: 0.3911 - val_accuracy: 0.8313\n",
            "Epoch 146/200\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.3312 - accuracy: 0.8683 - val_loss: 0.3713 - val_accuracy: 0.8500\n",
            "Epoch 147/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.3475 - accuracy: 0.8589 - val_loss: 0.3872 - val_accuracy: 0.8313\n",
            "Epoch 148/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.3325 - accuracy: 0.8605 - val_loss: 0.4149 - val_accuracy: 0.8188\n",
            "Epoch 149/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.3371 - accuracy: 0.8621 - val_loss: 0.3694 - val_accuracy: 0.8500\n",
            "Epoch 150/200\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.3323 - accuracy: 0.8668 - val_loss: 0.3810 - val_accuracy: 0.8500\n",
            "Epoch 151/200\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.3329 - accuracy: 0.8652 - val_loss: 0.4568 - val_accuracy: 0.8062\n",
            "Epoch 152/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.3460 - accuracy: 0.8527 - val_loss: 0.4032 - val_accuracy: 0.8188\n",
            "Epoch 153/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.3284 - accuracy: 0.8668 - val_loss: 0.3811 - val_accuracy: 0.8375\n",
            "Epoch 154/200\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.3139 - accuracy: 0.8777 - val_loss: 0.3903 - val_accuracy: 0.8313\n",
            "Epoch 155/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.3451 - accuracy: 0.8621 - val_loss: 0.3620 - val_accuracy: 0.8562\n",
            "Epoch 156/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.3296 - accuracy: 0.8668 - val_loss: 0.4331 - val_accuracy: 0.8188\n",
            "Epoch 157/200\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.3286 - accuracy: 0.8636 - val_loss: 0.4084 - val_accuracy: 0.8438\n",
            "Epoch 158/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.3205 - accuracy: 0.8683 - val_loss: 0.3599 - val_accuracy: 0.8625\n",
            "Epoch 159/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.3008 - accuracy: 0.8730 - val_loss: 0.4241 - val_accuracy: 0.8250\n",
            "Epoch 160/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.3473 - accuracy: 0.8652 - val_loss: 0.4432 - val_accuracy: 0.7937\n",
            "Epoch 161/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.3292 - accuracy: 0.8683 - val_loss: 0.3644 - val_accuracy: 0.8687\n",
            "Epoch 162/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.3212 - accuracy: 0.8730 - val_loss: 0.4071 - val_accuracy: 0.8313\n",
            "Epoch 163/200\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.3624 - accuracy: 0.8589 - val_loss: 0.4791 - val_accuracy: 0.7937\n",
            "Epoch 164/200\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.3348 - accuracy: 0.8668 - val_loss: 0.3771 - val_accuracy: 0.8562\n",
            "Epoch 165/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.3329 - accuracy: 0.8668 - val_loss: 0.3959 - val_accuracy: 0.8500\n",
            "Epoch 166/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.3221 - accuracy: 0.8730 - val_loss: 0.4031 - val_accuracy: 0.8375\n",
            "Epoch 167/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.3349 - accuracy: 0.8715 - val_loss: 0.3932 - val_accuracy: 0.8313\n",
            "Epoch 168/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.3146 - accuracy: 0.8715 - val_loss: 0.3474 - val_accuracy: 0.8813\n",
            "Epoch 169/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.3101 - accuracy: 0.8809 - val_loss: 0.4013 - val_accuracy: 0.8562\n",
            "Epoch 170/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.3111 - accuracy: 0.8636 - val_loss: 0.3825 - val_accuracy: 0.8562\n",
            "Epoch 171/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.3201 - accuracy: 0.8668 - val_loss: 0.3830 - val_accuracy: 0.8625\n",
            "Epoch 172/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.3165 - accuracy: 0.8809 - val_loss: 0.3528 - val_accuracy: 0.8875\n",
            "Epoch 173/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.3118 - accuracy: 0.8777 - val_loss: 0.3714 - val_accuracy: 0.8687\n",
            "Epoch 174/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.3332 - accuracy: 0.8636 - val_loss: 0.4010 - val_accuracy: 0.8313\n",
            "Epoch 175/200\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.3352 - accuracy: 0.8762 - val_loss: 0.4238 - val_accuracy: 0.8188\n",
            "Epoch 176/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.3300 - accuracy: 0.8621 - val_loss: 0.3617 - val_accuracy: 0.8625\n",
            "Epoch 177/200\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.3069 - accuracy: 0.8746 - val_loss: 0.3634 - val_accuracy: 0.8687\n",
            "Epoch 178/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.3304 - accuracy: 0.8699 - val_loss: 0.3847 - val_accuracy: 0.8500\n",
            "Epoch 179/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.3123 - accuracy: 0.8715 - val_loss: 0.3707 - val_accuracy: 0.8562\n",
            "Epoch 180/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.3149 - accuracy: 0.8699 - val_loss: 0.3609 - val_accuracy: 0.8750\n",
            "Epoch 181/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.3118 - accuracy: 0.8730 - val_loss: 0.4026 - val_accuracy: 0.8438\n",
            "Epoch 182/200\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.3251 - accuracy: 0.8621 - val_loss: 0.3916 - val_accuracy: 0.8375\n",
            "Epoch 183/200\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.3103 - accuracy: 0.8777 - val_loss: 0.3777 - val_accuracy: 0.8562\n",
            "Epoch 184/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.3132 - accuracy: 0.8840 - val_loss: 0.3704 - val_accuracy: 0.8562\n",
            "Epoch 185/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.2984 - accuracy: 0.8809 - val_loss: 0.3974 - val_accuracy: 0.8313\n",
            "Epoch 186/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.3249 - accuracy: 0.8636 - val_loss: 0.3808 - val_accuracy: 0.8438\n",
            "Epoch 187/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.3138 - accuracy: 0.8809 - val_loss: 0.4245 - val_accuracy: 0.8250\n",
            "Epoch 188/200\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.3029 - accuracy: 0.8715 - val_loss: 0.3732 - val_accuracy: 0.8625\n",
            "Epoch 189/200\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.3167 - accuracy: 0.8699 - val_loss: 0.4924 - val_accuracy: 0.7812\n",
            "Epoch 190/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.3217 - accuracy: 0.8668 - val_loss: 0.3562 - val_accuracy: 0.8750\n",
            "Epoch 191/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.3120 - accuracy: 0.8715 - val_loss: 0.3876 - val_accuracy: 0.8438\n",
            "Epoch 192/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.3102 - accuracy: 0.8840 - val_loss: 0.4575 - val_accuracy: 0.7937\n",
            "Epoch 193/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.3314 - accuracy: 0.8793 - val_loss: 0.3873 - val_accuracy: 0.8375\n",
            "Epoch 194/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.3098 - accuracy: 0.8824 - val_loss: 0.3756 - val_accuracy: 0.8375\n",
            "Epoch 195/200\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.3026 - accuracy: 0.8762 - val_loss: 0.3919 - val_accuracy: 0.8313\n",
            "Epoch 196/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.3103 - accuracy: 0.8699 - val_loss: 0.3474 - val_accuracy: 0.8875\n",
            "Epoch 197/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.2959 - accuracy: 0.8856 - val_loss: 0.4265 - val_accuracy: 0.8062\n",
            "Epoch 198/200\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.3019 - accuracy: 0.8746 - val_loss: 0.3854 - val_accuracy: 0.8375\n",
            "Epoch 199/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.3167 - accuracy: 0.8730 - val_loss: 0.3985 - val_accuracy: 0.8250\n",
            "Epoch 200/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.3198 - accuracy: 0.8699 - val_loss: 0.4136 - val_accuracy: 0.8125\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 0.3523 - accuracy: 0.8667\n",
            "## evaluation loss and_metrics ##\n",
            "[0.35230427980422974, 0.8666666746139526]\n",
            "4/4 [==============================] - 0s 5ms/step\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0, 1, 1, 1, 0, 1, 1, 0, 1, 1, 0, 0, 0, 0, 1, 1, 0, 1, 1, 0, 1, 0,\n",
              "       0, 0, 1, 1, 0, 1, 0, 0, 1, 1, 0, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 0,\n",
              "       0, 0, 1, 1, 1, 0, 1, 0, 1, 1, 1, 0, 0, 1, 1, 1, 0, 0, 0, 1, 0, 1,\n",
              "       1, 1, 1, 1, 0, 0, 1, 1, 0, 1, 0, 1, 0, 1, 1, 1, 1, 0, 1, 1, 0, 1,\n",
              "       0, 0, 1, 1, 1, 0, 0, 0, 1, 0, 1, 1, 0, 1, 1, 0, 1, 1, 0, 1, 1, 0,\n",
              "       1, 1, 0, 1, 1, 0, 1, 0, 1, 0])"
            ]
          },
          "metadata": {},
          "execution_count": 79
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "np.mean(y_test == y_pred_classMaxHR)"
      ],
      "metadata": {
        "id": "cgLzw6WtqXfx",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6f5c440c-53f0-4b83-8541-49aedd80145d"
      },
      "execution_count": 80,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.8666666666666667"
            ]
          },
          "metadata": {},
          "execution_count": 80
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "MaxHRscore=recall_score(y_test,y_pred_classMaxHR)\n",
        "print(MaxHRscore)"
      ],
      "metadata": {
        "id": "dmSYcycZqYmC",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a9b098d1-44ac-465a-bde0-485d62040891"
      },
      "execution_count": 81,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.9285714285714286\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Oldpeak"
      ],
      "metadata": {
        "id": "-HQ91tkqqnwt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "heart = pd.read_csv(f_path)\n",
        "\n",
        "heart = pd.get_dummies(heart)\n",
        "\n",
        "x = heart.drop('HeartDisease', axis=1)\n",
        "y = pd.get_dummies(heart[\"HeartDisease\"])\n",
        "\n",
        "heart['Oldpeak'] = 0\n",
        "\n",
        "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size = 0.13,shuffle=True, random_state = 42)\n",
        "\n",
        "print(\"X_train: \", x_train.shape)\n",
        "print(\"y_train: \", y_train.shape)\n",
        "\n",
        "print(\"X_test: \", x_test.shape)\n",
        "print(\"y_test: \", y_test.shape)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "ModelExceptOldpeak = Sequential()\n",
        "\n",
        "\n",
        "ModelExceptOldpeak.add(Dense(128, activation = \"relu\",input_dim=20))\n",
        "ModelExceptOldpeak.add(Dropout(rate=0.2))\n",
        "ModelExceptOldpeak.add(Dense(64, activation = \"relu\"))\n",
        "ModelExceptOldpeak.add(Dropout(rate=0.2))\n",
        "ModelExceptOldpeak.add(Dense(32, activation = \"relu\"))\n",
        "ModelExceptOldpeak.add(Dropout(rate=0.1))\n",
        "ModelExceptOldpeak.add(Dense(16, activation = \"relu\"))\n",
        "ModelExceptOldpeak.add(Dense(8, activation = \"relu\"))\n",
        "ModelExceptOldpeak.add(Dense(2, activation = \"sigmoid\"))\n",
        "\n",
        "ModelExceptOldpeak.compile(optimizer = \"adam\", loss = \"categorical_crossentropy\", metrics = [\"accuracy\"])\n",
        "ModelExceptOldpeak.summary()\n",
        "\n",
        "hin=ModelExceptOldpeak.fit(x_train,y_train,epochs=200, validation_split=0.2)\n",
        "\n",
        "loss_and_metrics = ModelExceptOldpeak.evaluate(x_test, y_test, batch_size=32)\n",
        "print('## evaluation loss and_metrics ##')\n",
        "print(loss_and_metrics)\n",
        "\n",
        "y_predOldpeak = ModelExceptOldpeak.predict(x_test)\n",
        "y_predOldpeak\n",
        "\n",
        "y_pred_classOldpeak = np.argmax(y_predOldpeak, axis=1)\n",
        "y_pred_classOldpeak\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "y_test  = y_test.to_numpy()\n",
        "y_test\n",
        "\n",
        "y_test = np.argmax(y_test,axis=1)\n",
        "y_test\n",
        "\n"
      ],
      "metadata": {
        "id": "4nXSaKNBree4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b7929ab8-bc85-447d-988e-7d1b280fdf3b"
      },
      "execution_count": 82,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "X_train:  (798, 20)\n",
            "y_train:  (798, 2)\n",
            "X_test:  (120, 20)\n",
            "y_test:  (120, 2)\n",
            "Model: \"sequential_10\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense_60 (Dense)            (None, 128)               2688      \n",
            "                                                                 \n",
            " dropout_30 (Dropout)        (None, 128)               0         \n",
            "                                                                 \n",
            " dense_61 (Dense)            (None, 64)                8256      \n",
            "                                                                 \n",
            " dropout_31 (Dropout)        (None, 64)                0         \n",
            "                                                                 \n",
            " dense_62 (Dense)            (None, 32)                2080      \n",
            "                                                                 \n",
            " dropout_32 (Dropout)        (None, 32)                0         \n",
            "                                                                 \n",
            " dense_63 (Dense)            (None, 16)                528       \n",
            "                                                                 \n",
            " dense_64 (Dense)            (None, 8)                 136       \n",
            "                                                                 \n",
            " dense_65 (Dense)            (None, 2)                 18        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 13,706\n",
            "Trainable params: 13,706\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/200\n",
            "20/20 [==============================] - 1s 14ms/step - loss: 0.9236 - accuracy: 0.5580 - val_loss: 0.6092 - val_accuracy: 0.6375\n",
            "Epoch 2/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.7111 - accuracy: 0.5611 - val_loss: 0.6249 - val_accuracy: 0.4938\n",
            "Epoch 3/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.7279 - accuracy: 0.5533 - val_loss: 0.6425 - val_accuracy: 0.4938\n",
            "Epoch 4/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.6905 - accuracy: 0.5831 - val_loss: 0.6352 - val_accuracy: 0.4938\n",
            "Epoch 5/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.7001 - accuracy: 0.5549 - val_loss: 0.6276 - val_accuracy: 0.4938\n",
            "Epoch 6/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.6645 - accuracy: 0.5658 - val_loss: 0.6354 - val_accuracy: 0.4938\n",
            "Epoch 7/200\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.6874 - accuracy: 0.5627 - val_loss: 0.6243 - val_accuracy: 0.4938\n",
            "Epoch 8/200\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.6691 - accuracy: 0.5580 - val_loss: 0.6216 - val_accuracy: 0.4938\n",
            "Epoch 9/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.6521 - accuracy: 0.5470 - val_loss: 0.6229 - val_accuracy: 0.4938\n",
            "Epoch 10/200\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.6709 - accuracy: 0.5596 - val_loss: 0.6206 - val_accuracy: 0.4938\n",
            "Epoch 11/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.6721 - accuracy: 0.5768 - val_loss: 0.6259 - val_accuracy: 0.4938\n",
            "Epoch 12/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.6662 - accuracy: 0.5564 - val_loss: 0.6179 - val_accuracy: 0.4938\n",
            "Epoch 13/200\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.6491 - accuracy: 0.5517 - val_loss: 0.6160 - val_accuracy: 0.4938\n",
            "Epoch 14/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.6763 - accuracy: 0.5627 - val_loss: 0.6150 - val_accuracy: 0.4938\n",
            "Epoch 15/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.6519 - accuracy: 0.5643 - val_loss: 0.6161 - val_accuracy: 0.5312\n",
            "Epoch 16/200\n",
            "20/20 [==============================] - 0s 6ms/step - loss: 0.6632 - accuracy: 0.5768 - val_loss: 0.6156 - val_accuracy: 0.7563\n",
            "Epoch 17/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.6517 - accuracy: 0.5564 - val_loss: 0.6175 - val_accuracy: 0.6750\n",
            "Epoch 18/200\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.6373 - accuracy: 0.5752 - val_loss: 0.6162 - val_accuracy: 0.6687\n",
            "Epoch 19/200\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.6480 - accuracy: 0.5878 - val_loss: 0.6139 - val_accuracy: 0.6938\n",
            "Epoch 20/200\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.6450 - accuracy: 0.6238 - val_loss: 0.6104 - val_accuracy: 0.7250\n",
            "Epoch 21/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.6443 - accuracy: 0.6144 - val_loss: 0.6109 - val_accuracy: 0.6562\n",
            "Epoch 22/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.6339 - accuracy: 0.6207 - val_loss: 0.6095 - val_accuracy: 0.7188\n",
            "Epoch 23/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.6404 - accuracy: 0.6223 - val_loss: 0.6074 - val_accuracy: 0.7437\n",
            "Epoch 24/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.6294 - accuracy: 0.6113 - val_loss: 0.6027 - val_accuracy: 0.7375\n",
            "Epoch 25/200\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.6365 - accuracy: 0.6097 - val_loss: 0.5989 - val_accuracy: 0.7125\n",
            "Epoch 26/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.6307 - accuracy: 0.6364 - val_loss: 0.5989 - val_accuracy: 0.7437\n",
            "Epoch 27/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.6335 - accuracy: 0.6708 - val_loss: 0.6268 - val_accuracy: 0.5562\n",
            "Epoch 28/200\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.6432 - accuracy: 0.6458 - val_loss: 0.5937 - val_accuracy: 0.7437\n",
            "Epoch 29/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.6142 - accuracy: 0.6661 - val_loss: 0.5949 - val_accuracy: 0.6687\n",
            "Epoch 30/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.6144 - accuracy: 0.6536 - val_loss: 0.5916 - val_accuracy: 0.7375\n",
            "Epoch 31/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.6411 - accuracy: 0.6787 - val_loss: 0.5877 - val_accuracy: 0.7312\n",
            "Epoch 32/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.6098 - accuracy: 0.6865 - val_loss: 0.5775 - val_accuracy: 0.7437\n",
            "Epoch 33/200\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.6013 - accuracy: 0.6944 - val_loss: 0.5690 - val_accuracy: 0.7375\n",
            "Epoch 34/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.6222 - accuracy: 0.6912 - val_loss: 0.5701 - val_accuracy: 0.7563\n",
            "Epoch 35/200\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.5938 - accuracy: 0.7116 - val_loss: 0.5666 - val_accuracy: 0.7563\n",
            "Epoch 36/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.5947 - accuracy: 0.7116 - val_loss: 0.5673 - val_accuracy: 0.7625\n",
            "Epoch 37/200\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.5833 - accuracy: 0.7382 - val_loss: 0.5525 - val_accuracy: 0.7563\n",
            "Epoch 38/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.5849 - accuracy: 0.7241 - val_loss: 0.5516 - val_accuracy: 0.7750\n",
            "Epoch 39/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.5842 - accuracy: 0.7053 - val_loss: 0.5456 - val_accuracy: 0.7750\n",
            "Epoch 40/200\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.5877 - accuracy: 0.7100 - val_loss: 0.5421 - val_accuracy: 0.7688\n",
            "Epoch 41/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.5909 - accuracy: 0.7273 - val_loss: 0.5455 - val_accuracy: 0.7750\n",
            "Epoch 42/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.5662 - accuracy: 0.7571 - val_loss: 0.5387 - val_accuracy: 0.7688\n",
            "Epoch 43/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.5749 - accuracy: 0.7320 - val_loss: 0.5391 - val_accuracy: 0.7625\n",
            "Epoch 44/200\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.5569 - accuracy: 0.7696 - val_loss: 0.5320 - val_accuracy: 0.7937\n",
            "Epoch 45/200\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.5469 - accuracy: 0.7665 - val_loss: 0.5192 - val_accuracy: 0.8000\n",
            "Epoch 46/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.5425 - accuracy: 0.7759 - val_loss: 0.5274 - val_accuracy: 0.7688\n",
            "Epoch 47/200\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.5410 - accuracy: 0.7618 - val_loss: 0.5219 - val_accuracy: 0.7688\n",
            "Epoch 48/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.5429 - accuracy: 0.7633 - val_loss: 0.5159 - val_accuracy: 0.7812\n",
            "Epoch 49/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.5489 - accuracy: 0.7508 - val_loss: 0.5001 - val_accuracy: 0.8125\n",
            "Epoch 50/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.5354 - accuracy: 0.7665 - val_loss: 0.5181 - val_accuracy: 0.7875\n",
            "Epoch 51/200\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.5396 - accuracy: 0.7618 - val_loss: 0.5471 - val_accuracy: 0.7500\n",
            "Epoch 52/200\n",
            "20/20 [==============================] - 0s 6ms/step - loss: 0.5266 - accuracy: 0.7790 - val_loss: 0.5007 - val_accuracy: 0.7875\n",
            "Epoch 53/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.5342 - accuracy: 0.7696 - val_loss: 0.5049 - val_accuracy: 0.7812\n",
            "Epoch 54/200\n",
            "20/20 [==============================] - 0s 6ms/step - loss: 0.5206 - accuracy: 0.7837 - val_loss: 0.4887 - val_accuracy: 0.8125\n",
            "Epoch 55/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.4931 - accuracy: 0.8150 - val_loss: 0.4824 - val_accuracy: 0.8125\n",
            "Epoch 56/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.5222 - accuracy: 0.7853 - val_loss: 0.4797 - val_accuracy: 0.8250\n",
            "Epoch 57/200\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.4910 - accuracy: 0.7978 - val_loss: 0.4893 - val_accuracy: 0.8062\n",
            "Epoch 58/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.5049 - accuracy: 0.7915 - val_loss: 0.4715 - val_accuracy: 0.8125\n",
            "Epoch 59/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.5088 - accuracy: 0.7915 - val_loss: 0.4681 - val_accuracy: 0.8313\n",
            "Epoch 60/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.4913 - accuracy: 0.7978 - val_loss: 0.4588 - val_accuracy: 0.8375\n",
            "Epoch 61/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.4881 - accuracy: 0.7884 - val_loss: 0.4700 - val_accuracy: 0.8125\n",
            "Epoch 62/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.4510 - accuracy: 0.8307 - val_loss: 0.4807 - val_accuracy: 0.8062\n",
            "Epoch 63/200\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.4614 - accuracy: 0.8292 - val_loss: 0.5528 - val_accuracy: 0.7812\n",
            "Epoch 64/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.4708 - accuracy: 0.8197 - val_loss: 0.4483 - val_accuracy: 0.8375\n",
            "Epoch 65/200\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.4477 - accuracy: 0.8166 - val_loss: 0.4685 - val_accuracy: 0.8250\n",
            "Epoch 66/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.4537 - accuracy: 0.8276 - val_loss: 0.4430 - val_accuracy: 0.8438\n",
            "Epoch 67/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.4526 - accuracy: 0.8166 - val_loss: 0.4407 - val_accuracy: 0.8375\n",
            "Epoch 68/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.4401 - accuracy: 0.8103 - val_loss: 0.4337 - val_accuracy: 0.8375\n",
            "Epoch 69/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.4474 - accuracy: 0.8323 - val_loss: 0.4462 - val_accuracy: 0.8438\n",
            "Epoch 70/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.4428 - accuracy: 0.8229 - val_loss: 0.4318 - val_accuracy: 0.8375\n",
            "Epoch 71/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.4427 - accuracy: 0.8386 - val_loss: 0.4423 - val_accuracy: 0.8313\n",
            "Epoch 72/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.4241 - accuracy: 0.8386 - val_loss: 0.4435 - val_accuracy: 0.8500\n",
            "Epoch 73/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.4216 - accuracy: 0.8339 - val_loss: 0.4469 - val_accuracy: 0.8438\n",
            "Epoch 74/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.4201 - accuracy: 0.8339 - val_loss: 0.4271 - val_accuracy: 0.8375\n",
            "Epoch 75/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.4168 - accuracy: 0.8433 - val_loss: 0.4147 - val_accuracy: 0.8500\n",
            "Epoch 76/200\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.4047 - accuracy: 0.8495 - val_loss: 0.4363 - val_accuracy: 0.8438\n",
            "Epoch 77/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.4106 - accuracy: 0.8448 - val_loss: 0.4138 - val_accuracy: 0.8562\n",
            "Epoch 78/200\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.3996 - accuracy: 0.8480 - val_loss: 0.4232 - val_accuracy: 0.8562\n",
            "Epoch 79/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.3992 - accuracy: 0.8433 - val_loss: 0.3753 - val_accuracy: 0.8500\n",
            "Epoch 80/200\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.3888 - accuracy: 0.8401 - val_loss: 0.3727 - val_accuracy: 0.8375\n",
            "Epoch 81/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.4041 - accuracy: 0.8292 - val_loss: 0.4381 - val_accuracy: 0.8438\n",
            "Epoch 82/200\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.3966 - accuracy: 0.8307 - val_loss: 0.3691 - val_accuracy: 0.8562\n",
            "Epoch 83/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.3843 - accuracy: 0.8448 - val_loss: 0.4062 - val_accuracy: 0.8438\n",
            "Epoch 84/200\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.3876 - accuracy: 0.8574 - val_loss: 0.3851 - val_accuracy: 0.8625\n",
            "Epoch 85/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.3387 - accuracy: 0.8652 - val_loss: 0.3686 - val_accuracy: 0.8562\n",
            "Epoch 86/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.3715 - accuracy: 0.8527 - val_loss: 0.3993 - val_accuracy: 0.8375\n",
            "Epoch 87/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.3671 - accuracy: 0.8558 - val_loss: 0.3538 - val_accuracy: 0.8562\n",
            "Epoch 88/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.3620 - accuracy: 0.8558 - val_loss: 0.3563 - val_accuracy: 0.8687\n",
            "Epoch 89/200\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.3711 - accuracy: 0.8511 - val_loss: 0.3773 - val_accuracy: 0.8562\n",
            "Epoch 90/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.3343 - accuracy: 0.8589 - val_loss: 0.3698 - val_accuracy: 0.8687\n",
            "Epoch 91/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.3316 - accuracy: 0.8605 - val_loss: 0.3904 - val_accuracy: 0.8500\n",
            "Epoch 92/200\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.3551 - accuracy: 0.8652 - val_loss: 0.3910 - val_accuracy: 0.8687\n",
            "Epoch 93/200\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.3565 - accuracy: 0.8558 - val_loss: 0.4301 - val_accuracy: 0.8438\n",
            "Epoch 94/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.3818 - accuracy: 0.8433 - val_loss: 0.3715 - val_accuracy: 0.8687\n",
            "Epoch 95/200\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.3589 - accuracy: 0.8574 - val_loss: 0.4008 - val_accuracy: 0.8438\n",
            "Epoch 96/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.3348 - accuracy: 0.8699 - val_loss: 0.3691 - val_accuracy: 0.8562\n",
            "Epoch 97/200\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.3427 - accuracy: 0.8668 - val_loss: 0.3695 - val_accuracy: 0.8625\n",
            "Epoch 98/200\n",
            "20/20 [==============================] - 0s 6ms/step - loss: 0.3600 - accuracy: 0.8370 - val_loss: 0.3714 - val_accuracy: 0.8687\n",
            "Epoch 99/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.3339 - accuracy: 0.8605 - val_loss: 0.3583 - val_accuracy: 0.8750\n",
            "Epoch 100/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.3505 - accuracy: 0.8621 - val_loss: 0.3516 - val_accuracy: 0.8625\n",
            "Epoch 101/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.3509 - accuracy: 0.8636 - val_loss: 0.3633 - val_accuracy: 0.8625\n",
            "Epoch 102/200\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.3320 - accuracy: 0.8668 - val_loss: 0.3918 - val_accuracy: 0.8562\n",
            "Epoch 103/200\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.3350 - accuracy: 0.8715 - val_loss: 0.3524 - val_accuracy: 0.8687\n",
            "Epoch 104/200\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.3480 - accuracy: 0.8574 - val_loss: 0.3743 - val_accuracy: 0.8687\n",
            "Epoch 105/200\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.3427 - accuracy: 0.8511 - val_loss: 0.3636 - val_accuracy: 0.8562\n",
            "Epoch 106/200\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.3289 - accuracy: 0.8699 - val_loss: 0.3581 - val_accuracy: 0.8750\n",
            "Epoch 107/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.3296 - accuracy: 0.8574 - val_loss: 0.4396 - val_accuracy: 0.8125\n",
            "Epoch 108/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.3500 - accuracy: 0.8636 - val_loss: 0.3616 - val_accuracy: 0.8687\n",
            "Epoch 109/200\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.3278 - accuracy: 0.8605 - val_loss: 0.3887 - val_accuracy: 0.8500\n",
            "Epoch 110/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.3137 - accuracy: 0.8840 - val_loss: 0.3962 - val_accuracy: 0.8562\n",
            "Epoch 111/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.3421 - accuracy: 0.8652 - val_loss: 0.3648 - val_accuracy: 0.8687\n",
            "Epoch 112/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.3350 - accuracy: 0.8636 - val_loss: 0.3641 - val_accuracy: 0.8625\n",
            "Epoch 113/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.3463 - accuracy: 0.8715 - val_loss: 0.3662 - val_accuracy: 0.8750\n",
            "Epoch 114/200\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.3082 - accuracy: 0.8668 - val_loss: 0.4306 - val_accuracy: 0.8562\n",
            "Epoch 115/200\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.3201 - accuracy: 0.8652 - val_loss: 0.4011 - val_accuracy: 0.8625\n",
            "Epoch 116/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.3243 - accuracy: 0.8762 - val_loss: 0.3707 - val_accuracy: 0.8687\n",
            "Epoch 117/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.3200 - accuracy: 0.8730 - val_loss: 0.3787 - val_accuracy: 0.8562\n",
            "Epoch 118/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.3339 - accuracy: 0.8542 - val_loss: 0.3817 - val_accuracy: 0.8687\n",
            "Epoch 119/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.3033 - accuracy: 0.8683 - val_loss: 0.4035 - val_accuracy: 0.8500\n",
            "Epoch 120/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.3177 - accuracy: 0.8730 - val_loss: 0.4030 - val_accuracy: 0.8562\n",
            "Epoch 121/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.3040 - accuracy: 0.8730 - val_loss: 0.4005 - val_accuracy: 0.8562\n",
            "Epoch 122/200\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.3021 - accuracy: 0.8824 - val_loss: 0.3709 - val_accuracy: 0.8687\n",
            "Epoch 123/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.3179 - accuracy: 0.8809 - val_loss: 0.3634 - val_accuracy: 0.8687\n",
            "Epoch 124/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.3155 - accuracy: 0.8777 - val_loss: 0.3869 - val_accuracy: 0.8687\n",
            "Epoch 125/200\n",
            "20/20 [==============================] - 0s 6ms/step - loss: 0.3053 - accuracy: 0.8793 - val_loss: 0.3773 - val_accuracy: 0.8562\n",
            "Epoch 126/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.3183 - accuracy: 0.8715 - val_loss: 0.3659 - val_accuracy: 0.8687\n",
            "Epoch 127/200\n",
            "20/20 [==============================] - 0s 6ms/step - loss: 0.3293 - accuracy: 0.8605 - val_loss: 0.3685 - val_accuracy: 0.8750\n",
            "Epoch 128/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.3045 - accuracy: 0.8683 - val_loss: 0.3983 - val_accuracy: 0.8500\n",
            "Epoch 129/200\n",
            "20/20 [==============================] - 0s 8ms/step - loss: 0.3044 - accuracy: 0.8746 - val_loss: 0.3654 - val_accuracy: 0.8750\n",
            "Epoch 130/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.2984 - accuracy: 0.8793 - val_loss: 0.3716 - val_accuracy: 0.8562\n",
            "Epoch 131/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.3043 - accuracy: 0.8668 - val_loss: 0.3522 - val_accuracy: 0.8750\n",
            "Epoch 132/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.3029 - accuracy: 0.8777 - val_loss: 0.3533 - val_accuracy: 0.8750\n",
            "Epoch 133/200\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.3200 - accuracy: 0.8699 - val_loss: 0.4053 - val_accuracy: 0.8313\n",
            "Epoch 134/200\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.3322 - accuracy: 0.8683 - val_loss: 0.3967 - val_accuracy: 0.8500\n",
            "Epoch 135/200\n",
            "20/20 [==============================] - 0s 6ms/step - loss: 0.3117 - accuracy: 0.8730 - val_loss: 0.3716 - val_accuracy: 0.8750\n",
            "Epoch 136/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.3177 - accuracy: 0.8793 - val_loss: 0.3787 - val_accuracy: 0.8625\n",
            "Epoch 137/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.3231 - accuracy: 0.8730 - val_loss: 0.3467 - val_accuracy: 0.8687\n",
            "Epoch 138/200\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.3120 - accuracy: 0.8746 - val_loss: 0.3368 - val_accuracy: 0.8750\n",
            "Epoch 139/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.3088 - accuracy: 0.8683 - val_loss: 0.3471 - val_accuracy: 0.8813\n",
            "Epoch 140/200\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.3010 - accuracy: 0.8793 - val_loss: 0.3690 - val_accuracy: 0.8625\n",
            "Epoch 141/200\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.3186 - accuracy: 0.8840 - val_loss: 0.3669 - val_accuracy: 0.8813\n",
            "Epoch 142/200\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.3003 - accuracy: 0.8668 - val_loss: 0.3585 - val_accuracy: 0.8750\n",
            "Epoch 143/200\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.3225 - accuracy: 0.8715 - val_loss: 0.3413 - val_accuracy: 0.8750\n",
            "Epoch 144/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.3238 - accuracy: 0.8652 - val_loss: 0.3518 - val_accuracy: 0.8813\n",
            "Epoch 145/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.3020 - accuracy: 0.8621 - val_loss: 0.4289 - val_accuracy: 0.8188\n",
            "Epoch 146/200\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.2996 - accuracy: 0.8730 - val_loss: 0.3624 - val_accuracy: 0.8750\n",
            "Epoch 147/200\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.3099 - accuracy: 0.8793 - val_loss: 0.3797 - val_accuracy: 0.8750\n",
            "Epoch 148/200\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.3013 - accuracy: 0.8715 - val_loss: 0.3663 - val_accuracy: 0.8625\n",
            "Epoch 149/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.2846 - accuracy: 0.8793 - val_loss: 0.3896 - val_accuracy: 0.8438\n",
            "Epoch 150/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.2939 - accuracy: 0.8856 - val_loss: 0.3852 - val_accuracy: 0.8687\n",
            "Epoch 151/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.2979 - accuracy: 0.8762 - val_loss: 0.4194 - val_accuracy: 0.8438\n",
            "Epoch 152/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.2893 - accuracy: 0.8777 - val_loss: 0.3715 - val_accuracy: 0.8813\n",
            "Epoch 153/200\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.2971 - accuracy: 0.8746 - val_loss: 0.3742 - val_accuracy: 0.8750\n",
            "Epoch 154/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.2915 - accuracy: 0.8652 - val_loss: 0.3578 - val_accuracy: 0.8625\n",
            "Epoch 155/200\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.3184 - accuracy: 0.8730 - val_loss: 0.3574 - val_accuracy: 0.8625\n",
            "Epoch 156/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.3077 - accuracy: 0.8652 - val_loss: 0.4442 - val_accuracy: 0.8438\n",
            "Epoch 157/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.3000 - accuracy: 0.8652 - val_loss: 0.3814 - val_accuracy: 0.8625\n",
            "Epoch 158/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.2991 - accuracy: 0.8668 - val_loss: 0.4018 - val_accuracy: 0.8625\n",
            "Epoch 159/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.2937 - accuracy: 0.8715 - val_loss: 0.3774 - val_accuracy: 0.8625\n",
            "Epoch 160/200\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.2937 - accuracy: 0.8777 - val_loss: 0.3612 - val_accuracy: 0.8625\n",
            "Epoch 161/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.2825 - accuracy: 0.8840 - val_loss: 0.3762 - val_accuracy: 0.8813\n",
            "Epoch 162/200\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.2785 - accuracy: 0.8856 - val_loss: 0.3914 - val_accuracy: 0.8500\n",
            "Epoch 163/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.2815 - accuracy: 0.8871 - val_loss: 0.3543 - val_accuracy: 0.8687\n",
            "Epoch 164/200\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.2857 - accuracy: 0.8793 - val_loss: 0.3727 - val_accuracy: 0.8625\n",
            "Epoch 165/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.2860 - accuracy: 0.8730 - val_loss: 0.3676 - val_accuracy: 0.8687\n",
            "Epoch 166/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.2786 - accuracy: 0.8777 - val_loss: 0.3794 - val_accuracy: 0.8687\n",
            "Epoch 167/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.2989 - accuracy: 0.8621 - val_loss: 0.4360 - val_accuracy: 0.8062\n",
            "Epoch 168/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.3041 - accuracy: 0.8809 - val_loss: 0.4601 - val_accuracy: 0.8062\n",
            "Epoch 169/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.2961 - accuracy: 0.8621 - val_loss: 0.4075 - val_accuracy: 0.8500\n",
            "Epoch 170/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.2967 - accuracy: 0.8730 - val_loss: 0.3802 - val_accuracy: 0.8687\n",
            "Epoch 171/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.2823 - accuracy: 0.8777 - val_loss: 0.3520 - val_accuracy: 0.8813\n",
            "Epoch 172/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.2669 - accuracy: 0.8918 - val_loss: 0.4271 - val_accuracy: 0.8438\n",
            "Epoch 173/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.3044 - accuracy: 0.8762 - val_loss: 0.4094 - val_accuracy: 0.8438\n",
            "Epoch 174/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.2930 - accuracy: 0.8793 - val_loss: 0.3682 - val_accuracy: 0.8750\n",
            "Epoch 175/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.2909 - accuracy: 0.8824 - val_loss: 0.3986 - val_accuracy: 0.8562\n",
            "Epoch 176/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.2725 - accuracy: 0.8871 - val_loss: 0.3746 - val_accuracy: 0.8625\n",
            "Epoch 177/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.2869 - accuracy: 0.8809 - val_loss: 0.3862 - val_accuracy: 0.8500\n",
            "Epoch 178/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.2907 - accuracy: 0.8730 - val_loss: 0.3497 - val_accuracy: 0.8750\n",
            "Epoch 179/200\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.3068 - accuracy: 0.8824 - val_loss: 0.3774 - val_accuracy: 0.8562\n",
            "Epoch 180/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.2876 - accuracy: 0.8840 - val_loss: 0.4027 - val_accuracy: 0.8438\n",
            "Epoch 181/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.2883 - accuracy: 0.8605 - val_loss: 0.3751 - val_accuracy: 0.8625\n",
            "Epoch 182/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.2894 - accuracy: 0.8683 - val_loss: 0.3570 - val_accuracy: 0.8750\n",
            "Epoch 183/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.2915 - accuracy: 0.8683 - val_loss: 0.3473 - val_accuracy: 0.8813\n",
            "Epoch 184/200\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.2779 - accuracy: 0.8934 - val_loss: 0.3682 - val_accuracy: 0.8813\n",
            "Epoch 185/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.2987 - accuracy: 0.8730 - val_loss: 0.3887 - val_accuracy: 0.8500\n",
            "Epoch 186/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.2870 - accuracy: 0.8746 - val_loss: 0.4180 - val_accuracy: 0.8625\n",
            "Epoch 187/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.2999 - accuracy: 0.8668 - val_loss: 0.3993 - val_accuracy: 0.8500\n",
            "Epoch 188/200\n",
            "20/20 [==============================] - 0s 6ms/step - loss: 0.2825 - accuracy: 0.8856 - val_loss: 0.3652 - val_accuracy: 0.8750\n",
            "Epoch 189/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.2748 - accuracy: 0.8793 - val_loss: 0.3717 - val_accuracy: 0.8750\n",
            "Epoch 190/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.2976 - accuracy: 0.8715 - val_loss: 0.3447 - val_accuracy: 0.8750\n",
            "Epoch 191/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.2792 - accuracy: 0.8793 - val_loss: 0.3998 - val_accuracy: 0.8562\n",
            "Epoch 192/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.2741 - accuracy: 0.8777 - val_loss: 0.4346 - val_accuracy: 0.8562\n",
            "Epoch 193/200\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.2866 - accuracy: 0.8746 - val_loss: 0.3622 - val_accuracy: 0.8687\n",
            "Epoch 194/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.2768 - accuracy: 0.8746 - val_loss: 0.4166 - val_accuracy: 0.8562\n",
            "Epoch 195/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.2781 - accuracy: 0.8824 - val_loss: 0.3618 - val_accuracy: 0.8750\n",
            "Epoch 196/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.2929 - accuracy: 0.8793 - val_loss: 0.4164 - val_accuracy: 0.8250\n",
            "Epoch 197/200\n",
            "20/20 [==============================] - 0s 6ms/step - loss: 0.2966 - accuracy: 0.8699 - val_loss: 0.3857 - val_accuracy: 0.8625\n",
            "Epoch 198/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.2886 - accuracy: 0.8762 - val_loss: 0.3453 - val_accuracy: 0.8813\n",
            "Epoch 199/200\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.2739 - accuracy: 0.8871 - val_loss: 0.4073 - val_accuracy: 0.8313\n",
            "Epoch 200/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.2774 - accuracy: 0.8809 - val_loss: 0.3752 - val_accuracy: 0.8625\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 0.4251 - accuracy: 0.8417\n",
            "## evaluation loss and_metrics ##\n",
            "[0.42507436871528625, 0.8416666388511658]\n",
            "4/4 [==============================] - 0s 3ms/step\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0, 1, 1, 1, 0, 1, 1, 0, 1, 1, 0, 0, 0, 0, 1, 1, 0, 1, 1, 0, 1, 0,\n",
              "       0, 0, 1, 1, 0, 1, 0, 0, 1, 1, 0, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 0,\n",
              "       0, 0, 1, 1, 1, 0, 1, 0, 1, 1, 1, 0, 0, 1, 1, 1, 0, 0, 0, 1, 0, 1,\n",
              "       1, 1, 1, 1, 0, 0, 1, 1, 0, 1, 0, 1, 0, 1, 1, 1, 1, 0, 1, 1, 0, 1,\n",
              "       0, 0, 1, 1, 1, 0, 0, 0, 1, 0, 1, 1, 0, 1, 1, 0, 1, 1, 0, 1, 1, 0,\n",
              "       1, 1, 0, 1, 1, 0, 1, 0, 1, 0])"
            ]
          },
          "metadata": {},
          "execution_count": 82
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "np.mean(y_test == y_pred_classOldpeak)"
      ],
      "metadata": {
        "id": "hXrmKXyEsUV7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bc10be3b-1983-43cf-f2e8-e1db163ec124"
      },
      "execution_count": 83,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.8416666666666667"
            ]
          },
          "metadata": {},
          "execution_count": 83
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "Oldpeakscore=recall_score(y_test,y_pred_classOldpeak)\n",
        "print(Oldpeakscore)"
      ],
      "metadata": {
        "id": "nBUP3a_osUlW",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "de6d1bdb-c918-4729-cef7-bd468293a75a"
      },
      "execution_count": 84,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.8857142857142857\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Sex_F"
      ],
      "metadata": {
        "id": "FDNqs5k3qtgB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "heart = pd.read_csv(f_path)\n",
        "\n",
        "heart = pd.get_dummies(heart)\n",
        "\n",
        "x = heart.drop('HeartDisease', axis=1)\n",
        "y = pd.get_dummies(heart[\"HeartDisease\"])\n",
        "\n",
        "heart['Sex_F'] = 0\n",
        "\n",
        "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size = 0.13,shuffle=True, random_state = 42)\n",
        "\n",
        "print(\"X_train: \", x_train.shape)\n",
        "print(\"y_train: \", y_train.shape)\n",
        "\n",
        "print(\"X_test: \", x_test.shape)\n",
        "print(\"y_test: \", y_test.shape)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "ModelExceptSex_F = Sequential()\n",
        "\n",
        "\n",
        "ModelExceptSex_F.add(Dense(128, activation = \"relu\",input_dim=20))\n",
        "ModelExceptSex_F.add(Dropout(rate=0.2))\n",
        "ModelExceptSex_F.add(Dense(64, activation = \"relu\"))\n",
        "ModelExceptSex_F.add(Dropout(rate=0.2))\n",
        "ModelExceptSex_F.add(Dense(32, activation = \"relu\"))\n",
        "ModelExceptSex_F.add(Dropout(rate=0.1))\n",
        "ModelExceptSex_F.add(Dense(16, activation = \"relu\"))\n",
        "ModelExceptSex_F.add(Dense(8, activation = \"relu\"))\n",
        "ModelExceptSex_F.add(Dense(2, activation = \"sigmoid\"))\n",
        "\n",
        "ModelExceptSex_F.compile(optimizer = \"adam\", loss = \"categorical_crossentropy\", metrics = [\"accuracy\"])\n",
        "ModelExceptSex_F.summary()\n",
        "\n",
        "hin=ModelExceptSex_F.fit(x_train,y_train,epochs=200, validation_split=0.2)\n",
        "\n",
        "loss_and_metrics = ModelExceptSex_F.evaluate(x_test, y_test, batch_size=32)\n",
        "print('## evaluation loss and_metrics ##')\n",
        "print(loss_and_metrics)\n",
        "\n",
        "y_predSex_F = ModelExceptSex_F.predict(x_test)\n",
        "y_predSex_F\n",
        "\n",
        "y_pred_classSex_F = np.argmax(y_predSex_F, axis=1)\n",
        "y_pred_classSex_F\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "y_test  = y_test.to_numpy()\n",
        "y_test\n",
        "\n",
        "y_test = np.argmax(y_test,axis=1)\n",
        "y_test\n",
        "\n"
      ],
      "metadata": {
        "id": "2xchYPypw_La",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ebc745d9-d6cc-4d40-c1f9-de6c1ceb3f14"
      },
      "execution_count": 85,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "X_train:  (798, 20)\n",
            "y_train:  (798, 2)\n",
            "X_test:  (120, 20)\n",
            "y_test:  (120, 2)\n",
            "Model: \"sequential_11\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense_66 (Dense)            (None, 128)               2688      \n",
            "                                                                 \n",
            " dropout_33 (Dropout)        (None, 128)               0         \n",
            "                                                                 \n",
            " dense_67 (Dense)            (None, 64)                8256      \n",
            "                                                                 \n",
            " dropout_34 (Dropout)        (None, 64)                0         \n",
            "                                                                 \n",
            " dense_68 (Dense)            (None, 32)                2080      \n",
            "                                                                 \n",
            " dropout_35 (Dropout)        (None, 32)                0         \n",
            "                                                                 \n",
            " dense_69 (Dense)            (None, 16)                528       \n",
            "                                                                 \n",
            " dense_70 (Dense)            (None, 8)                 136       \n",
            "                                                                 \n",
            " dense_71 (Dense)            (None, 2)                 18        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 13,706\n",
            "Trainable params: 13,706\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/200\n",
            "20/20 [==============================] - 1s 14ms/step - loss: 6.1731 - accuracy: 0.5627 - val_loss: 1.0273 - val_accuracy: 0.4938\n",
            "Epoch 2/200\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 2.0322 - accuracy: 0.5627 - val_loss: 0.8981 - val_accuracy: 0.4938\n",
            "Epoch 3/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 1.3369 - accuracy: 0.5611 - val_loss: 0.7504 - val_accuracy: 0.4938\n",
            "Epoch 4/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 1.0061 - accuracy: 0.5611 - val_loss: 0.7090 - val_accuracy: 0.4938\n",
            "Epoch 5/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.8543 - accuracy: 0.5596 - val_loss: 0.7376 - val_accuracy: 0.4938\n",
            "Epoch 6/200\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.8163 - accuracy: 0.5596 - val_loss: 0.6953 - val_accuracy: 0.4938\n",
            "Epoch 7/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.7687 - accuracy: 0.5517 - val_loss: 0.6750 - val_accuracy: 0.4938\n",
            "Epoch 8/200\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.7445 - accuracy: 0.5705 - val_loss: 0.6621 - val_accuracy: 0.4812\n",
            "Epoch 9/200\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.6932 - accuracy: 0.5737 - val_loss: 0.6501 - val_accuracy: 0.4750\n",
            "Epoch 10/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.7098 - accuracy: 0.5580 - val_loss: 0.6432 - val_accuracy: 0.6750\n",
            "Epoch 11/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.7047 - accuracy: 0.5549 - val_loss: 0.6437 - val_accuracy: 0.6438\n",
            "Epoch 12/200\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.6755 - accuracy: 0.5721 - val_loss: 0.6336 - val_accuracy: 0.5688\n",
            "Epoch 13/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.6639 - accuracy: 0.5674 - val_loss: 0.6272 - val_accuracy: 0.6375\n",
            "Epoch 14/200\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.6702 - accuracy: 0.5580 - val_loss: 0.6269 - val_accuracy: 0.6875\n",
            "Epoch 15/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.6566 - accuracy: 0.5690 - val_loss: 0.6249 - val_accuracy: 0.6750\n",
            "Epoch 16/200\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.6610 - accuracy: 0.5705 - val_loss: 0.6185 - val_accuracy: 0.6812\n",
            "Epoch 17/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.6501 - accuracy: 0.5784 - val_loss: 0.6058 - val_accuracy: 0.6750\n",
            "Epoch 18/200\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.6627 - accuracy: 0.5674 - val_loss: 0.6081 - val_accuracy: 0.6750\n",
            "Epoch 19/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.6595 - accuracy: 0.5674 - val_loss: 0.6062 - val_accuracy: 0.6750\n",
            "Epoch 20/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.6521 - accuracy: 0.5940 - val_loss: 0.6088 - val_accuracy: 0.6750\n",
            "Epoch 21/200\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.6676 - accuracy: 0.5376 - val_loss: 0.6054 - val_accuracy: 0.6687\n",
            "Epoch 22/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.6472 - accuracy: 0.5799 - val_loss: 0.6041 - val_accuracy: 0.6812\n",
            "Epoch 23/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.6528 - accuracy: 0.5878 - val_loss: 0.6045 - val_accuracy: 0.6750\n",
            "Epoch 24/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.6373 - accuracy: 0.5909 - val_loss: 0.6085 - val_accuracy: 0.6750\n",
            "Epoch 25/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.6492 - accuracy: 0.6019 - val_loss: 0.6062 - val_accuracy: 0.6750\n",
            "Epoch 26/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.6550 - accuracy: 0.5737 - val_loss: 0.6054 - val_accuracy: 0.6750\n",
            "Epoch 27/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.6473 - accuracy: 0.5815 - val_loss: 0.6021 - val_accuracy: 0.6750\n",
            "Epoch 28/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.6429 - accuracy: 0.5862 - val_loss: 0.6042 - val_accuracy: 0.6750\n",
            "Epoch 29/200\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.6449 - accuracy: 0.6082 - val_loss: 0.6030 - val_accuracy: 0.6812\n",
            "Epoch 30/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.6474 - accuracy: 0.5878 - val_loss: 0.6056 - val_accuracy: 0.7000\n",
            "Epoch 31/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.6449 - accuracy: 0.5909 - val_loss: 0.6063 - val_accuracy: 0.6938\n",
            "Epoch 32/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.6394 - accuracy: 0.5987 - val_loss: 0.6069 - val_accuracy: 0.7188\n",
            "Epoch 33/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.6288 - accuracy: 0.6113 - val_loss: 0.6046 - val_accuracy: 0.7188\n",
            "Epoch 34/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.6455 - accuracy: 0.6097 - val_loss: 0.6035 - val_accuracy: 0.7063\n",
            "Epoch 35/200\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.6358 - accuracy: 0.6034 - val_loss: 0.5993 - val_accuracy: 0.7312\n",
            "Epoch 36/200\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.6279 - accuracy: 0.6379 - val_loss: 0.5984 - val_accuracy: 0.7437\n",
            "Epoch 37/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.6263 - accuracy: 0.6332 - val_loss: 0.5957 - val_accuracy: 0.7250\n",
            "Epoch 38/200\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.6288 - accuracy: 0.6536 - val_loss: 0.5896 - val_accuracy: 0.7250\n",
            "Epoch 39/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.6235 - accuracy: 0.6426 - val_loss: 0.5910 - val_accuracy: 0.7188\n",
            "Epoch 40/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.6327 - accuracy: 0.6520 - val_loss: 0.5915 - val_accuracy: 0.7437\n",
            "Epoch 41/200\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.6321 - accuracy: 0.6254 - val_loss: 0.5922 - val_accuracy: 0.7375\n",
            "Epoch 42/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.6261 - accuracy: 0.6473 - val_loss: 0.5926 - val_accuracy: 0.7375\n",
            "Epoch 43/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.6256 - accuracy: 0.6505 - val_loss: 0.5940 - val_accuracy: 0.7312\n",
            "Epoch 44/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.6240 - accuracy: 0.6426 - val_loss: 0.5833 - val_accuracy: 0.7625\n",
            "Epoch 45/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.6134 - accuracy: 0.6818 - val_loss: 0.5866 - val_accuracy: 0.7563\n",
            "Epoch 46/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.6174 - accuracy: 0.6630 - val_loss: 0.5747 - val_accuracy: 0.7750\n",
            "Epoch 47/200\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.6168 - accuracy: 0.6787 - val_loss: 0.5733 - val_accuracy: 0.7625\n",
            "Epoch 48/200\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.6135 - accuracy: 0.6991 - val_loss: 0.5682 - val_accuracy: 0.7563\n",
            "Epoch 49/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.6104 - accuracy: 0.6426 - val_loss: 0.5694 - val_accuracy: 0.7625\n",
            "Epoch 50/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.6140 - accuracy: 0.6614 - val_loss: 0.5707 - val_accuracy: 0.7750\n",
            "Epoch 51/200\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.6080 - accuracy: 0.6834 - val_loss: 0.5706 - val_accuracy: 0.7750\n",
            "Epoch 52/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.5998 - accuracy: 0.6771 - val_loss: 0.5701 - val_accuracy: 0.7563\n",
            "Epoch 53/200\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.6152 - accuracy: 0.6646 - val_loss: 0.5643 - val_accuracy: 0.7688\n",
            "Epoch 54/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.5984 - accuracy: 0.6991 - val_loss: 0.5625 - val_accuracy: 0.7688\n",
            "Epoch 55/200\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.5795 - accuracy: 0.6928 - val_loss: 0.5530 - val_accuracy: 0.7812\n",
            "Epoch 56/200\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.5862 - accuracy: 0.7022 - val_loss: 0.5430 - val_accuracy: 0.7875\n",
            "Epoch 57/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.5821 - accuracy: 0.7116 - val_loss: 0.5426 - val_accuracy: 0.7812\n",
            "Epoch 58/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.5725 - accuracy: 0.7445 - val_loss: 0.5389 - val_accuracy: 0.7750\n",
            "Epoch 59/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.5732 - accuracy: 0.6975 - val_loss: 0.5331 - val_accuracy: 0.7937\n",
            "Epoch 60/200\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.5727 - accuracy: 0.7288 - val_loss: 0.5278 - val_accuracy: 0.7875\n",
            "Epoch 61/200\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.5522 - accuracy: 0.7398 - val_loss: 0.5266 - val_accuracy: 0.7688\n",
            "Epoch 62/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.5767 - accuracy: 0.7273 - val_loss: 0.5212 - val_accuracy: 0.8000\n",
            "Epoch 63/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.5629 - accuracy: 0.7273 - val_loss: 0.5163 - val_accuracy: 0.8062\n",
            "Epoch 64/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.5659 - accuracy: 0.7445 - val_loss: 0.5151 - val_accuracy: 0.8000\n",
            "Epoch 65/200\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.5713 - accuracy: 0.7257 - val_loss: 0.5136 - val_accuracy: 0.8000\n",
            "Epoch 66/200\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.5488 - accuracy: 0.7320 - val_loss: 0.5175 - val_accuracy: 0.7688\n",
            "Epoch 67/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.5295 - accuracy: 0.7618 - val_loss: 0.5036 - val_accuracy: 0.8188\n",
            "Epoch 68/200\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.5549 - accuracy: 0.7508 - val_loss: 0.4965 - val_accuracy: 0.8062\n",
            "Epoch 69/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.5458 - accuracy: 0.7414 - val_loss: 0.4949 - val_accuracy: 0.8188\n",
            "Epoch 70/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.5484 - accuracy: 0.7539 - val_loss: 0.5011 - val_accuracy: 0.8125\n",
            "Epoch 71/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.5379 - accuracy: 0.7571 - val_loss: 0.4937 - val_accuracy: 0.7937\n",
            "Epoch 72/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.5180 - accuracy: 0.7680 - val_loss: 0.4902 - val_accuracy: 0.8000\n",
            "Epoch 73/200\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.5196 - accuracy: 0.7806 - val_loss: 0.4898 - val_accuracy: 0.8125\n",
            "Epoch 74/200\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.5160 - accuracy: 0.7790 - val_loss: 0.4910 - val_accuracy: 0.7937\n",
            "Epoch 75/200\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.5422 - accuracy: 0.7508 - val_loss: 0.4783 - val_accuracy: 0.8250\n",
            "Epoch 76/200\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.5136 - accuracy: 0.7900 - val_loss: 0.4818 - val_accuracy: 0.8062\n",
            "Epoch 77/200\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.5156 - accuracy: 0.7712 - val_loss: 0.4766 - val_accuracy: 0.8062\n",
            "Epoch 78/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.5073 - accuracy: 0.8041 - val_loss: 0.4816 - val_accuracy: 0.8062\n",
            "Epoch 79/200\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.5005 - accuracy: 0.7962 - val_loss: 0.4728 - val_accuracy: 0.8125\n",
            "Epoch 80/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.5096 - accuracy: 0.7853 - val_loss: 0.4647 - val_accuracy: 0.8250\n",
            "Epoch 81/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.4943 - accuracy: 0.7931 - val_loss: 0.4601 - val_accuracy: 0.8313\n",
            "Epoch 82/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.4968 - accuracy: 0.7790 - val_loss: 0.4608 - val_accuracy: 0.8313\n",
            "Epoch 83/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.4692 - accuracy: 0.8009 - val_loss: 0.4616 - val_accuracy: 0.8313\n",
            "Epoch 84/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.4846 - accuracy: 0.7931 - val_loss: 0.4502 - val_accuracy: 0.8375\n",
            "Epoch 85/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.4647 - accuracy: 0.8088 - val_loss: 0.4490 - val_accuracy: 0.8375\n",
            "Epoch 86/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.4741 - accuracy: 0.7806 - val_loss: 0.4501 - val_accuracy: 0.8250\n",
            "Epoch 87/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.4567 - accuracy: 0.8276 - val_loss: 0.4475 - val_accuracy: 0.8375\n",
            "Epoch 88/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.4596 - accuracy: 0.8182 - val_loss: 0.4400 - val_accuracy: 0.8375\n",
            "Epoch 89/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.4504 - accuracy: 0.8182 - val_loss: 0.4528 - val_accuracy: 0.8375\n",
            "Epoch 90/200\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.4720 - accuracy: 0.7978 - val_loss: 0.4926 - val_accuracy: 0.7937\n",
            "Epoch 91/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.4609 - accuracy: 0.8119 - val_loss: 0.4428 - val_accuracy: 0.8250\n",
            "Epoch 92/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.4482 - accuracy: 0.8119 - val_loss: 0.4335 - val_accuracy: 0.8375\n",
            "Epoch 93/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.4455 - accuracy: 0.8245 - val_loss: 0.4378 - val_accuracy: 0.8438\n",
            "Epoch 94/200\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.4420 - accuracy: 0.8260 - val_loss: 0.4268 - val_accuracy: 0.8438\n",
            "Epoch 95/200\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.4574 - accuracy: 0.8119 - val_loss: 0.4408 - val_accuracy: 0.8313\n",
            "Epoch 96/200\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.4592 - accuracy: 0.8292 - val_loss: 0.4373 - val_accuracy: 0.8375\n",
            "Epoch 97/200\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.4388 - accuracy: 0.8417 - val_loss: 0.4198 - val_accuracy: 0.8438\n",
            "Epoch 98/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.4427 - accuracy: 0.8229 - val_loss: 0.4207 - val_accuracy: 0.8438\n",
            "Epoch 99/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.4367 - accuracy: 0.8417 - val_loss: 0.4160 - val_accuracy: 0.8562\n",
            "Epoch 100/200\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.4247 - accuracy: 0.8433 - val_loss: 0.4164 - val_accuracy: 0.8500\n",
            "Epoch 101/200\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.4122 - accuracy: 0.8386 - val_loss: 0.4236 - val_accuracy: 0.8500\n",
            "Epoch 102/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.4333 - accuracy: 0.8229 - val_loss: 0.4223 - val_accuracy: 0.8562\n",
            "Epoch 103/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.4360 - accuracy: 0.8448 - val_loss: 0.4161 - val_accuracy: 0.8500\n",
            "Epoch 104/200\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.4513 - accuracy: 0.8197 - val_loss: 0.4070 - val_accuracy: 0.8500\n",
            "Epoch 105/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.4101 - accuracy: 0.8433 - val_loss: 0.4135 - val_accuracy: 0.8687\n",
            "Epoch 106/200\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.4197 - accuracy: 0.8401 - val_loss: 0.4129 - val_accuracy: 0.8625\n",
            "Epoch 107/200\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.3844 - accuracy: 0.8605 - val_loss: 0.4099 - val_accuracy: 0.8562\n",
            "Epoch 108/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.4036 - accuracy: 0.8386 - val_loss: 0.4075 - val_accuracy: 0.8625\n",
            "Epoch 109/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.4242 - accuracy: 0.8339 - val_loss: 0.4103 - val_accuracy: 0.8750\n",
            "Epoch 110/200\n",
            "20/20 [==============================] - 0s 6ms/step - loss: 0.4018 - accuracy: 0.8307 - val_loss: 0.4179 - val_accuracy: 0.8500\n",
            "Epoch 111/200\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.4150 - accuracy: 0.8417 - val_loss: 0.4017 - val_accuracy: 0.8687\n",
            "Epoch 112/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.3858 - accuracy: 0.8495 - val_loss: 0.4213 - val_accuracy: 0.8375\n",
            "Epoch 113/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.4156 - accuracy: 0.8213 - val_loss: 0.4158 - val_accuracy: 0.8562\n",
            "Epoch 114/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.3958 - accuracy: 0.8386 - val_loss: 0.3977 - val_accuracy: 0.8562\n",
            "Epoch 115/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.3911 - accuracy: 0.8448 - val_loss: 0.4028 - val_accuracy: 0.8750\n",
            "Epoch 116/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.3984 - accuracy: 0.8527 - val_loss: 0.3971 - val_accuracy: 0.8500\n",
            "Epoch 117/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.4053 - accuracy: 0.8527 - val_loss: 0.4133 - val_accuracy: 0.8500\n",
            "Epoch 118/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.3842 - accuracy: 0.8495 - val_loss: 0.3952 - val_accuracy: 0.8687\n",
            "Epoch 119/200\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.3877 - accuracy: 0.8511 - val_loss: 0.3925 - val_accuracy: 0.8625\n",
            "Epoch 120/200\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.3766 - accuracy: 0.8480 - val_loss: 0.3984 - val_accuracy: 0.8625\n",
            "Epoch 121/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.3787 - accuracy: 0.8542 - val_loss: 0.3866 - val_accuracy: 0.8687\n",
            "Epoch 122/200\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.3772 - accuracy: 0.8652 - val_loss: 0.3906 - val_accuracy: 0.8687\n",
            "Epoch 123/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.3842 - accuracy: 0.8511 - val_loss: 0.3835 - val_accuracy: 0.8687\n",
            "Epoch 124/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.3746 - accuracy: 0.8527 - val_loss: 0.3861 - val_accuracy: 0.8562\n",
            "Epoch 125/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.4168 - accuracy: 0.8119 - val_loss: 0.4072 - val_accuracy: 0.8438\n",
            "Epoch 126/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.3819 - accuracy: 0.8558 - val_loss: 0.4068 - val_accuracy: 0.8438\n",
            "Epoch 127/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.4072 - accuracy: 0.8370 - val_loss: 0.4046 - val_accuracy: 0.8562\n",
            "Epoch 128/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.3801 - accuracy: 0.8558 - val_loss: 0.3984 - val_accuracy: 0.8500\n",
            "Epoch 129/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.3925 - accuracy: 0.8542 - val_loss: 0.3795 - val_accuracy: 0.8625\n",
            "Epoch 130/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.3633 - accuracy: 0.8589 - val_loss: 0.4233 - val_accuracy: 0.8438\n",
            "Epoch 131/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.3801 - accuracy: 0.8495 - val_loss: 0.3937 - val_accuracy: 0.8438\n",
            "Epoch 132/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.3889 - accuracy: 0.8401 - val_loss: 0.3973 - val_accuracy: 0.8375\n",
            "Epoch 133/200\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.3717 - accuracy: 0.8542 - val_loss: 0.3802 - val_accuracy: 0.8625\n",
            "Epoch 134/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.3658 - accuracy: 0.8511 - val_loss: 0.3794 - val_accuracy: 0.8625\n",
            "Epoch 135/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.3787 - accuracy: 0.8527 - val_loss: 0.3947 - val_accuracy: 0.8562\n",
            "Epoch 136/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.3557 - accuracy: 0.8589 - val_loss: 0.3741 - val_accuracy: 0.8687\n",
            "Epoch 137/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.3761 - accuracy: 0.8542 - val_loss: 0.3775 - val_accuracy: 0.8500\n",
            "Epoch 138/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.3555 - accuracy: 0.8652 - val_loss: 0.3800 - val_accuracy: 0.8687\n",
            "Epoch 139/200\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.3613 - accuracy: 0.8558 - val_loss: 0.3832 - val_accuracy: 0.8562\n",
            "Epoch 140/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.3555 - accuracy: 0.8574 - val_loss: 0.3801 - val_accuracy: 0.8500\n",
            "Epoch 141/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.3553 - accuracy: 0.8621 - val_loss: 0.3873 - val_accuracy: 0.8750\n",
            "Epoch 142/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.3538 - accuracy: 0.8636 - val_loss: 0.3709 - val_accuracy: 0.8687\n",
            "Epoch 143/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.3459 - accuracy: 0.8621 - val_loss: 0.3886 - val_accuracy: 0.8375\n",
            "Epoch 144/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.3512 - accuracy: 0.8668 - val_loss: 0.3737 - val_accuracy: 0.8687\n",
            "Epoch 145/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.3647 - accuracy: 0.8574 - val_loss: 0.3862 - val_accuracy: 0.8562\n",
            "Epoch 146/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.3449 - accuracy: 0.8683 - val_loss: 0.3687 - val_accuracy: 0.8562\n",
            "Epoch 147/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.3523 - accuracy: 0.8652 - val_loss: 0.3696 - val_accuracy: 0.8687\n",
            "Epoch 148/200\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.3561 - accuracy: 0.8715 - val_loss: 0.3844 - val_accuracy: 0.8562\n",
            "Epoch 149/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.3500 - accuracy: 0.8652 - val_loss: 0.3780 - val_accuracy: 0.8562\n",
            "Epoch 150/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.3398 - accuracy: 0.8683 - val_loss: 0.3747 - val_accuracy: 0.8562\n",
            "Epoch 151/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.3478 - accuracy: 0.8621 - val_loss: 0.3706 - val_accuracy: 0.8500\n",
            "Epoch 152/200\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.3646 - accuracy: 0.8558 - val_loss: 0.4161 - val_accuracy: 0.8375\n",
            "Epoch 153/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.3755 - accuracy: 0.8464 - val_loss: 0.4055 - val_accuracy: 0.8562\n",
            "Epoch 154/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.3552 - accuracy: 0.8464 - val_loss: 0.3617 - val_accuracy: 0.8562\n",
            "Epoch 155/200\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.3464 - accuracy: 0.8683 - val_loss: 0.3790 - val_accuracy: 0.8562\n",
            "Epoch 156/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.3350 - accuracy: 0.8589 - val_loss: 0.3640 - val_accuracy: 0.8500\n",
            "Epoch 157/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.3527 - accuracy: 0.8589 - val_loss: 0.3932 - val_accuracy: 0.8313\n",
            "Epoch 158/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.3552 - accuracy: 0.8558 - val_loss: 0.3881 - val_accuracy: 0.8500\n",
            "Epoch 159/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.3629 - accuracy: 0.8589 - val_loss: 0.3744 - val_accuracy: 0.8687\n",
            "Epoch 160/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.3460 - accuracy: 0.8668 - val_loss: 0.3699 - val_accuracy: 0.8500\n",
            "Epoch 161/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.3439 - accuracy: 0.8621 - val_loss: 0.3721 - val_accuracy: 0.8375\n",
            "Epoch 162/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.3602 - accuracy: 0.8511 - val_loss: 0.3699 - val_accuracy: 0.8625\n",
            "Epoch 163/200\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.3435 - accuracy: 0.8621 - val_loss: 0.3798 - val_accuracy: 0.8375\n",
            "Epoch 164/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.3566 - accuracy: 0.8636 - val_loss: 0.3749 - val_accuracy: 0.8500\n",
            "Epoch 165/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.3481 - accuracy: 0.8636 - val_loss: 0.3749 - val_accuracy: 0.8687\n",
            "Epoch 166/200\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.3549 - accuracy: 0.8558 - val_loss: 0.3715 - val_accuracy: 0.8625\n",
            "Epoch 167/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.3202 - accuracy: 0.8762 - val_loss: 0.3858 - val_accuracy: 0.8562\n",
            "Epoch 168/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.3425 - accuracy: 0.8652 - val_loss: 0.3677 - val_accuracy: 0.8500\n",
            "Epoch 169/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.3475 - accuracy: 0.8699 - val_loss: 0.3618 - val_accuracy: 0.8438\n",
            "Epoch 170/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.3383 - accuracy: 0.8746 - val_loss: 0.3713 - val_accuracy: 0.8500\n",
            "Epoch 171/200\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.3491 - accuracy: 0.8683 - val_loss: 0.3757 - val_accuracy: 0.8313\n",
            "Epoch 172/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.3514 - accuracy: 0.8511 - val_loss: 0.4124 - val_accuracy: 0.8500\n",
            "Epoch 173/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.3527 - accuracy: 0.8668 - val_loss: 0.3674 - val_accuracy: 0.8375\n",
            "Epoch 174/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.3338 - accuracy: 0.8558 - val_loss: 0.3911 - val_accuracy: 0.8562\n",
            "Epoch 175/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.3321 - accuracy: 0.8777 - val_loss: 0.3517 - val_accuracy: 0.8500\n",
            "Epoch 176/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.3391 - accuracy: 0.8699 - val_loss: 0.3720 - val_accuracy: 0.8375\n",
            "Epoch 177/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.3500 - accuracy: 0.8589 - val_loss: 0.3584 - val_accuracy: 0.8562\n",
            "Epoch 178/200\n",
            "20/20 [==============================] - 0s 6ms/step - loss: 0.3274 - accuracy: 0.8746 - val_loss: 0.3618 - val_accuracy: 0.8625\n",
            "Epoch 179/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.3235 - accuracy: 0.8699 - val_loss: 0.3789 - val_accuracy: 0.8562\n",
            "Epoch 180/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.3197 - accuracy: 0.8621 - val_loss: 0.3791 - val_accuracy: 0.8562\n",
            "Epoch 181/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.3291 - accuracy: 0.8589 - val_loss: 0.3702 - val_accuracy: 0.8375\n",
            "Epoch 182/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.3258 - accuracy: 0.8730 - val_loss: 0.3934 - val_accuracy: 0.8500\n",
            "Epoch 183/200\n",
            "20/20 [==============================] - 0s 6ms/step - loss: 0.3191 - accuracy: 0.8621 - val_loss: 0.3560 - val_accuracy: 0.8687\n",
            "Epoch 184/200\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.3300 - accuracy: 0.8683 - val_loss: 0.3862 - val_accuracy: 0.8500\n",
            "Epoch 185/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.3331 - accuracy: 0.8621 - val_loss: 0.3653 - val_accuracy: 0.8625\n",
            "Epoch 186/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.3399 - accuracy: 0.8699 - val_loss: 0.3816 - val_accuracy: 0.8438\n",
            "Epoch 187/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.3249 - accuracy: 0.8683 - val_loss: 0.3639 - val_accuracy: 0.8625\n",
            "Epoch 188/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.3115 - accuracy: 0.8746 - val_loss: 0.3617 - val_accuracy: 0.8562\n",
            "Epoch 189/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.3235 - accuracy: 0.8683 - val_loss: 0.3678 - val_accuracy: 0.8438\n",
            "Epoch 190/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.3268 - accuracy: 0.8668 - val_loss: 0.3676 - val_accuracy: 0.8625\n",
            "Epoch 191/200\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.3109 - accuracy: 0.8715 - val_loss: 0.3920 - val_accuracy: 0.8562\n",
            "Epoch 192/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.3360 - accuracy: 0.8636 - val_loss: 0.3946 - val_accuracy: 0.8500\n",
            "Epoch 193/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.3205 - accuracy: 0.8746 - val_loss: 0.3661 - val_accuracy: 0.8562\n",
            "Epoch 194/200\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.3369 - accuracy: 0.8699 - val_loss: 0.3802 - val_accuracy: 0.8188\n",
            "Epoch 195/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.3242 - accuracy: 0.8636 - val_loss: 0.3638 - val_accuracy: 0.8750\n",
            "Epoch 196/200\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.3422 - accuracy: 0.8605 - val_loss: 0.3642 - val_accuracy: 0.8500\n",
            "Epoch 197/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.3237 - accuracy: 0.8558 - val_loss: 0.3737 - val_accuracy: 0.8562\n",
            "Epoch 198/200\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.3219 - accuracy: 0.8699 - val_loss: 0.3555 - val_accuracy: 0.8750\n",
            "Epoch 199/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.3287 - accuracy: 0.8715 - val_loss: 0.3616 - val_accuracy: 0.8500\n",
            "Epoch 200/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.3348 - accuracy: 0.8652 - val_loss: 0.3651 - val_accuracy: 0.8500\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.4399 - accuracy: 0.8000\n",
            "## evaluation loss and_metrics ##\n",
            "[0.43990591168403625, 0.800000011920929]\n",
            "4/4 [==============================] - 0s 3ms/step\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0, 1, 1, 1, 0, 1, 1, 0, 1, 1, 0, 0, 0, 0, 1, 1, 0, 1, 1, 0, 1, 0,\n",
              "       0, 0, 1, 1, 0, 1, 0, 0, 1, 1, 0, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 0,\n",
              "       0, 0, 1, 1, 1, 0, 1, 0, 1, 1, 1, 0, 0, 1, 1, 1, 0, 0, 0, 1, 0, 1,\n",
              "       1, 1, 1, 1, 0, 0, 1, 1, 0, 1, 0, 1, 0, 1, 1, 1, 1, 0, 1, 1, 0, 1,\n",
              "       0, 0, 1, 1, 1, 0, 0, 0, 1, 0, 1, 1, 0, 1, 1, 0, 1, 1, 0, 1, 1, 0,\n",
              "       1, 1, 0, 1, 1, 0, 1, 0, 1, 0])"
            ]
          },
          "metadata": {},
          "execution_count": 85
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "np.mean(y_test == y_pred_classSex_F)"
      ],
      "metadata": {
        "id": "GUf6imzaxBS3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Sex_Fscore=recall_score(y_test,y_pred_classSex_F)\n",
        "print(Sex_Fscore)"
      ],
      "metadata": {
        "id": "xMOQ1J2AxBeL",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4592d352-4dde-4199-f6e2-ec9d76809da0"
      },
      "execution_count": 86,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.6857142857142857\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Sex_M"
      ],
      "metadata": {
        "id": "CU2heTO_quuG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "heart = pd.read_csv(f_path)\n",
        "\n",
        "heart = pd.get_dummies(heart)\n",
        "\n",
        "x = heart.drop('HeartDisease', axis=1)\n",
        "y = pd.get_dummies(heart[\"HeartDisease\"])\n",
        "\n",
        "heart['Sex_M'] = 0\n",
        "\n",
        "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size = 0.13,shuffle=True, random_state = 42)\n",
        "\n",
        "print(\"X_train: \", x_train.shape)\n",
        "print(\"y_train: \", y_train.shape)\n",
        "\n",
        "print(\"X_test: \", x_test.shape)\n",
        "print(\"y_test: \", y_test.shape)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "ModelExceptSex_M = Sequential()\n",
        "\n",
        "\n",
        "ModelExceptSex_M.add(Dense(128, activation = \"relu\",input_dim=20))\n",
        "ModelExceptSex_M.add(Dropout(rate=0.2))\n",
        "ModelExceptSex_M.add(Dense(64, activation = \"relu\"))\n",
        "ModelExceptSex_M.add(Dropout(rate=0.2))\n",
        "ModelExceptSex_M.add(Dense(32, activation = \"relu\"))\n",
        "ModelExceptSex_M.add(Dropout(rate=0.1))\n",
        "ModelExceptSex_M.add(Dense(16, activation = \"relu\"))\n",
        "ModelExceptSex_M.add(Dense(8, activation = \"relu\"))\n",
        "ModelExceptSex_M.add(Dense(2, activation = \"sigmoid\"))\n",
        "\n",
        "ModelExceptSex_M.compile(optimizer = \"adam\", loss = \"categorical_crossentropy\", metrics = [\"accuracy\"])\n",
        "ModelExceptSex_M.summary()\n",
        "\n",
        "hin=ModelExceptSex_M.fit(x_train,y_train,epochs=200, validation_split=0.2)\n",
        "\n",
        "loss_and_metrics = ModelExceptSex_M.evaluate(x_test, y_test, batch_size=32)\n",
        "print('## evaluation loss and_metrics ##')\n",
        "print(loss_and_metrics)\n",
        "\n",
        "y_predSex_M = ModelExceptSex_M.predict(x_test)\n",
        "y_predSex_M\n",
        "\n",
        "y_pred_classSex_M = np.argmax(y_predSex_M, axis=1)\n",
        "y_pred_classSex_M\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "y_test  = y_test.to_numpy()\n",
        "y_test\n",
        "\n",
        "y_test = np.argmax(y_test,axis=1)\n",
        "y_test\n",
        "\n"
      ],
      "metadata": {
        "id": "zQQXDeenx_n6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d882f0c2-dfbf-4513-f26d-8b84cc5d06be"
      },
      "execution_count": 87,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "X_train:  (798, 20)\n",
            "y_train:  (798, 2)\n",
            "X_test:  (120, 20)\n",
            "y_test:  (120, 2)\n",
            "Model: \"sequential_12\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense_72 (Dense)            (None, 128)               2688      \n",
            "                                                                 \n",
            " dropout_36 (Dropout)        (None, 128)               0         \n",
            "                                                                 \n",
            " dense_73 (Dense)            (None, 64)                8256      \n",
            "                                                                 \n",
            " dropout_37 (Dropout)        (None, 64)                0         \n",
            "                                                                 \n",
            " dense_74 (Dense)            (None, 32)                2080      \n",
            "                                                                 \n",
            " dropout_38 (Dropout)        (None, 32)                0         \n",
            "                                                                 \n",
            " dense_75 (Dense)            (None, 16)                528       \n",
            "                                                                 \n",
            " dense_76 (Dense)            (None, 8)                 136       \n",
            "                                                                 \n",
            " dense_77 (Dense)            (None, 2)                 18        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 13,706\n",
            "Trainable params: 13,706\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/200\n",
            "20/20 [==============================] - 1s 12ms/step - loss: 2.4053 - accuracy: 0.5831 - val_loss: 0.5663 - val_accuracy: 0.7563\n",
            "Epoch 2/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 1.1536 - accuracy: 0.5486 - val_loss: 0.6749 - val_accuracy: 0.6687\n",
            "Epoch 3/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.8528 - accuracy: 0.5517 - val_loss: 0.6519 - val_accuracy: 0.6500\n",
            "Epoch 4/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.7802 - accuracy: 0.5611 - val_loss: 0.6371 - val_accuracy: 0.6625\n",
            "Epoch 5/200\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.7521 - accuracy: 0.5674 - val_loss: 0.6089 - val_accuracy: 0.6750\n",
            "Epoch 6/200\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.7088 - accuracy: 0.5768 - val_loss: 0.6031 - val_accuracy: 0.6875\n",
            "Epoch 7/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.6875 - accuracy: 0.5768 - val_loss: 0.6122 - val_accuracy: 0.6750\n",
            "Epoch 8/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.6811 - accuracy: 0.5940 - val_loss: 0.6051 - val_accuracy: 0.6750\n",
            "Epoch 9/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.6849 - accuracy: 0.6003 - val_loss: 0.6052 - val_accuracy: 0.6750\n",
            "Epoch 10/200\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.6645 - accuracy: 0.5611 - val_loss: 0.6131 - val_accuracy: 0.6687\n",
            "Epoch 11/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.6691 - accuracy: 0.5940 - val_loss: 0.6066 - val_accuracy: 0.6750\n",
            "Epoch 12/200\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.6626 - accuracy: 0.5862 - val_loss: 0.6117 - val_accuracy: 0.6687\n",
            "Epoch 13/200\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.6931 - accuracy: 0.5408 - val_loss: 0.6104 - val_accuracy: 0.6750\n",
            "Epoch 14/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.6564 - accuracy: 0.5987 - val_loss: 0.6082 - val_accuracy: 0.6750\n",
            "Epoch 15/200\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.6685 - accuracy: 0.5596 - val_loss: 0.6312 - val_accuracy: 0.4938\n",
            "Epoch 16/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.6342 - accuracy: 0.5596 - val_loss: 0.6153 - val_accuracy: 0.7000\n",
            "Epoch 17/200\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.6512 - accuracy: 0.5784 - val_loss: 0.6161 - val_accuracy: 0.6313\n",
            "Epoch 18/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.6578 - accuracy: 0.5674 - val_loss: 0.6091 - val_accuracy: 0.6687\n",
            "Epoch 19/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.6365 - accuracy: 0.5956 - val_loss: 0.6135 - val_accuracy: 0.7125\n",
            "Epoch 20/200\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.6557 - accuracy: 0.5799 - val_loss: 0.6137 - val_accuracy: 0.7188\n",
            "Epoch 21/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.6628 - accuracy: 0.5721 - val_loss: 0.6141 - val_accuracy: 0.7000\n",
            "Epoch 22/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.6479 - accuracy: 0.6270 - val_loss: 0.6091 - val_accuracy: 0.6750\n",
            "Epoch 23/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.6655 - accuracy: 0.5940 - val_loss: 0.6062 - val_accuracy: 0.6750\n",
            "Epoch 24/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.6503 - accuracy: 0.5925 - val_loss: 0.6167 - val_accuracy: 0.6750\n",
            "Epoch 25/200\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.6422 - accuracy: 0.6097 - val_loss: 0.6041 - val_accuracy: 0.6750\n",
            "Epoch 26/200\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.6450 - accuracy: 0.5846 - val_loss: 0.6170 - val_accuracy: 0.6438\n",
            "Epoch 27/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.6329 - accuracy: 0.6144 - val_loss: 0.6018 - val_accuracy: 0.6750\n",
            "Epoch 28/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.6292 - accuracy: 0.6160 - val_loss: 0.5976 - val_accuracy: 0.6812\n",
            "Epoch 29/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.6392 - accuracy: 0.6270 - val_loss: 0.5796 - val_accuracy: 0.7625\n",
            "Epoch 30/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.6123 - accuracy: 0.6489 - val_loss: 0.5857 - val_accuracy: 0.7250\n",
            "Epoch 31/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.6287 - accuracy: 0.6614 - val_loss: 0.6054 - val_accuracy: 0.6438\n",
            "Epoch 32/200\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.6214 - accuracy: 0.6787 - val_loss: 0.5901 - val_accuracy: 0.6625\n",
            "Epoch 33/200\n",
            "20/20 [==============================] - 0s 6ms/step - loss: 0.6311 - accuracy: 0.6458 - val_loss: 0.5704 - val_accuracy: 0.7312\n",
            "Epoch 34/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.6013 - accuracy: 0.6583 - val_loss: 0.5421 - val_accuracy: 0.7688\n",
            "Epoch 35/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.5982 - accuracy: 0.6818 - val_loss: 0.5402 - val_accuracy: 0.7437\n",
            "Epoch 36/200\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.5995 - accuracy: 0.6865 - val_loss: 0.5369 - val_accuracy: 0.7312\n",
            "Epoch 37/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.6221 - accuracy: 0.6724 - val_loss: 0.5368 - val_accuracy: 0.7750\n",
            "Epoch 38/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.6258 - accuracy: 0.6552 - val_loss: 0.5565 - val_accuracy: 0.7500\n",
            "Epoch 39/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.5833 - accuracy: 0.7116 - val_loss: 0.5328 - val_accuracy: 0.7563\n",
            "Epoch 40/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.5871 - accuracy: 0.6959 - val_loss: 0.5656 - val_accuracy: 0.7250\n",
            "Epoch 41/200\n",
            "20/20 [==============================] - 0s 6ms/step - loss: 0.6169 - accuracy: 0.6850 - val_loss: 0.5282 - val_accuracy: 0.7500\n",
            "Epoch 42/200\n",
            "20/20 [==============================] - 0s 7ms/step - loss: 0.5649 - accuracy: 0.7210 - val_loss: 0.5365 - val_accuracy: 0.7625\n",
            "Epoch 43/200\n",
            "20/20 [==============================] - 0s 6ms/step - loss: 0.5571 - accuracy: 0.7414 - val_loss: 0.5708 - val_accuracy: 0.7063\n",
            "Epoch 44/200\n",
            "20/20 [==============================] - 0s 6ms/step - loss: 0.5533 - accuracy: 0.7351 - val_loss: 0.5124 - val_accuracy: 0.7625\n",
            "Epoch 45/200\n",
            "20/20 [==============================] - 0s 7ms/step - loss: 0.5641 - accuracy: 0.7257 - val_loss: 0.5351 - val_accuracy: 0.7500\n",
            "Epoch 46/200\n",
            "20/20 [==============================] - 0s 7ms/step - loss: 0.5382 - accuracy: 0.7429 - val_loss: 0.5136 - val_accuracy: 0.7563\n",
            "Epoch 47/200\n",
            "20/20 [==============================] - 0s 7ms/step - loss: 0.5808 - accuracy: 0.7053 - val_loss: 0.5238 - val_accuracy: 0.7437\n",
            "Epoch 48/200\n",
            "20/20 [==============================] - 0s 6ms/step - loss: 0.5691 - accuracy: 0.7257 - val_loss: 0.4992 - val_accuracy: 0.7750\n",
            "Epoch 49/200\n",
            "20/20 [==============================] - 0s 6ms/step - loss: 0.5516 - accuracy: 0.7257 - val_loss: 0.5294 - val_accuracy: 0.7500\n",
            "Epoch 50/200\n",
            "20/20 [==============================] - 0s 7ms/step - loss: 0.5310 - accuracy: 0.7476 - val_loss: 0.5200 - val_accuracy: 0.7500\n",
            "Epoch 51/200\n",
            "20/20 [==============================] - 0s 6ms/step - loss: 0.5526 - accuracy: 0.7382 - val_loss: 0.5043 - val_accuracy: 0.7812\n",
            "Epoch 52/200\n",
            "20/20 [==============================] - 0s 7ms/step - loss: 0.5285 - accuracy: 0.7665 - val_loss: 0.4958 - val_accuracy: 0.7812\n",
            "Epoch 53/200\n",
            "20/20 [==============================] - 0s 6ms/step - loss: 0.5207 - accuracy: 0.7602 - val_loss: 0.4913 - val_accuracy: 0.7750\n",
            "Epoch 54/200\n",
            "20/20 [==============================] - 0s 6ms/step - loss: 0.5334 - accuracy: 0.7508 - val_loss: 0.4944 - val_accuracy: 0.7875\n",
            "Epoch 55/200\n",
            "20/20 [==============================] - 0s 6ms/step - loss: 0.5181 - accuracy: 0.7665 - val_loss: 0.4843 - val_accuracy: 0.7812\n",
            "Epoch 56/200\n",
            "20/20 [==============================] - 0s 6ms/step - loss: 0.5046 - accuracy: 0.7696 - val_loss: 0.4653 - val_accuracy: 0.8000\n",
            "Epoch 57/200\n",
            "20/20 [==============================] - 0s 7ms/step - loss: 0.5235 - accuracy: 0.7602 - val_loss: 0.5034 - val_accuracy: 0.7625\n",
            "Epoch 58/200\n",
            "20/20 [==============================] - 0s 6ms/step - loss: 0.5377 - accuracy: 0.7555 - val_loss: 0.4717 - val_accuracy: 0.8000\n",
            "Epoch 59/200\n",
            "20/20 [==============================] - 0s 7ms/step - loss: 0.5028 - accuracy: 0.7759 - val_loss: 0.4637 - val_accuracy: 0.8062\n",
            "Epoch 60/200\n",
            "20/20 [==============================] - 0s 6ms/step - loss: 0.5172 - accuracy: 0.7571 - val_loss: 0.5274 - val_accuracy: 0.7437\n",
            "Epoch 61/200\n",
            "20/20 [==============================] - 0s 6ms/step - loss: 0.4978 - accuracy: 0.7837 - val_loss: 0.4672 - val_accuracy: 0.8125\n",
            "Epoch 62/200\n",
            "20/20 [==============================] - 0s 6ms/step - loss: 0.4969 - accuracy: 0.7743 - val_loss: 0.4545 - val_accuracy: 0.8250\n",
            "Epoch 63/200\n",
            "20/20 [==============================] - 0s 6ms/step - loss: 0.4782 - accuracy: 0.8009 - val_loss: 0.4624 - val_accuracy: 0.8250\n",
            "Epoch 64/200\n",
            "20/20 [==============================] - 0s 6ms/step - loss: 0.4783 - accuracy: 0.7868 - val_loss: 0.4672 - val_accuracy: 0.8062\n",
            "Epoch 65/200\n",
            "20/20 [==============================] - 0s 6ms/step - loss: 0.4680 - accuracy: 0.8041 - val_loss: 0.4405 - val_accuracy: 0.8250\n",
            "Epoch 66/200\n",
            "20/20 [==============================] - 0s 9ms/step - loss: 0.4801 - accuracy: 0.7900 - val_loss: 0.5637 - val_accuracy: 0.7000\n",
            "Epoch 67/200\n",
            "20/20 [==============================] - 0s 6ms/step - loss: 0.4958 - accuracy: 0.7900 - val_loss: 0.4481 - val_accuracy: 0.8188\n",
            "Epoch 68/200\n",
            "20/20 [==============================] - 0s 7ms/step - loss: 0.4849 - accuracy: 0.7900 - val_loss: 0.4709 - val_accuracy: 0.7937\n",
            "Epoch 69/200\n",
            "20/20 [==============================] - 0s 6ms/step - loss: 0.4683 - accuracy: 0.8041 - val_loss: 0.4362 - val_accuracy: 0.8438\n",
            "Epoch 70/200\n",
            "20/20 [==============================] - 0s 6ms/step - loss: 0.4647 - accuracy: 0.8072 - val_loss: 0.4251 - val_accuracy: 0.8313\n",
            "Epoch 71/200\n",
            "20/20 [==============================] - 0s 9ms/step - loss: 0.4657 - accuracy: 0.8103 - val_loss: 0.4456 - val_accuracy: 0.8438\n",
            "Epoch 72/200\n",
            "20/20 [==============================] - 0s 6ms/step - loss: 0.4373 - accuracy: 0.8119 - val_loss: 0.4147 - val_accuracy: 0.8375\n",
            "Epoch 73/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.4602 - accuracy: 0.7837 - val_loss: 0.4195 - val_accuracy: 0.8438\n",
            "Epoch 74/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.4506 - accuracy: 0.8119 - val_loss: 0.4557 - val_accuracy: 0.8000\n",
            "Epoch 75/200\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.4311 - accuracy: 0.8276 - val_loss: 0.4097 - val_accuracy: 0.8438\n",
            "Epoch 76/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.4389 - accuracy: 0.8041 - val_loss: 0.3961 - val_accuracy: 0.8438\n",
            "Epoch 77/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.4387 - accuracy: 0.8229 - val_loss: 0.4144 - val_accuracy: 0.8375\n",
            "Epoch 78/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.4341 - accuracy: 0.8182 - val_loss: 0.3972 - val_accuracy: 0.8438\n",
            "Epoch 79/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.4208 - accuracy: 0.8448 - val_loss: 0.4078 - val_accuracy: 0.8438\n",
            "Epoch 80/200\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.4356 - accuracy: 0.8245 - val_loss: 0.4089 - val_accuracy: 0.8375\n",
            "Epoch 81/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.4155 - accuracy: 0.8229 - val_loss: 0.4043 - val_accuracy: 0.8375\n",
            "Epoch 82/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.4207 - accuracy: 0.8166 - val_loss: 0.4500 - val_accuracy: 0.8250\n",
            "Epoch 83/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.4098 - accuracy: 0.8260 - val_loss: 0.4117 - val_accuracy: 0.8500\n",
            "Epoch 84/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.4046 - accuracy: 0.8339 - val_loss: 0.3754 - val_accuracy: 0.8500\n",
            "Epoch 85/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.4119 - accuracy: 0.8307 - val_loss: 0.4042 - val_accuracy: 0.8562\n",
            "Epoch 86/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.3875 - accuracy: 0.8495 - val_loss: 0.3845 - val_accuracy: 0.8562\n",
            "Epoch 87/200\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.4024 - accuracy: 0.8433 - val_loss: 0.4499 - val_accuracy: 0.8313\n",
            "Epoch 88/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.3848 - accuracy: 0.8464 - val_loss: 0.3739 - val_accuracy: 0.8625\n",
            "Epoch 89/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.3942 - accuracy: 0.8307 - val_loss: 0.3985 - val_accuracy: 0.8562\n",
            "Epoch 90/200\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.3622 - accuracy: 0.8574 - val_loss: 0.3932 - val_accuracy: 0.8500\n",
            "Epoch 91/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.3522 - accuracy: 0.8495 - val_loss: 0.3577 - val_accuracy: 0.8687\n",
            "Epoch 92/200\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.3745 - accuracy: 0.8558 - val_loss: 0.3581 - val_accuracy: 0.8562\n",
            "Epoch 93/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.3870 - accuracy: 0.8464 - val_loss: 0.3675 - val_accuracy: 0.8625\n",
            "Epoch 94/200\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.3755 - accuracy: 0.8542 - val_loss: 0.4037 - val_accuracy: 0.8438\n",
            "Epoch 95/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.3838 - accuracy: 0.8323 - val_loss: 0.3788 - val_accuracy: 0.8500\n",
            "Epoch 96/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.3695 - accuracy: 0.8527 - val_loss: 0.4033 - val_accuracy: 0.8375\n",
            "Epoch 97/200\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.3745 - accuracy: 0.8464 - val_loss: 0.3613 - val_accuracy: 0.8687\n",
            "Epoch 98/200\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.3756 - accuracy: 0.8354 - val_loss: 0.4011 - val_accuracy: 0.8562\n",
            "Epoch 99/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.3454 - accuracy: 0.8777 - val_loss: 0.3553 - val_accuracy: 0.8750\n",
            "Epoch 100/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.3651 - accuracy: 0.8417 - val_loss: 0.3983 - val_accuracy: 0.8438\n",
            "Epoch 101/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.3649 - accuracy: 0.8527 - val_loss: 0.4340 - val_accuracy: 0.8313\n",
            "Epoch 102/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.3585 - accuracy: 0.8495 - val_loss: 0.3944 - val_accuracy: 0.8500\n",
            "Epoch 103/200\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.3572 - accuracy: 0.8605 - val_loss: 0.3596 - val_accuracy: 0.8813\n",
            "Epoch 104/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.3476 - accuracy: 0.8558 - val_loss: 0.3957 - val_accuracy: 0.8687\n",
            "Epoch 105/200\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.3464 - accuracy: 0.8574 - val_loss: 0.3783 - val_accuracy: 0.8750\n",
            "Epoch 106/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.3316 - accuracy: 0.8746 - val_loss: 0.3851 - val_accuracy: 0.8500\n",
            "Epoch 107/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.3449 - accuracy: 0.8542 - val_loss: 0.3521 - val_accuracy: 0.8813\n",
            "Epoch 108/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.3897 - accuracy: 0.8464 - val_loss: 0.3463 - val_accuracy: 0.8687\n",
            "Epoch 109/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.3660 - accuracy: 0.8511 - val_loss: 0.3957 - val_accuracy: 0.8562\n",
            "Epoch 110/200\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.3525 - accuracy: 0.8542 - val_loss: 0.3804 - val_accuracy: 0.8562\n",
            "Epoch 111/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.3329 - accuracy: 0.8683 - val_loss: 0.4294 - val_accuracy: 0.8250\n",
            "Epoch 112/200\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.3713 - accuracy: 0.8464 - val_loss: 0.4297 - val_accuracy: 0.8313\n",
            "Epoch 113/200\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.3737 - accuracy: 0.8433 - val_loss: 0.3984 - val_accuracy: 0.8313\n",
            "Epoch 114/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.3775 - accuracy: 0.8605 - val_loss: 0.3688 - val_accuracy: 0.8687\n",
            "Epoch 115/200\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.3311 - accuracy: 0.8621 - val_loss: 0.3474 - val_accuracy: 0.8750\n",
            "Epoch 116/200\n",
            "20/20 [==============================] - 0s 7ms/step - loss: 0.3454 - accuracy: 0.8542 - val_loss: 0.4056 - val_accuracy: 0.8375\n",
            "Epoch 117/200\n",
            "20/20 [==============================] - 0s 6ms/step - loss: 0.3155 - accuracy: 0.8762 - val_loss: 0.4200 - val_accuracy: 0.8375\n",
            "Epoch 118/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.3490 - accuracy: 0.8652 - val_loss: 0.3875 - val_accuracy: 0.8500\n",
            "Epoch 119/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.3226 - accuracy: 0.8683 - val_loss: 0.4127 - val_accuracy: 0.8500\n",
            "Epoch 120/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.3368 - accuracy: 0.8636 - val_loss: 0.3859 - val_accuracy: 0.8500\n",
            "Epoch 121/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.3264 - accuracy: 0.8762 - val_loss: 0.3689 - val_accuracy: 0.8562\n",
            "Epoch 122/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.3106 - accuracy: 0.8730 - val_loss: 0.3930 - val_accuracy: 0.8438\n",
            "Epoch 123/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.3352 - accuracy: 0.8777 - val_loss: 0.3617 - val_accuracy: 0.8562\n",
            "Epoch 124/200\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.3441 - accuracy: 0.8636 - val_loss: 0.4951 - val_accuracy: 0.8062\n",
            "Epoch 125/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.3406 - accuracy: 0.8683 - val_loss: 0.3553 - val_accuracy: 0.8687\n",
            "Epoch 126/200\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.3289 - accuracy: 0.8668 - val_loss: 0.3857 - val_accuracy: 0.8625\n",
            "Epoch 127/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.3305 - accuracy: 0.8605 - val_loss: 0.3531 - val_accuracy: 0.8687\n",
            "Epoch 128/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.3284 - accuracy: 0.8777 - val_loss: 0.4080 - val_accuracy: 0.8313\n",
            "Epoch 129/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.3380 - accuracy: 0.8605 - val_loss: 0.3535 - val_accuracy: 0.8750\n",
            "Epoch 130/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.3158 - accuracy: 0.8762 - val_loss: 0.3915 - val_accuracy: 0.8500\n",
            "Epoch 131/200\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.3171 - accuracy: 0.8683 - val_loss: 0.4741 - val_accuracy: 0.8062\n",
            "Epoch 132/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.3571 - accuracy: 0.8574 - val_loss: 0.3495 - val_accuracy: 0.8750\n",
            "Epoch 133/200\n",
            "20/20 [==============================] - 0s 6ms/step - loss: 0.3256 - accuracy: 0.8762 - val_loss: 0.3722 - val_accuracy: 0.8562\n",
            "Epoch 134/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.3340 - accuracy: 0.8683 - val_loss: 0.4502 - val_accuracy: 0.8062\n",
            "Epoch 135/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.3322 - accuracy: 0.8652 - val_loss: 0.3402 - val_accuracy: 0.8750\n",
            "Epoch 136/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.3180 - accuracy: 0.8683 - val_loss: 0.4019 - val_accuracy: 0.8313\n",
            "Epoch 137/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.3177 - accuracy: 0.8809 - val_loss: 0.3547 - val_accuracy: 0.8625\n",
            "Epoch 138/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.3151 - accuracy: 0.8683 - val_loss: 0.3366 - val_accuracy: 0.8750\n",
            "Epoch 139/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.3084 - accuracy: 0.8777 - val_loss: 0.3652 - val_accuracy: 0.8625\n",
            "Epoch 140/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.3271 - accuracy: 0.8668 - val_loss: 0.3542 - val_accuracy: 0.8750\n",
            "Epoch 141/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.3205 - accuracy: 0.8574 - val_loss: 0.4049 - val_accuracy: 0.8438\n",
            "Epoch 142/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.3133 - accuracy: 0.8730 - val_loss: 0.3784 - val_accuracy: 0.8500\n",
            "Epoch 143/200\n",
            "20/20 [==============================] - 0s 6ms/step - loss: 0.3268 - accuracy: 0.8699 - val_loss: 0.3820 - val_accuracy: 0.8625\n",
            "Epoch 144/200\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.3324 - accuracy: 0.8746 - val_loss: 0.3979 - val_accuracy: 0.8375\n",
            "Epoch 145/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.3135 - accuracy: 0.8871 - val_loss: 0.3760 - val_accuracy: 0.8438\n",
            "Epoch 146/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.3347 - accuracy: 0.8699 - val_loss: 0.3611 - val_accuracy: 0.8562\n",
            "Epoch 147/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.3262 - accuracy: 0.8652 - val_loss: 0.3459 - val_accuracy: 0.8750\n",
            "Epoch 148/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.3268 - accuracy: 0.8636 - val_loss: 0.4438 - val_accuracy: 0.8062\n",
            "Epoch 149/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.3158 - accuracy: 0.8715 - val_loss: 0.3529 - val_accuracy: 0.8813\n",
            "Epoch 150/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.3208 - accuracy: 0.8636 - val_loss: 0.3752 - val_accuracy: 0.8562\n",
            "Epoch 151/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.3209 - accuracy: 0.8668 - val_loss: 0.3836 - val_accuracy: 0.8687\n",
            "Epoch 152/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.3000 - accuracy: 0.8903 - val_loss: 0.4156 - val_accuracy: 0.8438\n",
            "Epoch 153/200\n",
            "20/20 [==============================] - 0s 8ms/step - loss: 0.3083 - accuracy: 0.8715 - val_loss: 0.3912 - val_accuracy: 0.8438\n",
            "Epoch 154/200\n",
            "20/20 [==============================] - 0s 11ms/step - loss: 0.3154 - accuracy: 0.8746 - val_loss: 0.3874 - val_accuracy: 0.8438\n",
            "Epoch 155/200\n",
            "20/20 [==============================] - 0s 11ms/step - loss: 0.3080 - accuracy: 0.8683 - val_loss: 0.3598 - val_accuracy: 0.8687\n",
            "Epoch 156/200\n",
            "20/20 [==============================] - 0s 16ms/step - loss: 0.3103 - accuracy: 0.8793 - val_loss: 0.3923 - val_accuracy: 0.8438\n",
            "Epoch 157/200\n",
            "20/20 [==============================] - 0s 11ms/step - loss: 0.3112 - accuracy: 0.8730 - val_loss: 0.3822 - val_accuracy: 0.8438\n",
            "Epoch 158/200\n",
            "20/20 [==============================] - 0s 12ms/step - loss: 0.3047 - accuracy: 0.8746 - val_loss: 0.4033 - val_accuracy: 0.8188\n",
            "Epoch 159/200\n",
            "20/20 [==============================] - 0s 13ms/step - loss: 0.3184 - accuracy: 0.8652 - val_loss: 0.3620 - val_accuracy: 0.8813\n",
            "Epoch 160/200\n",
            "20/20 [==============================] - 0s 8ms/step - loss: 0.3279 - accuracy: 0.8542 - val_loss: 0.3503 - val_accuracy: 0.8625\n",
            "Epoch 161/200\n",
            "20/20 [==============================] - 0s 9ms/step - loss: 0.3076 - accuracy: 0.8762 - val_loss: 0.3866 - val_accuracy: 0.8562\n",
            "Epoch 162/200\n",
            "20/20 [==============================] - 0s 7ms/step - loss: 0.2993 - accuracy: 0.8950 - val_loss: 0.3681 - val_accuracy: 0.8500\n",
            "Epoch 163/200\n",
            "20/20 [==============================] - 0s 7ms/step - loss: 0.3193 - accuracy: 0.8652 - val_loss: 0.3826 - val_accuracy: 0.8438\n",
            "Epoch 164/200\n",
            "20/20 [==============================] - 0s 7ms/step - loss: 0.3086 - accuracy: 0.8824 - val_loss: 0.3571 - val_accuracy: 0.8687\n",
            "Epoch 165/200\n",
            "20/20 [==============================] - 0s 7ms/step - loss: 0.2929 - accuracy: 0.8856 - val_loss: 0.3595 - val_accuracy: 0.8750\n",
            "Epoch 166/200\n",
            "20/20 [==============================] - 0s 8ms/step - loss: 0.3004 - accuracy: 0.8793 - val_loss: 0.3736 - val_accuracy: 0.8562\n",
            "Epoch 167/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.3015 - accuracy: 0.8918 - val_loss: 0.3938 - val_accuracy: 0.8188\n",
            "Epoch 168/200\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.3119 - accuracy: 0.8652 - val_loss: 0.3514 - val_accuracy: 0.8625\n",
            "Epoch 169/200\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.3077 - accuracy: 0.8762 - val_loss: 0.3370 - val_accuracy: 0.8875\n",
            "Epoch 170/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.3017 - accuracy: 0.8762 - val_loss: 0.3781 - val_accuracy: 0.8313\n",
            "Epoch 171/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.3092 - accuracy: 0.8809 - val_loss: 0.3438 - val_accuracy: 0.8750\n",
            "Epoch 172/200\n",
            "20/20 [==============================] - 0s 6ms/step - loss: 0.3065 - accuracy: 0.8762 - val_loss: 0.3850 - val_accuracy: 0.8313\n",
            "Epoch 173/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.2919 - accuracy: 0.8809 - val_loss: 0.3626 - val_accuracy: 0.8562\n",
            "Epoch 174/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.3025 - accuracy: 0.8793 - val_loss: 0.4016 - val_accuracy: 0.8188\n",
            "Epoch 175/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.2953 - accuracy: 0.8840 - val_loss: 0.3414 - val_accuracy: 0.8750\n",
            "Epoch 176/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.3062 - accuracy: 0.8715 - val_loss: 0.3671 - val_accuracy: 0.8562\n",
            "Epoch 177/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.3075 - accuracy: 0.8762 - val_loss: 0.3830 - val_accuracy: 0.8250\n",
            "Epoch 178/200\n",
            "20/20 [==============================] - 0s 6ms/step - loss: 0.2974 - accuracy: 0.8871 - val_loss: 0.3877 - val_accuracy: 0.8250\n",
            "Epoch 179/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.2860 - accuracy: 0.8856 - val_loss: 0.3641 - val_accuracy: 0.8687\n",
            "Epoch 180/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.3177 - accuracy: 0.8730 - val_loss: 0.3486 - val_accuracy: 0.8500\n",
            "Epoch 181/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.3023 - accuracy: 0.8746 - val_loss: 0.3579 - val_accuracy: 0.8625\n",
            "Epoch 182/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.3012 - accuracy: 0.8840 - val_loss: 0.3398 - val_accuracy: 0.8813\n",
            "Epoch 183/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.2972 - accuracy: 0.8793 - val_loss: 0.3653 - val_accuracy: 0.8438\n",
            "Epoch 184/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.2994 - accuracy: 0.8730 - val_loss: 0.4757 - val_accuracy: 0.8062\n",
            "Epoch 185/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.3114 - accuracy: 0.8699 - val_loss: 0.3806 - val_accuracy: 0.8500\n",
            "Epoch 186/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.2893 - accuracy: 0.8887 - val_loss: 0.3466 - val_accuracy: 0.8687\n",
            "Epoch 187/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.2876 - accuracy: 0.8746 - val_loss: 0.4159 - val_accuracy: 0.8250\n",
            "Epoch 188/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.3018 - accuracy: 0.8824 - val_loss: 0.3819 - val_accuracy: 0.8438\n",
            "Epoch 189/200\n",
            "20/20 [==============================] - 0s 6ms/step - loss: 0.2751 - accuracy: 0.8856 - val_loss: 0.3560 - val_accuracy: 0.8625\n",
            "Epoch 190/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.2833 - accuracy: 0.8777 - val_loss: 0.3629 - val_accuracy: 0.8813\n",
            "Epoch 191/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.3163 - accuracy: 0.8636 - val_loss: 0.4116 - val_accuracy: 0.8313\n",
            "Epoch 192/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.3200 - accuracy: 0.8699 - val_loss: 0.4252 - val_accuracy: 0.8062\n",
            "Epoch 193/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.3104 - accuracy: 0.8824 - val_loss: 0.3427 - val_accuracy: 0.8750\n",
            "Epoch 194/200\n",
            "20/20 [==============================] - 0s 6ms/step - loss: 0.2962 - accuracy: 0.8824 - val_loss: 0.4053 - val_accuracy: 0.8313\n",
            "Epoch 195/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.2874 - accuracy: 0.8777 - val_loss: 0.4489 - val_accuracy: 0.8062\n",
            "Epoch 196/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.3060 - accuracy: 0.8668 - val_loss: 0.3885 - val_accuracy: 0.8500\n",
            "Epoch 197/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.2862 - accuracy: 0.8918 - val_loss: 0.3816 - val_accuracy: 0.8813\n",
            "Epoch 198/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.2938 - accuracy: 0.8762 - val_loss: 0.4603 - val_accuracy: 0.8125\n",
            "Epoch 199/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.2866 - accuracy: 0.8824 - val_loss: 0.3991 - val_accuracy: 0.8375\n",
            "Epoch 200/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.2777 - accuracy: 0.8903 - val_loss: 0.3770 - val_accuracy: 0.8750\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 0.3980 - accuracy: 0.8583\n",
            "## evaluation loss and_metrics ##\n",
            "[0.3979974687099457, 0.8583333492279053]\n",
            "4/4 [==============================] - 0s 4ms/step\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0, 1, 1, 1, 0, 1, 1, 0, 1, 1, 0, 0, 0, 0, 1, 1, 0, 1, 1, 0, 1, 0,\n",
              "       0, 0, 1, 1, 0, 1, 0, 0, 1, 1, 0, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 0,\n",
              "       0, 0, 1, 1, 1, 0, 1, 0, 1, 1, 1, 0, 0, 1, 1, 1, 0, 0, 0, 1, 0, 1,\n",
              "       1, 1, 1, 1, 0, 0, 1, 1, 0, 1, 0, 1, 0, 1, 1, 1, 1, 0, 1, 1, 0, 1,\n",
              "       0, 0, 1, 1, 1, 0, 0, 0, 1, 0, 1, 1, 0, 1, 1, 0, 1, 1, 0, 1, 1, 0,\n",
              "       1, 1, 0, 1, 1, 0, 1, 0, 1, 0])"
            ]
          },
          "metadata": {},
          "execution_count": 87
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "np.mean(y_test == y_pred_classSex_M)"
      ],
      "metadata": {
        "id": "4RJpzhMvx_z4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Sex_Mscore=recall_score(y_test,y_pred_classSex_M)\n",
        "print(Sex_Mscore)"
      ],
      "metadata": {
        "id": "4AdvQ11IyADC",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f58c8904-003f-4a5d-aabb-0db3a2c43250"
      },
      "execution_count": 88,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.9\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "ChestPainType_ASY"
      ],
      "metadata": {
        "id": "w2hgHMvLqv5d"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "heart = pd.read_csv(f_path)\n",
        "\n",
        "heart = pd.get_dummies(heart)\n",
        "\n",
        "x = heart.drop('HeartDisease', axis=1)\n",
        "y = pd.get_dummies(heart[\"HeartDisease\"])\n",
        "\n",
        "heart['ChestPainType_ASY'] = 0\n",
        "\n",
        "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size = 0.13,shuffle=True, random_state = 42)\n",
        "\n",
        "print(\"X_train: \", x_train.shape)\n",
        "print(\"y_train: \", y_train.shape)\n",
        "\n",
        "print(\"X_test: \", x_test.shape)\n",
        "print(\"y_test: \", y_test.shape)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "ModelExceptChestPainType_ASY = Sequential()\n",
        "\n",
        "\n",
        "ModelExceptChestPainType_ASY.add(Dense(128, activation = \"relu\",input_dim=20))\n",
        "ModelExceptChestPainType_ASY.add(Dropout(rate=0.2))\n",
        "ModelExceptChestPainType_ASY.add(Dense(64, activation = \"relu\"))\n",
        "ModelExceptChestPainType_ASY.add(Dropout(rate=0.2))\n",
        "ModelExceptChestPainType_ASY.add(Dense(32, activation = \"relu\"))\n",
        "ModelExceptChestPainType_ASY.add(Dropout(rate=0.1))\n",
        "ModelExceptChestPainType_ASY.add(Dense(16, activation = \"relu\"))\n",
        "ModelExceptChestPainType_ASY.add(Dense(8, activation = \"relu\"))\n",
        "ModelExceptChestPainType_ASY.add(Dense(2, activation = \"sigmoid\"))\n",
        "\n",
        "ModelExceptChestPainType_ASY.compile(optimizer = \"adam\", loss = \"categorical_crossentropy\", metrics = [\"accuracy\"])\n",
        "ModelExceptChestPainType_ASY.summary()\n",
        "\n",
        "hin=ModelExceptChestPainType_ASY.fit(x_train,y_train,epochs=200, validation_split=0.2)\n",
        "\n",
        "loss_and_metrics = ModelExceptChestPainType_ASY.evaluate(x_test, y_test, batch_size=32)\n",
        "print('## evaluation loss and_metrics ##')\n",
        "print(loss_and_metrics)\n",
        "\n",
        "y_predChestPainType_ASY = ModelExceptChestPainType_ASY.predict(x_test)\n",
        "y_predChestPainType_ASY\n",
        "\n",
        "y_pred_classChestPainType_ASY = np.argmax(y_predChestPainType_ASY, axis=1)\n",
        "y_pred_classChestPainType_ASY\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "y_test  = y_test.to_numpy()\n",
        "y_test\n",
        "\n",
        "y_test = np.argmax(y_test,axis=1)\n",
        "y_test\n"
      ],
      "metadata": {
        "id": "wBPMs50gybso",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8dfd51e7-e1fe-47e9-a32d-65a5316eec72"
      },
      "execution_count": 89,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "X_train:  (798, 20)\n",
            "y_train:  (798, 2)\n",
            "X_test:  (120, 20)\n",
            "y_test:  (120, 2)\n",
            "Model: \"sequential_13\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense_78 (Dense)            (None, 128)               2688      \n",
            "                                                                 \n",
            " dropout_39 (Dropout)        (None, 128)               0         \n",
            "                                                                 \n",
            " dense_79 (Dense)            (None, 64)                8256      \n",
            "                                                                 \n",
            " dropout_40 (Dropout)        (None, 64)                0         \n",
            "                                                                 \n",
            " dense_80 (Dense)            (None, 32)                2080      \n",
            "                                                                 \n",
            " dropout_41 (Dropout)        (None, 32)                0         \n",
            "                                                                 \n",
            " dense_81 (Dense)            (None, 16)                528       \n",
            "                                                                 \n",
            " dense_82 (Dense)            (None, 8)                 136       \n",
            "                                                                 \n",
            " dense_83 (Dense)            (None, 2)                 18        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 13,706\n",
            "Trainable params: 13,706\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/200\n",
            "20/20 [==============================] - 1s 13ms/step - loss: 2.1524 - accuracy: 0.4937 - val_loss: 0.6154 - val_accuracy: 0.7250\n",
            "Epoch 2/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.9505 - accuracy: 0.5925 - val_loss: 0.6124 - val_accuracy: 0.6750\n",
            "Epoch 3/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.8461 - accuracy: 0.5486 - val_loss: 0.6198 - val_accuracy: 0.6750\n",
            "Epoch 4/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.7051 - accuracy: 0.5846 - val_loss: 0.6217 - val_accuracy: 0.6750\n",
            "Epoch 5/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.6815 - accuracy: 0.6129 - val_loss: 0.6232 - val_accuracy: 0.6812\n",
            "Epoch 6/200\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.6718 - accuracy: 0.5784 - val_loss: 0.6276 - val_accuracy: 0.6812\n",
            "Epoch 7/200\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.6549 - accuracy: 0.5878 - val_loss: 0.6179 - val_accuracy: 0.6875\n",
            "Epoch 8/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.6472 - accuracy: 0.5878 - val_loss: 0.6192 - val_accuracy: 0.6750\n",
            "Epoch 9/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.6605 - accuracy: 0.5674 - val_loss: 0.6212 - val_accuracy: 0.6750\n",
            "Epoch 10/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.6807 - accuracy: 0.6034 - val_loss: 0.6186 - val_accuracy: 0.6812\n",
            "Epoch 11/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.6477 - accuracy: 0.5956 - val_loss: 0.6187 - val_accuracy: 0.6750\n",
            "Epoch 12/200\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.6415 - accuracy: 0.6066 - val_loss: 0.6198 - val_accuracy: 0.6750\n",
            "Epoch 13/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.6692 - accuracy: 0.6113 - val_loss: 0.6204 - val_accuracy: 0.6750\n",
            "Epoch 14/200\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.6333 - accuracy: 0.6160 - val_loss: 0.6169 - val_accuracy: 0.6938\n",
            "Epoch 15/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.6340 - accuracy: 0.6129 - val_loss: 0.6167 - val_accuracy: 0.6938\n",
            "Epoch 16/200\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.6547 - accuracy: 0.6207 - val_loss: 0.6186 - val_accuracy: 0.6875\n",
            "Epoch 17/200\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.6356 - accuracy: 0.6191 - val_loss: 0.6155 - val_accuracy: 0.7188\n",
            "Epoch 18/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.6336 - accuracy: 0.6395 - val_loss: 0.6037 - val_accuracy: 0.7625\n",
            "Epoch 19/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.6361 - accuracy: 0.6411 - val_loss: 0.6123 - val_accuracy: 0.7188\n",
            "Epoch 20/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.6263 - accuracy: 0.6254 - val_loss: 0.6137 - val_accuracy: 0.7063\n",
            "Epoch 21/200\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.6327 - accuracy: 0.6599 - val_loss: 0.5961 - val_accuracy: 0.7563\n",
            "Epoch 22/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.6236 - accuracy: 0.6599 - val_loss: 0.5940 - val_accuracy: 0.7812\n",
            "Epoch 23/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.6142 - accuracy: 0.6661 - val_loss: 0.5910 - val_accuracy: 0.7750\n",
            "Epoch 24/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.6028 - accuracy: 0.6677 - val_loss: 0.5627 - val_accuracy: 0.7375\n",
            "Epoch 25/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.6221 - accuracy: 0.6661 - val_loss: 0.5768 - val_accuracy: 0.7437\n",
            "Epoch 26/200\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.6212 - accuracy: 0.6567 - val_loss: 0.5616 - val_accuracy: 0.7750\n",
            "Epoch 27/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.5978 - accuracy: 0.6991 - val_loss: 0.5565 - val_accuracy: 0.7688\n",
            "Epoch 28/200\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.5855 - accuracy: 0.6865 - val_loss: 0.5592 - val_accuracy: 0.7625\n",
            "Epoch 29/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.6126 - accuracy: 0.6803 - val_loss: 0.5448 - val_accuracy: 0.7812\n",
            "Epoch 30/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.5837 - accuracy: 0.6991 - val_loss: 0.5417 - val_accuracy: 0.7750\n",
            "Epoch 31/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.5926 - accuracy: 0.6897 - val_loss: 0.5304 - val_accuracy: 0.7750\n",
            "Epoch 32/200\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.6044 - accuracy: 0.7006 - val_loss: 0.5197 - val_accuracy: 0.7688\n",
            "Epoch 33/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.5621 - accuracy: 0.7163 - val_loss: 0.5197 - val_accuracy: 0.7875\n",
            "Epoch 34/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.5490 - accuracy: 0.7257 - val_loss: 0.5266 - val_accuracy: 0.7688\n",
            "Epoch 35/200\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.5780 - accuracy: 0.7273 - val_loss: 0.5321 - val_accuracy: 0.7625\n",
            "Epoch 36/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.5756 - accuracy: 0.7069 - val_loss: 0.5285 - val_accuracy: 0.7750\n",
            "Epoch 37/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.5588 - accuracy: 0.7288 - val_loss: 0.5425 - val_accuracy: 0.7500\n",
            "Epoch 38/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.5657 - accuracy: 0.7241 - val_loss: 0.5119 - val_accuracy: 0.7937\n",
            "Epoch 39/200\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.5471 - accuracy: 0.7398 - val_loss: 0.5059 - val_accuracy: 0.7812\n",
            "Epoch 40/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.5652 - accuracy: 0.7241 - val_loss: 0.5075 - val_accuracy: 0.7688\n",
            "Epoch 41/200\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.5240 - accuracy: 0.7618 - val_loss: 0.5001 - val_accuracy: 0.7688\n",
            "Epoch 42/200\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.5413 - accuracy: 0.7320 - val_loss: 0.4889 - val_accuracy: 0.7937\n",
            "Epoch 43/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.5675 - accuracy: 0.7163 - val_loss: 0.5034 - val_accuracy: 0.7875\n",
            "Epoch 44/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.5303 - accuracy: 0.7649 - val_loss: 0.5155 - val_accuracy: 0.7688\n",
            "Epoch 45/200\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.5188 - accuracy: 0.7539 - val_loss: 0.5055 - val_accuracy: 0.7625\n",
            "Epoch 46/200\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.5229 - accuracy: 0.7429 - val_loss: 0.4793 - val_accuracy: 0.8000\n",
            "Epoch 47/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.5117 - accuracy: 0.7790 - val_loss: 0.4683 - val_accuracy: 0.8125\n",
            "Epoch 48/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.5096 - accuracy: 0.7618 - val_loss: 0.4810 - val_accuracy: 0.8125\n",
            "Epoch 49/200\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.5088 - accuracy: 0.7665 - val_loss: 0.4547 - val_accuracy: 0.8000\n",
            "Epoch 50/200\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.5126 - accuracy: 0.7696 - val_loss: 0.4682 - val_accuracy: 0.8125\n",
            "Epoch 51/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.4991 - accuracy: 0.7790 - val_loss: 0.4794 - val_accuracy: 0.7937\n",
            "Epoch 52/200\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.4876 - accuracy: 0.7743 - val_loss: 0.4533 - val_accuracy: 0.8250\n",
            "Epoch 53/200\n",
            "20/20 [==============================] - 0s 6ms/step - loss: 0.4918 - accuracy: 0.7743 - val_loss: 0.4497 - val_accuracy: 0.8250\n",
            "Epoch 54/200\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.4751 - accuracy: 0.7837 - val_loss: 0.4613 - val_accuracy: 0.8000\n",
            "Epoch 55/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.4803 - accuracy: 0.7868 - val_loss: 0.4318 - val_accuracy: 0.8188\n",
            "Epoch 56/200\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.4712 - accuracy: 0.7900 - val_loss: 0.4305 - val_accuracy: 0.8250\n",
            "Epoch 57/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.4861 - accuracy: 0.7900 - val_loss: 0.5068 - val_accuracy: 0.7688\n",
            "Epoch 58/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.4752 - accuracy: 0.7806 - val_loss: 0.4425 - val_accuracy: 0.8375\n",
            "Epoch 59/200\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.4539 - accuracy: 0.8056 - val_loss: 0.4370 - val_accuracy: 0.8250\n",
            "Epoch 60/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.4459 - accuracy: 0.8150 - val_loss: 0.4450 - val_accuracy: 0.8250\n",
            "Epoch 61/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.4596 - accuracy: 0.8150 - val_loss: 0.4539 - val_accuracy: 0.8062\n",
            "Epoch 62/200\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.4360 - accuracy: 0.8150 - val_loss: 0.4356 - val_accuracy: 0.8375\n",
            "Epoch 63/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.4404 - accuracy: 0.8009 - val_loss: 0.4144 - val_accuracy: 0.8500\n",
            "Epoch 64/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.4577 - accuracy: 0.8041 - val_loss: 0.4231 - val_accuracy: 0.8375\n",
            "Epoch 65/200\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.4516 - accuracy: 0.8135 - val_loss: 0.4116 - val_accuracy: 0.8438\n",
            "Epoch 66/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.4188 - accuracy: 0.8041 - val_loss: 0.3968 - val_accuracy: 0.8438\n",
            "Epoch 67/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.4417 - accuracy: 0.8103 - val_loss: 0.4319 - val_accuracy: 0.8188\n",
            "Epoch 68/200\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.4391 - accuracy: 0.8088 - val_loss: 0.4453 - val_accuracy: 0.8188\n",
            "Epoch 69/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.4247 - accuracy: 0.8307 - val_loss: 0.4578 - val_accuracy: 0.8125\n",
            "Epoch 70/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.4210 - accuracy: 0.8323 - val_loss: 0.3850 - val_accuracy: 0.8375\n",
            "Epoch 71/200\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.4199 - accuracy: 0.8103 - val_loss: 0.3895 - val_accuracy: 0.8438\n",
            "Epoch 72/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.4093 - accuracy: 0.8323 - val_loss: 0.4155 - val_accuracy: 0.8500\n",
            "Epoch 73/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.3919 - accuracy: 0.8448 - val_loss: 0.4269 - val_accuracy: 0.8375\n",
            "Epoch 74/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.3879 - accuracy: 0.8386 - val_loss: 0.4093 - val_accuracy: 0.8438\n",
            "Epoch 75/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.3983 - accuracy: 0.8229 - val_loss: 0.4108 - val_accuracy: 0.8562\n",
            "Epoch 76/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.4076 - accuracy: 0.8401 - val_loss: 0.4122 - val_accuracy: 0.8500\n",
            "Epoch 77/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.3935 - accuracy: 0.8307 - val_loss: 0.4064 - val_accuracy: 0.8438\n",
            "Epoch 78/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.4095 - accuracy: 0.8354 - val_loss: 0.4140 - val_accuracy: 0.8375\n",
            "Epoch 79/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.3790 - accuracy: 0.8464 - val_loss: 0.4683 - val_accuracy: 0.8125\n",
            "Epoch 80/200\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.3791 - accuracy: 0.8417 - val_loss: 0.4113 - val_accuracy: 0.8313\n",
            "Epoch 81/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.3760 - accuracy: 0.8495 - val_loss: 0.4585 - val_accuracy: 0.8062\n",
            "Epoch 82/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.3913 - accuracy: 0.8307 - val_loss: 0.4606 - val_accuracy: 0.8188\n",
            "Epoch 83/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.3821 - accuracy: 0.8401 - val_loss: 0.3928 - val_accuracy: 0.8438\n",
            "Epoch 84/200\n",
            "20/20 [==============================] - 0s 7ms/step - loss: 0.3830 - accuracy: 0.8354 - val_loss: 0.4727 - val_accuracy: 0.7937\n",
            "Epoch 85/200\n",
            "20/20 [==============================] - 0s 6ms/step - loss: 0.3884 - accuracy: 0.8401 - val_loss: 0.4083 - val_accuracy: 0.8500\n",
            "Epoch 86/200\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.3770 - accuracy: 0.8605 - val_loss: 0.3913 - val_accuracy: 0.8562\n",
            "Epoch 87/200\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.3767 - accuracy: 0.8495 - val_loss: 0.3890 - val_accuracy: 0.8500\n",
            "Epoch 88/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.3711 - accuracy: 0.8417 - val_loss: 0.3551 - val_accuracy: 0.8687\n",
            "Epoch 89/200\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.3865 - accuracy: 0.8527 - val_loss: 0.3656 - val_accuracy: 0.8625\n",
            "Epoch 90/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.3584 - accuracy: 0.8495 - val_loss: 0.3765 - val_accuracy: 0.8625\n",
            "Epoch 91/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.3441 - accuracy: 0.8636 - val_loss: 0.3770 - val_accuracy: 0.8687\n",
            "Epoch 92/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.3626 - accuracy: 0.8621 - val_loss: 0.3648 - val_accuracy: 0.8687\n",
            "Epoch 93/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.3467 - accuracy: 0.8527 - val_loss: 0.3829 - val_accuracy: 0.8562\n",
            "Epoch 94/200\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.3574 - accuracy: 0.8354 - val_loss: 0.4090 - val_accuracy: 0.8562\n",
            "Epoch 95/200\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.3684 - accuracy: 0.8589 - val_loss: 0.4674 - val_accuracy: 0.7937\n",
            "Epoch 96/200\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.3501 - accuracy: 0.8527 - val_loss: 0.3823 - val_accuracy: 0.8625\n",
            "Epoch 97/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.3486 - accuracy: 0.8417 - val_loss: 0.3601 - val_accuracy: 0.8750\n",
            "Epoch 98/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.3609 - accuracy: 0.8480 - val_loss: 0.3922 - val_accuracy: 0.8500\n",
            "Epoch 99/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.3435 - accuracy: 0.8715 - val_loss: 0.4402 - val_accuracy: 0.8062\n",
            "Epoch 100/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.3480 - accuracy: 0.8527 - val_loss: 0.3850 - val_accuracy: 0.8562\n",
            "Epoch 101/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.3269 - accuracy: 0.8683 - val_loss: 0.4016 - val_accuracy: 0.8438\n",
            "Epoch 102/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.3540 - accuracy: 0.8652 - val_loss: 0.4196 - val_accuracy: 0.8250\n",
            "Epoch 103/200\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.3359 - accuracy: 0.8574 - val_loss: 0.3745 - val_accuracy: 0.8625\n",
            "Epoch 104/200\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.3446 - accuracy: 0.8605 - val_loss: 0.3498 - val_accuracy: 0.8813\n",
            "Epoch 105/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.3712 - accuracy: 0.8527 - val_loss: 0.3584 - val_accuracy: 0.8625\n",
            "Epoch 106/200\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.3499 - accuracy: 0.8621 - val_loss: 0.3731 - val_accuracy: 0.8625\n",
            "Epoch 107/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.3336 - accuracy: 0.8652 - val_loss: 0.3668 - val_accuracy: 0.8562\n",
            "Epoch 108/200\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.3283 - accuracy: 0.8574 - val_loss: 0.4464 - val_accuracy: 0.8125\n",
            "Epoch 109/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.3427 - accuracy: 0.8683 - val_loss: 0.3820 - val_accuracy: 0.8625\n",
            "Epoch 110/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.3312 - accuracy: 0.8699 - val_loss: 0.4650 - val_accuracy: 0.8000\n",
            "Epoch 111/200\n",
            "20/20 [==============================] - 0s 6ms/step - loss: 0.3362 - accuracy: 0.8668 - val_loss: 0.3678 - val_accuracy: 0.8750\n",
            "Epoch 112/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.3365 - accuracy: 0.8636 - val_loss: 0.3962 - val_accuracy: 0.8562\n",
            "Epoch 113/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.3355 - accuracy: 0.8699 - val_loss: 0.4113 - val_accuracy: 0.8375\n",
            "Epoch 114/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.3245 - accuracy: 0.8746 - val_loss: 0.3945 - val_accuracy: 0.8438\n",
            "Epoch 115/200\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.3141 - accuracy: 0.8856 - val_loss: 0.3903 - val_accuracy: 0.8375\n",
            "Epoch 116/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.3197 - accuracy: 0.8762 - val_loss: 0.4342 - val_accuracy: 0.8125\n",
            "Epoch 117/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.3264 - accuracy: 0.8699 - val_loss: 0.4512 - val_accuracy: 0.8062\n",
            "Epoch 118/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.3476 - accuracy: 0.8574 - val_loss: 0.3633 - val_accuracy: 0.8625\n",
            "Epoch 119/200\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.3431 - accuracy: 0.8683 - val_loss: 0.4225 - val_accuracy: 0.8125\n",
            "Epoch 120/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.3298 - accuracy: 0.8715 - val_loss: 0.3589 - val_accuracy: 0.8687\n",
            "Epoch 121/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.3282 - accuracy: 0.8715 - val_loss: 0.3484 - val_accuracy: 0.8750\n",
            "Epoch 122/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.3167 - accuracy: 0.8777 - val_loss: 0.3745 - val_accuracy: 0.8438\n",
            "Epoch 123/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.3527 - accuracy: 0.8605 - val_loss: 0.3485 - val_accuracy: 0.8750\n",
            "Epoch 124/200\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.3237 - accuracy: 0.8605 - val_loss: 0.3659 - val_accuracy: 0.8687\n",
            "Epoch 125/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.3277 - accuracy: 0.8777 - val_loss: 0.3791 - val_accuracy: 0.8562\n",
            "Epoch 126/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.3250 - accuracy: 0.8636 - val_loss: 0.3510 - val_accuracy: 0.8875\n",
            "Epoch 127/200\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.3398 - accuracy: 0.8683 - val_loss: 0.3639 - val_accuracy: 0.8625\n",
            "Epoch 128/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.3180 - accuracy: 0.8762 - val_loss: 0.3842 - val_accuracy: 0.8500\n",
            "Epoch 129/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.3082 - accuracy: 0.8809 - val_loss: 0.3894 - val_accuracy: 0.8375\n",
            "Epoch 130/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.3098 - accuracy: 0.8762 - val_loss: 0.4067 - val_accuracy: 0.8375\n",
            "Epoch 131/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.3229 - accuracy: 0.8699 - val_loss: 0.3530 - val_accuracy: 0.8687\n",
            "Epoch 132/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.3178 - accuracy: 0.8746 - val_loss: 0.3689 - val_accuracy: 0.8625\n",
            "Epoch 133/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.3069 - accuracy: 0.8793 - val_loss: 0.3969 - val_accuracy: 0.8375\n",
            "Epoch 134/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.3244 - accuracy: 0.8730 - val_loss: 0.3645 - val_accuracy: 0.8562\n",
            "Epoch 135/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.3330 - accuracy: 0.8730 - val_loss: 0.3743 - val_accuracy: 0.8500\n",
            "Epoch 136/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.3289 - accuracy: 0.8652 - val_loss: 0.3775 - val_accuracy: 0.8562\n",
            "Epoch 137/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.3076 - accuracy: 0.8793 - val_loss: 0.3825 - val_accuracy: 0.8313\n",
            "Epoch 138/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.3013 - accuracy: 0.8777 - val_loss: 0.3667 - val_accuracy: 0.8625\n",
            "Epoch 139/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.3043 - accuracy: 0.8824 - val_loss: 0.3978 - val_accuracy: 0.8313\n",
            "Epoch 140/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.3120 - accuracy: 0.8809 - val_loss: 0.3590 - val_accuracy: 0.8687\n",
            "Epoch 141/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.3225 - accuracy: 0.8730 - val_loss: 0.3560 - val_accuracy: 0.8562\n",
            "Epoch 142/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.3095 - accuracy: 0.8777 - val_loss: 0.3664 - val_accuracy: 0.8562\n",
            "Epoch 143/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.3134 - accuracy: 0.8652 - val_loss: 0.4329 - val_accuracy: 0.8000\n",
            "Epoch 144/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.3135 - accuracy: 0.8777 - val_loss: 0.4004 - val_accuracy: 0.8438\n",
            "Epoch 145/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.3029 - accuracy: 0.8683 - val_loss: 0.4393 - val_accuracy: 0.8125\n",
            "Epoch 146/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.2966 - accuracy: 0.8809 - val_loss: 0.3788 - val_accuracy: 0.8625\n",
            "Epoch 147/200\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.2967 - accuracy: 0.8793 - val_loss: 0.4164 - val_accuracy: 0.8125\n",
            "Epoch 148/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.3144 - accuracy: 0.8777 - val_loss: 0.4136 - val_accuracy: 0.8125\n",
            "Epoch 149/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.3003 - accuracy: 0.8840 - val_loss: 0.3653 - val_accuracy: 0.8625\n",
            "Epoch 150/200\n",
            "20/20 [==============================] - 0s 6ms/step - loss: 0.3068 - accuracy: 0.8809 - val_loss: 0.3548 - val_accuracy: 0.8687\n",
            "Epoch 151/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.3178 - accuracy: 0.8746 - val_loss: 0.4106 - val_accuracy: 0.8062\n",
            "Epoch 152/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.2979 - accuracy: 0.8871 - val_loss: 0.3877 - val_accuracy: 0.8625\n",
            "Epoch 153/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.2944 - accuracy: 0.8809 - val_loss: 0.3848 - val_accuracy: 0.8625\n",
            "Epoch 154/200\n",
            "20/20 [==============================] - 0s 6ms/step - loss: 0.2725 - accuracy: 0.8840 - val_loss: 0.3908 - val_accuracy: 0.8562\n",
            "Epoch 155/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.3001 - accuracy: 0.8793 - val_loss: 0.3930 - val_accuracy: 0.8313\n",
            "Epoch 156/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.3062 - accuracy: 0.8824 - val_loss: 0.3607 - val_accuracy: 0.8562\n",
            "Epoch 157/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.3180 - accuracy: 0.8746 - val_loss: 0.3896 - val_accuracy: 0.8313\n",
            "Epoch 158/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.2802 - accuracy: 0.8856 - val_loss: 0.4227 - val_accuracy: 0.8188\n",
            "Epoch 159/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.2845 - accuracy: 0.8824 - val_loss: 0.3951 - val_accuracy: 0.8188\n",
            "Epoch 160/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.3074 - accuracy: 0.8777 - val_loss: 0.3838 - val_accuracy: 0.8562\n",
            "Epoch 161/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.3096 - accuracy: 0.8715 - val_loss: 0.3512 - val_accuracy: 0.8687\n",
            "Epoch 162/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.3080 - accuracy: 0.8730 - val_loss: 0.4136 - val_accuracy: 0.8250\n",
            "Epoch 163/200\n",
            "20/20 [==============================] - 0s 6ms/step - loss: 0.2902 - accuracy: 0.8824 - val_loss: 0.3691 - val_accuracy: 0.8687\n",
            "Epoch 164/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.2855 - accuracy: 0.8824 - val_loss: 0.3735 - val_accuracy: 0.8562\n",
            "Epoch 165/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.2902 - accuracy: 0.8824 - val_loss: 0.3888 - val_accuracy: 0.8375\n",
            "Epoch 166/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.3003 - accuracy: 0.8856 - val_loss: 0.3502 - val_accuracy: 0.8875\n",
            "Epoch 167/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.2948 - accuracy: 0.8809 - val_loss: 0.3961 - val_accuracy: 0.8188\n",
            "Epoch 168/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.2809 - accuracy: 0.8840 - val_loss: 0.3554 - val_accuracy: 0.8938\n",
            "Epoch 169/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.3025 - accuracy: 0.8746 - val_loss: 0.3465 - val_accuracy: 0.8625\n",
            "Epoch 170/200\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.2982 - accuracy: 0.8746 - val_loss: 0.3611 - val_accuracy: 0.8625\n",
            "Epoch 171/200\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.3046 - accuracy: 0.8683 - val_loss: 0.3695 - val_accuracy: 0.8625\n",
            "Epoch 172/200\n",
            "20/20 [==============================] - 0s 6ms/step - loss: 0.2855 - accuracy: 0.8793 - val_loss: 0.3958 - val_accuracy: 0.8375\n",
            "Epoch 173/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.2871 - accuracy: 0.8762 - val_loss: 0.3754 - val_accuracy: 0.8500\n",
            "Epoch 174/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.2979 - accuracy: 0.8793 - val_loss: 0.3521 - val_accuracy: 0.8813\n",
            "Epoch 175/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.2968 - accuracy: 0.8730 - val_loss: 0.3578 - val_accuracy: 0.8875\n",
            "Epoch 176/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.2931 - accuracy: 0.8699 - val_loss: 0.3490 - val_accuracy: 0.8938\n",
            "Epoch 177/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.2868 - accuracy: 0.8777 - val_loss: 0.4088 - val_accuracy: 0.8438\n",
            "Epoch 178/200\n",
            "20/20 [==============================] - 0s 6ms/step - loss: 0.3012 - accuracy: 0.8777 - val_loss: 0.3618 - val_accuracy: 0.8562\n",
            "Epoch 179/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.2989 - accuracy: 0.8746 - val_loss: 0.4082 - val_accuracy: 0.8313\n",
            "Epoch 180/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.2883 - accuracy: 0.8777 - val_loss: 0.3743 - val_accuracy: 0.8375\n",
            "Epoch 181/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.2888 - accuracy: 0.8730 - val_loss: 0.3692 - val_accuracy: 0.8562\n",
            "Epoch 182/200\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.2765 - accuracy: 0.8840 - val_loss: 0.3560 - val_accuracy: 0.8625\n",
            "Epoch 183/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.2897 - accuracy: 0.8934 - val_loss: 0.3630 - val_accuracy: 0.8750\n",
            "Epoch 184/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.2799 - accuracy: 0.8699 - val_loss: 0.3835 - val_accuracy: 0.8562\n",
            "Epoch 185/200\n",
            "20/20 [==============================] - 0s 6ms/step - loss: 0.2886 - accuracy: 0.8871 - val_loss: 0.3680 - val_accuracy: 0.8562\n",
            "Epoch 186/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.2978 - accuracy: 0.8809 - val_loss: 0.4259 - val_accuracy: 0.8250\n",
            "Epoch 187/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.2745 - accuracy: 0.8950 - val_loss: 0.4051 - val_accuracy: 0.8500\n",
            "Epoch 188/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.2780 - accuracy: 0.8903 - val_loss: 0.3775 - val_accuracy: 0.8625\n",
            "Epoch 189/200\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.2801 - accuracy: 0.8887 - val_loss: 0.3640 - val_accuracy: 0.8938\n",
            "Epoch 190/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.2876 - accuracy: 0.8777 - val_loss: 0.3697 - val_accuracy: 0.8625\n",
            "Epoch 191/200\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.2811 - accuracy: 0.8840 - val_loss: 0.3767 - val_accuracy: 0.8625\n",
            "Epoch 192/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.2773 - accuracy: 0.8934 - val_loss: 0.3881 - val_accuracy: 0.8375\n",
            "Epoch 193/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.2755 - accuracy: 0.8840 - val_loss: 0.3706 - val_accuracy: 0.8687\n",
            "Epoch 194/200\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.2760 - accuracy: 0.8871 - val_loss: 0.3945 - val_accuracy: 0.8375\n",
            "Epoch 195/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.2814 - accuracy: 0.8762 - val_loss: 0.4153 - val_accuracy: 0.8250\n",
            "Epoch 196/200\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.2940 - accuracy: 0.8762 - val_loss: 0.3717 - val_accuracy: 0.8687\n",
            "Epoch 197/200\n",
            "20/20 [==============================] - 0s 6ms/step - loss: 0.2728 - accuracy: 0.8871 - val_loss: 0.4084 - val_accuracy: 0.8500\n",
            "Epoch 198/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.3014 - accuracy: 0.8809 - val_loss: 0.3835 - val_accuracy: 0.8500\n",
            "Epoch 199/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.2717 - accuracy: 0.8840 - val_loss: 0.3878 - val_accuracy: 0.8687\n",
            "Epoch 200/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.2746 - accuracy: 0.8903 - val_loss: 0.3859 - val_accuracy: 0.8687\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 0.4300 - accuracy: 0.8333\n",
            "## evaluation loss and_metrics ##\n",
            "[0.42995646595954895, 0.8333333134651184]\n",
            "4/4 [==============================] - 0s 3ms/step\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0, 1, 1, 1, 0, 1, 1, 0, 1, 1, 0, 0, 0, 0, 1, 1, 0, 1, 1, 0, 1, 0,\n",
              "       0, 0, 1, 1, 0, 1, 0, 0, 1, 1, 0, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 0,\n",
              "       0, 0, 1, 1, 1, 0, 1, 0, 1, 1, 1, 0, 0, 1, 1, 1, 0, 0, 0, 1, 0, 1,\n",
              "       1, 1, 1, 1, 0, 0, 1, 1, 0, 1, 0, 1, 0, 1, 1, 1, 1, 0, 1, 1, 0, 1,\n",
              "       0, 0, 1, 1, 1, 0, 0, 0, 1, 0, 1, 1, 0, 1, 1, 0, 1, 1, 0, 1, 1, 0,\n",
              "       1, 1, 0, 1, 1, 0, 1, 0, 1, 0])"
            ]
          },
          "metadata": {},
          "execution_count": 89
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "np.mean(y_test == y_pred_classChestPainType_ASY)"
      ],
      "metadata": {
        "id": "DEJvbEbKyb9f"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ChestPainType_ASYscore=recall_score(y_test,y_pred_classChestPainType_ASY)\n",
        "print(ChestPainType_ASYscore)"
      ],
      "metadata": {
        "id": "ViaOtTRQycTx",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5df7720d-5665-4fa8-f284-ccff7c110203"
      },
      "execution_count": 90,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.8571428571428571\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "ChestPainType_ATA"
      ],
      "metadata": {
        "id": "0U3vnjoHq3V3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "heart = pd.read_csv(f_path)\n",
        "\n",
        "heart = pd.get_dummies(heart)\n",
        "\n",
        "x = heart.drop('HeartDisease', axis=1)\n",
        "y = pd.get_dummies(heart[\"HeartDisease\"])\n",
        "\n",
        "heart['ChestPainType_ATA'] = 0\n",
        "\n",
        "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size = 0.13,shuffle=True, random_state = 42)\n",
        "\n",
        "print(\"X_train: \", x_train.shape)\n",
        "print(\"y_train: \", y_train.shape)\n",
        "\n",
        "print(\"X_test: \", x_test.shape)\n",
        "print(\"y_test: \", y_test.shape)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "ModelExceptChestPainType_ATA = Sequential()\n",
        "\n",
        "\n",
        "ModelExceptChestPainType_ATA.add(Dense(128, activation = \"relu\",input_dim=20))\n",
        "ModelExceptChestPainType_ATA.add(Dropout(rate=0.2))\n",
        "ModelExceptChestPainType_ATA.add(Dense(64, activation = \"relu\"))\n",
        "ModelExceptChestPainType_ATA.add(Dropout(rate=0.2))\n",
        "ModelExceptChestPainType_ATA.add(Dense(32, activation = \"relu\"))\n",
        "ModelExceptChestPainType_ATA.add(Dropout(rate=0.1))\n",
        "ModelExceptChestPainType_ATA.add(Dense(16, activation = \"relu\"))\n",
        "ModelExceptChestPainType_ATA.add(Dense(8, activation = \"relu\"))\n",
        "ModelExceptChestPainType_ATA.add(Dense(2, activation = \"sigmoid\"))\n",
        "\n",
        "ModelExceptChestPainType_ATA.compile(optimizer = \"adam\", loss = \"categorical_crossentropy\", metrics = [\"accuracy\"])\n",
        "ModelExceptChestPainType_ATA.summary()\n",
        "\n",
        "hin=ModelExceptChestPainType_ATA.fit(x_train,y_train,epochs=200, validation_split=0.2)\n",
        "\n",
        "loss_and_metrics = ModelExceptChestPainType_ASY.evaluate(x_test, y_test, batch_size=32)\n",
        "print('## evaluation loss and_metrics ##')\n",
        "print(loss_and_metrics)\n",
        "\n",
        "y_predChestPainType_ATA = ModelExceptChestPainType_ATA.predict(x_test)\n",
        "y_predChestPainType_ATA\n",
        "\n",
        "y_pred_classChestPainType_ATA = np.argmax(y_predChestPainType_ATA, axis=1)\n",
        "y_pred_classChestPainType_ATA\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "y_test  = y_test.to_numpy()\n",
        "y_test\n",
        "\n",
        "y_test = np.argmax(y_test,axis=1)\n",
        "y_test\n",
        "\n",
        "np.mean(y_test == y_pred_classChestPainType_ATA)\n",
        "ChestPainType_ATAscore=recall_score(y_test,y_pred_classChestPainType_ATA)\n",
        "print(ChestPainType_ATAscore)"
      ],
      "metadata": {
        "id": "D1w3GlzJy7mb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "85b1f9cf-583e-44ca-e1c4-8f9158f3fc55"
      },
      "execution_count": 91,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "X_train:  (798, 20)\n",
            "y_train:  (798, 2)\n",
            "X_test:  (120, 20)\n",
            "y_test:  (120, 2)\n",
            "Model: \"sequential_14\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense_84 (Dense)            (None, 128)               2688      \n",
            "                                                                 \n",
            " dropout_42 (Dropout)        (None, 128)               0         \n",
            "                                                                 \n",
            " dense_85 (Dense)            (None, 64)                8256      \n",
            "                                                                 \n",
            " dropout_43 (Dropout)        (None, 64)                0         \n",
            "                                                                 \n",
            " dense_86 (Dense)            (None, 32)                2080      \n",
            "                                                                 \n",
            " dropout_44 (Dropout)        (None, 32)                0         \n",
            "                                                                 \n",
            " dense_87 (Dense)            (None, 16)                528       \n",
            "                                                                 \n",
            " dense_88 (Dense)            (None, 8)                 136       \n",
            "                                                                 \n",
            " dense_89 (Dense)            (None, 2)                 18        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 13,706\n",
            "Trainable params: 13,706\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/200\n",
            "20/20 [==============================] - 1s 12ms/step - loss: 1.8596 - accuracy: 0.5361 - val_loss: 0.6697 - val_accuracy: 0.5250\n",
            "Epoch 2/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 1.1186 - accuracy: 0.5799 - val_loss: 0.8316 - val_accuracy: 0.4437\n",
            "Epoch 3/200\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.9689 - accuracy: 0.5502 - val_loss: 0.7151 - val_accuracy: 0.6687\n",
            "Epoch 4/200\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.9081 - accuracy: 0.5486 - val_loss: 0.6736 - val_accuracy: 0.4875\n",
            "Epoch 5/200\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.8113 - accuracy: 0.5408 - val_loss: 0.6430 - val_accuracy: 0.6687\n",
            "Epoch 6/200\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.7587 - accuracy: 0.5831 - val_loss: 0.7377 - val_accuracy: 0.4938\n",
            "Epoch 7/200\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.7332 - accuracy: 0.5878 - val_loss: 0.6557 - val_accuracy: 0.4938\n",
            "Epoch 8/200\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.7159 - accuracy: 0.5815 - val_loss: 0.6155 - val_accuracy: 0.7000\n",
            "Epoch 9/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.6746 - accuracy: 0.6019 - val_loss: 0.6341 - val_accuracy: 0.5063\n",
            "Epoch 10/200\n",
            "20/20 [==============================] - 0s 7ms/step - loss: 0.6939 - accuracy: 0.5956 - val_loss: 0.6589 - val_accuracy: 0.5063\n",
            "Epoch 11/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.6752 - accuracy: 0.6254 - val_loss: 0.6635 - val_accuracy: 0.4938\n",
            "Epoch 12/200\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.6733 - accuracy: 0.6034 - val_loss: 0.6381 - val_accuracy: 0.5063\n",
            "Epoch 13/200\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.6474 - accuracy: 0.6097 - val_loss: 0.5918 - val_accuracy: 0.7000\n",
            "Epoch 14/200\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.6465 - accuracy: 0.6254 - val_loss: 0.6485 - val_accuracy: 0.5063\n",
            "Epoch 15/200\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.6573 - accuracy: 0.6379 - val_loss: 0.5731 - val_accuracy: 0.7563\n",
            "Epoch 16/200\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.6434 - accuracy: 0.6317 - val_loss: 0.6217 - val_accuracy: 0.5312\n",
            "Epoch 17/200\n",
            "20/20 [==============================] - 0s 6ms/step - loss: 0.6544 - accuracy: 0.6129 - val_loss: 0.5979 - val_accuracy: 0.6875\n",
            "Epoch 18/200\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.6414 - accuracy: 0.6520 - val_loss: 0.6668 - val_accuracy: 0.5063\n",
            "Epoch 19/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.6384 - accuracy: 0.5972 - val_loss: 0.5812 - val_accuracy: 0.7750\n",
            "Epoch 20/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.6367 - accuracy: 0.6426 - val_loss: 0.5949 - val_accuracy: 0.6375\n",
            "Epoch 21/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.6265 - accuracy: 0.6473 - val_loss: 0.5778 - val_accuracy: 0.7125\n",
            "Epoch 22/200\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.6289 - accuracy: 0.6285 - val_loss: 0.6280 - val_accuracy: 0.5625\n",
            "Epoch 23/200\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.6313 - accuracy: 0.6395 - val_loss: 0.5825 - val_accuracy: 0.7188\n",
            "Epoch 24/200\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.6146 - accuracy: 0.6301 - val_loss: 0.5611 - val_accuracy: 0.7312\n",
            "Epoch 25/200\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.6117 - accuracy: 0.6755 - val_loss: 0.6010 - val_accuracy: 0.6250\n",
            "Epoch 26/200\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.6225 - accuracy: 0.6379 - val_loss: 0.5868 - val_accuracy: 0.6562\n",
            "Epoch 27/200\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.5952 - accuracy: 0.6661 - val_loss: 0.5548 - val_accuracy: 0.7188\n",
            "Epoch 28/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.6101 - accuracy: 0.6677 - val_loss: 0.5487 - val_accuracy: 0.7625\n",
            "Epoch 29/200\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.5968 - accuracy: 0.6850 - val_loss: 0.5709 - val_accuracy: 0.7063\n",
            "Epoch 30/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.5935 - accuracy: 0.6912 - val_loss: 0.5459 - val_accuracy: 0.7437\n",
            "Epoch 31/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.5914 - accuracy: 0.7053 - val_loss: 0.5308 - val_accuracy: 0.7250\n",
            "Epoch 32/200\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.6074 - accuracy: 0.6740 - val_loss: 0.6028 - val_accuracy: 0.6000\n",
            "Epoch 33/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.5872 - accuracy: 0.6865 - val_loss: 0.5902 - val_accuracy: 0.6187\n",
            "Epoch 34/200\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.5950 - accuracy: 0.6630 - val_loss: 0.5489 - val_accuracy: 0.7500\n",
            "Epoch 35/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.5823 - accuracy: 0.7069 - val_loss: 0.5247 - val_accuracy: 0.7625\n",
            "Epoch 36/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.5838 - accuracy: 0.6991 - val_loss: 0.5761 - val_accuracy: 0.6500\n",
            "Epoch 37/200\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.5769 - accuracy: 0.6881 - val_loss: 0.5432 - val_accuracy: 0.7375\n",
            "Epoch 38/200\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.5758 - accuracy: 0.7038 - val_loss: 0.5200 - val_accuracy: 0.7437\n",
            "Epoch 39/200\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.5780 - accuracy: 0.7273 - val_loss: 0.5300 - val_accuracy: 0.7625\n",
            "Epoch 40/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.5779 - accuracy: 0.7147 - val_loss: 0.5385 - val_accuracy: 0.7375\n",
            "Epoch 41/200\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.5698 - accuracy: 0.7367 - val_loss: 0.5501 - val_accuracy: 0.7188\n",
            "Epoch 42/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.5598 - accuracy: 0.7257 - val_loss: 0.5682 - val_accuracy: 0.6687\n",
            "Epoch 43/200\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.5835 - accuracy: 0.7069 - val_loss: 0.5298 - val_accuracy: 0.7500\n",
            "Epoch 44/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.5540 - accuracy: 0.7367 - val_loss: 0.5128 - val_accuracy: 0.7437\n",
            "Epoch 45/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.5409 - accuracy: 0.7304 - val_loss: 0.5349 - val_accuracy: 0.7375\n",
            "Epoch 46/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.5515 - accuracy: 0.7304 - val_loss: 0.5050 - val_accuracy: 0.7750\n",
            "Epoch 47/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.5415 - accuracy: 0.7429 - val_loss: 0.5462 - val_accuracy: 0.7125\n",
            "Epoch 48/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.5300 - accuracy: 0.7508 - val_loss: 0.5188 - val_accuracy: 0.7563\n",
            "Epoch 49/200\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.5330 - accuracy: 0.7414 - val_loss: 0.4864 - val_accuracy: 0.7875\n",
            "Epoch 50/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.5324 - accuracy: 0.7602 - val_loss: 0.4935 - val_accuracy: 0.7688\n",
            "Epoch 51/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.5422 - accuracy: 0.7445 - val_loss: 0.5203 - val_accuracy: 0.7375\n",
            "Epoch 52/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.5438 - accuracy: 0.7586 - val_loss: 0.5892 - val_accuracy: 0.6562\n",
            "Epoch 53/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.5577 - accuracy: 0.7257 - val_loss: 0.5213 - val_accuracy: 0.7500\n",
            "Epoch 54/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.5195 - accuracy: 0.7539 - val_loss: 0.4755 - val_accuracy: 0.8000\n",
            "Epoch 55/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.5198 - accuracy: 0.7759 - val_loss: 0.5210 - val_accuracy: 0.7500\n",
            "Epoch 56/200\n",
            "20/20 [==============================] - 0s 7ms/step - loss: 0.5210 - accuracy: 0.7539 - val_loss: 0.4946 - val_accuracy: 0.7750\n",
            "Epoch 57/200\n",
            "20/20 [==============================] - 0s 9ms/step - loss: 0.5183 - accuracy: 0.7665 - val_loss: 0.4633 - val_accuracy: 0.8062\n",
            "Epoch 58/200\n",
            "20/20 [==============================] - 0s 9ms/step - loss: 0.5349 - accuracy: 0.7555 - val_loss: 0.5211 - val_accuracy: 0.7312\n",
            "Epoch 59/200\n",
            "20/20 [==============================] - 0s 7ms/step - loss: 0.4913 - accuracy: 0.7853 - val_loss: 0.4545 - val_accuracy: 0.8062\n",
            "Epoch 60/200\n",
            "20/20 [==============================] - 0s 7ms/step - loss: 0.5017 - accuracy: 0.7743 - val_loss: 0.4955 - val_accuracy: 0.7812\n",
            "Epoch 61/200\n",
            "20/20 [==============================] - 0s 7ms/step - loss: 0.4974 - accuracy: 0.7696 - val_loss: 0.4854 - val_accuracy: 0.7812\n",
            "Epoch 62/200\n",
            "20/20 [==============================] - 0s 7ms/step - loss: 0.4951 - accuracy: 0.7743 - val_loss: 0.4730 - val_accuracy: 0.8125\n",
            "Epoch 63/200\n",
            "20/20 [==============================] - 0s 6ms/step - loss: 0.4802 - accuracy: 0.7931 - val_loss: 0.4669 - val_accuracy: 0.8062\n",
            "Epoch 64/200\n",
            "20/20 [==============================] - 0s 7ms/step - loss: 0.4788 - accuracy: 0.7853 - val_loss: 0.4597 - val_accuracy: 0.8250\n",
            "Epoch 65/200\n",
            "20/20 [==============================] - 0s 7ms/step - loss: 0.4814 - accuracy: 0.7821 - val_loss: 0.4685 - val_accuracy: 0.8062\n",
            "Epoch 66/200\n",
            "20/20 [==============================] - 0s 6ms/step - loss: 0.4792 - accuracy: 0.7884 - val_loss: 0.4572 - val_accuracy: 0.8062\n",
            "Epoch 67/200\n",
            "20/20 [==============================] - 0s 7ms/step - loss: 0.4639 - accuracy: 0.7962 - val_loss: 0.4434 - val_accuracy: 0.8375\n",
            "Epoch 68/200\n",
            "20/20 [==============================] - 0s 6ms/step - loss: 0.4678 - accuracy: 0.7915 - val_loss: 0.4732 - val_accuracy: 0.8000\n",
            "Epoch 69/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.4448 - accuracy: 0.8119 - val_loss: 0.4795 - val_accuracy: 0.7875\n",
            "Epoch 70/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.4679 - accuracy: 0.8025 - val_loss: 0.4514 - val_accuracy: 0.8375\n",
            "Epoch 71/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.4576 - accuracy: 0.8119 - val_loss: 0.4213 - val_accuracy: 0.8438\n",
            "Epoch 72/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.4003 - accuracy: 0.8292 - val_loss: 0.4441 - val_accuracy: 0.8188\n",
            "Epoch 73/200\n",
            "20/20 [==============================] - 0s 6ms/step - loss: 0.4659 - accuracy: 0.8103 - val_loss: 0.4520 - val_accuracy: 0.8313\n",
            "Epoch 74/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.4128 - accuracy: 0.8166 - val_loss: 0.5293 - val_accuracy: 0.7812\n",
            "Epoch 75/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.4655 - accuracy: 0.8072 - val_loss: 0.4526 - val_accuracy: 0.8125\n",
            "Epoch 76/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.4224 - accuracy: 0.8370 - val_loss: 0.4385 - val_accuracy: 0.8188\n",
            "Epoch 77/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.4331 - accuracy: 0.8150 - val_loss: 0.4013 - val_accuracy: 0.8375\n",
            "Epoch 78/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.4252 - accuracy: 0.8245 - val_loss: 0.4079 - val_accuracy: 0.8375\n",
            "Epoch 79/200\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.4103 - accuracy: 0.8339 - val_loss: 0.4252 - val_accuracy: 0.8313\n",
            "Epoch 80/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.3973 - accuracy: 0.8464 - val_loss: 0.3957 - val_accuracy: 0.8438\n",
            "Epoch 81/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.4070 - accuracy: 0.8276 - val_loss: 0.4102 - val_accuracy: 0.8375\n",
            "Epoch 82/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.3920 - accuracy: 0.8480 - val_loss: 0.4908 - val_accuracy: 0.8188\n",
            "Epoch 83/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.4102 - accuracy: 0.8339 - val_loss: 0.4601 - val_accuracy: 0.8313\n",
            "Epoch 84/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.3902 - accuracy: 0.8401 - val_loss: 0.4306 - val_accuracy: 0.8438\n",
            "Epoch 85/200\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.4038 - accuracy: 0.8401 - val_loss: 0.4006 - val_accuracy: 0.8625\n",
            "Epoch 86/200\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.3845 - accuracy: 0.8574 - val_loss: 0.3800 - val_accuracy: 0.8625\n",
            "Epoch 87/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.4094 - accuracy: 0.8339 - val_loss: 0.3929 - val_accuracy: 0.8625\n",
            "Epoch 88/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.3754 - accuracy: 0.8401 - val_loss: 0.4082 - val_accuracy: 0.8313\n",
            "Epoch 89/200\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.3725 - accuracy: 0.8511 - val_loss: 0.3885 - val_accuracy: 0.8562\n",
            "Epoch 90/200\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.3851 - accuracy: 0.8339 - val_loss: 0.4428 - val_accuracy: 0.8188\n",
            "Epoch 91/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.3768 - accuracy: 0.8292 - val_loss: 0.3923 - val_accuracy: 0.8500\n",
            "Epoch 92/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.3877 - accuracy: 0.8401 - val_loss: 0.4015 - val_accuracy: 0.8438\n",
            "Epoch 93/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.3587 - accuracy: 0.8511 - val_loss: 0.3986 - val_accuracy: 0.8500\n",
            "Epoch 94/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.3621 - accuracy: 0.8558 - val_loss: 0.4290 - val_accuracy: 0.8313\n",
            "Epoch 95/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.3823 - accuracy: 0.8417 - val_loss: 0.4466 - val_accuracy: 0.8125\n",
            "Epoch 96/200\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.3758 - accuracy: 0.8448 - val_loss: 0.4317 - val_accuracy: 0.8313\n",
            "Epoch 97/200\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.3779 - accuracy: 0.8448 - val_loss: 0.4340 - val_accuracy: 0.8313\n",
            "Epoch 98/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.3689 - accuracy: 0.8574 - val_loss: 0.3796 - val_accuracy: 0.8500\n",
            "Epoch 99/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.3694 - accuracy: 0.8370 - val_loss: 0.3678 - val_accuracy: 0.8687\n",
            "Epoch 100/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.3428 - accuracy: 0.8636 - val_loss: 0.3890 - val_accuracy: 0.8687\n",
            "Epoch 101/200\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.3838 - accuracy: 0.8401 - val_loss: 0.3928 - val_accuracy: 0.8438\n",
            "Epoch 102/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.3461 - accuracy: 0.8636 - val_loss: 0.3991 - val_accuracy: 0.8375\n",
            "Epoch 103/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.3902 - accuracy: 0.8480 - val_loss: 0.3930 - val_accuracy: 0.8438\n",
            "Epoch 104/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.3718 - accuracy: 0.8401 - val_loss: 0.4263 - val_accuracy: 0.8250\n",
            "Epoch 105/200\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.3501 - accuracy: 0.8636 - val_loss: 0.3676 - val_accuracy: 0.8625\n",
            "Epoch 106/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.3431 - accuracy: 0.8668 - val_loss: 0.3841 - val_accuracy: 0.8500\n",
            "Epoch 107/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.3397 - accuracy: 0.8558 - val_loss: 0.4324 - val_accuracy: 0.8375\n",
            "Epoch 108/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.3442 - accuracy: 0.8480 - val_loss: 0.3908 - val_accuracy: 0.8562\n",
            "Epoch 109/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.3519 - accuracy: 0.8495 - val_loss: 0.3867 - val_accuracy: 0.8500\n",
            "Epoch 110/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.3465 - accuracy: 0.8527 - val_loss: 0.3552 - val_accuracy: 0.8687\n",
            "Epoch 111/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.3475 - accuracy: 0.8542 - val_loss: 0.4148 - val_accuracy: 0.8313\n",
            "Epoch 112/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.3261 - accuracy: 0.8762 - val_loss: 0.4250 - val_accuracy: 0.8375\n",
            "Epoch 113/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.3614 - accuracy: 0.8652 - val_loss: 0.3623 - val_accuracy: 0.8562\n",
            "Epoch 114/200\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.3389 - accuracy: 0.8636 - val_loss: 0.4177 - val_accuracy: 0.8250\n",
            "Epoch 115/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.3357 - accuracy: 0.8730 - val_loss: 0.4223 - val_accuracy: 0.8188\n",
            "Epoch 116/200\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.3363 - accuracy: 0.8636 - val_loss: 0.3807 - val_accuracy: 0.8438\n",
            "Epoch 117/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.3302 - accuracy: 0.8621 - val_loss: 0.3641 - val_accuracy: 0.8687\n",
            "Epoch 118/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.3483 - accuracy: 0.8511 - val_loss: 0.3689 - val_accuracy: 0.8625\n",
            "Epoch 119/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.3470 - accuracy: 0.8668 - val_loss: 0.3983 - val_accuracy: 0.8500\n",
            "Epoch 120/200\n",
            "20/20 [==============================] - 0s 6ms/step - loss: 0.3367 - accuracy: 0.8605 - val_loss: 0.3876 - val_accuracy: 0.8188\n",
            "Epoch 121/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.3351 - accuracy: 0.8683 - val_loss: 0.3801 - val_accuracy: 0.8438\n",
            "Epoch 122/200\n",
            "20/20 [==============================] - 0s 6ms/step - loss: 0.3337 - accuracy: 0.8715 - val_loss: 0.3730 - val_accuracy: 0.8500\n",
            "Epoch 123/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.3354 - accuracy: 0.8683 - val_loss: 0.3934 - val_accuracy: 0.8250\n",
            "Epoch 124/200\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.3194 - accuracy: 0.8683 - val_loss: 0.3714 - val_accuracy: 0.8562\n",
            "Epoch 125/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.3318 - accuracy: 0.8636 - val_loss: 0.4203 - val_accuracy: 0.8188\n",
            "Epoch 126/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.3253 - accuracy: 0.8652 - val_loss: 0.3907 - val_accuracy: 0.8500\n",
            "Epoch 127/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.3214 - accuracy: 0.8699 - val_loss: 0.4211 - val_accuracy: 0.8188\n",
            "Epoch 128/200\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.3453 - accuracy: 0.8480 - val_loss: 0.3947 - val_accuracy: 0.8062\n",
            "Epoch 129/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.3309 - accuracy: 0.8683 - val_loss: 0.4006 - val_accuracy: 0.8250\n",
            "Epoch 130/200\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.3404 - accuracy: 0.8605 - val_loss: 0.3907 - val_accuracy: 0.8562\n",
            "Epoch 131/200\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.3254 - accuracy: 0.8652 - val_loss: 0.4190 - val_accuracy: 0.8188\n",
            "Epoch 132/200\n",
            "20/20 [==============================] - 0s 6ms/step - loss: 0.3196 - accuracy: 0.8762 - val_loss: 0.4314 - val_accuracy: 0.8000\n",
            "Epoch 133/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.3138 - accuracy: 0.8777 - val_loss: 0.3554 - val_accuracy: 0.8750\n",
            "Epoch 134/200\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.3233 - accuracy: 0.8793 - val_loss: 0.3615 - val_accuracy: 0.8813\n",
            "Epoch 135/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.3338 - accuracy: 0.8621 - val_loss: 0.3973 - val_accuracy: 0.8375\n",
            "Epoch 136/200\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.3121 - accuracy: 0.8856 - val_loss: 0.4102 - val_accuracy: 0.8313\n",
            "Epoch 137/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.3281 - accuracy: 0.8574 - val_loss: 0.4070 - val_accuracy: 0.8188\n",
            "Epoch 138/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.3172 - accuracy: 0.8636 - val_loss: 0.4041 - val_accuracy: 0.8250\n",
            "Epoch 139/200\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.3029 - accuracy: 0.8793 - val_loss: 0.3649 - val_accuracy: 0.8562\n",
            "Epoch 140/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.3166 - accuracy: 0.8668 - val_loss: 0.3851 - val_accuracy: 0.8562\n",
            "Epoch 141/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.3106 - accuracy: 0.8777 - val_loss: 0.3576 - val_accuracy: 0.8687\n",
            "Epoch 142/200\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.3276 - accuracy: 0.8668 - val_loss: 0.3870 - val_accuracy: 0.8438\n",
            "Epoch 143/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.3334 - accuracy: 0.8652 - val_loss: 0.3819 - val_accuracy: 0.8438\n",
            "Epoch 144/200\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.3207 - accuracy: 0.8715 - val_loss: 0.3573 - val_accuracy: 0.8687\n",
            "Epoch 145/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.3132 - accuracy: 0.8636 - val_loss: 0.3597 - val_accuracy: 0.8625\n",
            "Epoch 146/200\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.3226 - accuracy: 0.8715 - val_loss: 0.4182 - val_accuracy: 0.8062\n",
            "Epoch 147/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.3042 - accuracy: 0.8809 - val_loss: 0.4364 - val_accuracy: 0.8125\n",
            "Epoch 148/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.3173 - accuracy: 0.8715 - val_loss: 0.3650 - val_accuracy: 0.8750\n",
            "Epoch 149/200\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.3173 - accuracy: 0.8793 - val_loss: 0.3755 - val_accuracy: 0.8562\n",
            "Epoch 150/200\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.3159 - accuracy: 0.8809 - val_loss: 0.3898 - val_accuracy: 0.8438\n",
            "Epoch 151/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.3154 - accuracy: 0.8809 - val_loss: 0.3481 - val_accuracy: 0.8750\n",
            "Epoch 152/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.3163 - accuracy: 0.8605 - val_loss: 0.3577 - val_accuracy: 0.8750\n",
            "Epoch 153/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.3216 - accuracy: 0.8699 - val_loss: 0.3678 - val_accuracy: 0.8562\n",
            "Epoch 154/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.3262 - accuracy: 0.8699 - val_loss: 0.3523 - val_accuracy: 0.8875\n",
            "Epoch 155/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.3322 - accuracy: 0.8699 - val_loss: 0.3779 - val_accuracy: 0.8500\n",
            "Epoch 156/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.3145 - accuracy: 0.8715 - val_loss: 0.4290 - val_accuracy: 0.8188\n",
            "Epoch 157/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.3049 - accuracy: 0.8762 - val_loss: 0.3846 - val_accuracy: 0.8438\n",
            "Epoch 158/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.3260 - accuracy: 0.8621 - val_loss: 0.4247 - val_accuracy: 0.8062\n",
            "Epoch 159/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.3142 - accuracy: 0.8715 - val_loss: 0.3783 - val_accuracy: 0.8687\n",
            "Epoch 160/200\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.3004 - accuracy: 0.8840 - val_loss: 0.4040 - val_accuracy: 0.8500\n",
            "Epoch 161/200\n",
            "20/20 [==============================] - 0s 6ms/step - loss: 0.3093 - accuracy: 0.8730 - val_loss: 0.3641 - val_accuracy: 0.8562\n",
            "Epoch 162/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.2906 - accuracy: 0.8856 - val_loss: 0.3641 - val_accuracy: 0.8562\n",
            "Epoch 163/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.2955 - accuracy: 0.8762 - val_loss: 0.4229 - val_accuracy: 0.8125\n",
            "Epoch 164/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.2987 - accuracy: 0.8777 - val_loss: 0.4374 - val_accuracy: 0.8188\n",
            "Epoch 165/200\n",
            "20/20 [==============================] - 0s 6ms/step - loss: 0.3062 - accuracy: 0.8730 - val_loss: 0.3704 - val_accuracy: 0.8500\n",
            "Epoch 166/200\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.2932 - accuracy: 0.8824 - val_loss: 0.3811 - val_accuracy: 0.8500\n",
            "Epoch 167/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.3002 - accuracy: 0.8746 - val_loss: 0.4019 - val_accuracy: 0.8375\n",
            "Epoch 168/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.3037 - accuracy: 0.8809 - val_loss: 0.3819 - val_accuracy: 0.8375\n",
            "Epoch 169/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.3035 - accuracy: 0.8762 - val_loss: 0.4056 - val_accuracy: 0.8188\n",
            "Epoch 170/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.2682 - accuracy: 0.8981 - val_loss: 0.3749 - val_accuracy: 0.8438\n",
            "Epoch 171/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.3135 - accuracy: 0.8762 - val_loss: 0.4353 - val_accuracy: 0.8000\n",
            "Epoch 172/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.3008 - accuracy: 0.8809 - val_loss: 0.3858 - val_accuracy: 0.8438\n",
            "Epoch 173/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.3031 - accuracy: 0.8699 - val_loss: 0.3854 - val_accuracy: 0.8500\n",
            "Epoch 174/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.3091 - accuracy: 0.8824 - val_loss: 0.4088 - val_accuracy: 0.8562\n",
            "Epoch 175/200\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.2975 - accuracy: 0.8699 - val_loss: 0.4106 - val_accuracy: 0.8438\n",
            "Epoch 176/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.2961 - accuracy: 0.8840 - val_loss: 0.3956 - val_accuracy: 0.8562\n",
            "Epoch 177/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.2881 - accuracy: 0.8809 - val_loss: 0.3989 - val_accuracy: 0.8438\n",
            "Epoch 178/200\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.2845 - accuracy: 0.8699 - val_loss: 0.3791 - val_accuracy: 0.8313\n",
            "Epoch 179/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.2973 - accuracy: 0.8730 - val_loss: 0.3937 - val_accuracy: 0.8438\n",
            "Epoch 180/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.2824 - accuracy: 0.8856 - val_loss: 0.4070 - val_accuracy: 0.8562\n",
            "Epoch 181/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.3036 - accuracy: 0.8730 - val_loss: 0.3837 - val_accuracy: 0.8438\n",
            "Epoch 182/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.2872 - accuracy: 0.8824 - val_loss: 0.3629 - val_accuracy: 0.8750\n",
            "Epoch 183/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.2965 - accuracy: 0.8746 - val_loss: 0.3747 - val_accuracy: 0.8687\n",
            "Epoch 184/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.3119 - accuracy: 0.8762 - val_loss: 0.3708 - val_accuracy: 0.8813\n",
            "Epoch 185/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.3062 - accuracy: 0.8621 - val_loss: 0.4251 - val_accuracy: 0.8562\n",
            "Epoch 186/200\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.2823 - accuracy: 0.8746 - val_loss: 0.4157 - val_accuracy: 0.8562\n",
            "Epoch 187/200\n",
            "20/20 [==============================] - 0s 6ms/step - loss: 0.2876 - accuracy: 0.8746 - val_loss: 0.4673 - val_accuracy: 0.8062\n",
            "Epoch 188/200\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.2662 - accuracy: 0.8887 - val_loss: 0.3985 - val_accuracy: 0.8625\n",
            "Epoch 189/200\n",
            "20/20 [==============================] - 0s 6ms/step - loss: 0.3063 - accuracy: 0.8777 - val_loss: 0.3916 - val_accuracy: 0.8500\n",
            "Epoch 190/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.2904 - accuracy: 0.8809 - val_loss: 0.4553 - val_accuracy: 0.7875\n",
            "Epoch 191/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.2997 - accuracy: 0.8824 - val_loss: 0.3973 - val_accuracy: 0.8313\n",
            "Epoch 192/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.3006 - accuracy: 0.8668 - val_loss: 0.3870 - val_accuracy: 0.8562\n",
            "Epoch 193/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.3006 - accuracy: 0.8777 - val_loss: 0.4215 - val_accuracy: 0.8500\n",
            "Epoch 194/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.2910 - accuracy: 0.8840 - val_loss: 0.3898 - val_accuracy: 0.8500\n",
            "Epoch 195/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.2967 - accuracy: 0.8777 - val_loss: 0.4167 - val_accuracy: 0.8125\n",
            "Epoch 196/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.2784 - accuracy: 0.8746 - val_loss: 0.4299 - val_accuracy: 0.8188\n",
            "Epoch 197/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.2824 - accuracy: 0.8762 - val_loss: 0.4022 - val_accuracy: 0.8625\n",
            "Epoch 198/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.2802 - accuracy: 0.8730 - val_loss: 0.4282 - val_accuracy: 0.8375\n",
            "Epoch 199/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.2789 - accuracy: 0.8809 - val_loss: 0.4145 - val_accuracy: 0.8188\n",
            "Epoch 200/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.2989 - accuracy: 0.8746 - val_loss: 0.3713 - val_accuracy: 0.8562\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.4300 - accuracy: 0.8333\n",
            "## evaluation loss and_metrics ##\n",
            "[0.42995646595954895, 0.8333333134651184]\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "0.8285714285714286\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "ChestPainType_ATAscore=recall_score(y_test,y_pred_classChestPainType_ATA)\n",
        "print(ChestPainType_ATAscore)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1BFTSjVKq8OE",
        "outputId": "816e8404-5289-41d9-daf4-f33ad161a7eb"
      },
      "execution_count": 92,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.8285714285714286\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "ChestPainType_NAP"
      ],
      "metadata": {
        "id": "qiktin0yq5O4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "heart = pd.read_csv(f_path)\n",
        "\n",
        "heart = pd.get_dummies(heart)\n",
        "\n",
        "x = heart.drop('HeartDisease', axis=1)\n",
        "y = pd.get_dummies(heart[\"HeartDisease\"])\n",
        "\n",
        "heart['ChestPainType_NAP'] = 0\n",
        "\n",
        "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size = 0.13,shuffle=True, random_state = 42)\n",
        "\n",
        "print(\"X_train: \", x_train.shape)\n",
        "print(\"y_train: \", y_train.shape)\n",
        "\n",
        "print(\"X_test: \", x_test.shape)\n",
        "print(\"y_test: \", y_test.shape)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "ModelExceptChestPainType_NAP = Sequential()\n",
        "\n",
        "\n",
        "ModelExceptChestPainType_NAP.add(Dense(128, activation = \"relu\",input_dim=20))\n",
        "ModelExceptChestPainType_NAP.add(Dropout(rate=0.2))\n",
        "ModelExceptChestPainType_NAP.add(Dense(64, activation = \"relu\"))\n",
        "ModelExceptChestPainType_NAP.add(Dropout(rate=0.2))\n",
        "ModelExceptChestPainType_NAP.add(Dense(32, activation = \"relu\"))\n",
        "ModelExceptChestPainType_NAP.add(Dropout(rate=0.1))\n",
        "ModelExceptChestPainType_NAP.add(Dense(16, activation = \"relu\"))\n",
        "ModelExceptChestPainType_NAP.add(Dense(8, activation = \"relu\"))\n",
        "ModelExceptChestPainType_NAP.add(Dense(2, activation = \"sigmoid\"))\n",
        "\n",
        "ModelExceptChestPainType_NAP.compile(optimizer = \"adam\", loss = \"categorical_crossentropy\", metrics = [\"accuracy\"])\n",
        "ModelExceptChestPainType_NAP.summary()\n",
        "\n",
        "hin=ModelExceptChestPainType_NAP.fit(x_train,y_train,epochs=200, validation_split=0.2)\n",
        "\n",
        "loss_and_metrics = ModelExceptChestPainType_NAP.evaluate(x_test, y_test, batch_size=32)\n",
        "print('## evaluation loss and_metrics ##')\n",
        "print(loss_and_metrics)\n",
        "\n",
        "y_predChestPainType_NAP = ModelExceptChestPainType_NAP.predict(x_test)\n",
        "y_predChestPainType_NAP\n",
        "\n",
        "y_pred_classChestPainType_NAP = np.argmax(y_predChestPainType_NAP, axis=1)\n",
        "y_pred_classChestPainType_NAP\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "y_test  = y_test.to_numpy()\n",
        "y_test\n",
        "\n",
        "y_test = np.argmax(y_test,axis=1)\n",
        "y_test\n",
        "\n",
        "np.mean(y_test == y_pred_classChestPainType_NAP)\n",
        "ChestPainType_NAPscore=recall_score(y_test,y_pred_classChestPainType_NAP)\n",
        "print(ChestPainType_NAPscore)"
      ],
      "metadata": {
        "id": "zJ2JCg5yy8Qi",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "28c2875b-3e3d-4746-977a-6ac1afe68200"
      },
      "execution_count": 93,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "X_train:  (798, 20)\n",
            "y_train:  (798, 2)\n",
            "X_test:  (120, 20)\n",
            "y_test:  (120, 2)\n",
            "Model: \"sequential_15\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense_90 (Dense)            (None, 128)               2688      \n",
            "                                                                 \n",
            " dropout_45 (Dropout)        (None, 128)               0         \n",
            "                                                                 \n",
            " dense_91 (Dense)            (None, 64)                8256      \n",
            "                                                                 \n",
            " dropout_46 (Dropout)        (None, 64)                0         \n",
            "                                                                 \n",
            " dense_92 (Dense)            (None, 32)                2080      \n",
            "                                                                 \n",
            " dropout_47 (Dropout)        (None, 32)                0         \n",
            "                                                                 \n",
            " dense_93 (Dense)            (None, 16)                528       \n",
            "                                                                 \n",
            " dense_94 (Dense)            (None, 8)                 136       \n",
            "                                                                 \n",
            " dense_95 (Dense)            (None, 2)                 18        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 13,706\n",
            "Trainable params: 13,706\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/200\n",
            "20/20 [==============================] - 1s 13ms/step - loss: 5.0670 - accuracy: 0.5533 - val_loss: 0.6688 - val_accuracy: 0.5000\n",
            "Epoch 2/200\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 1.5674 - accuracy: 0.5596 - val_loss: 0.9124 - val_accuracy: 0.4938\n",
            "Epoch 3/200\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 1.2162 - accuracy: 0.5533 - val_loss: 0.6226 - val_accuracy: 0.5750\n",
            "Epoch 4/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 1.0714 - accuracy: 0.5752 - val_loss: 0.7566 - val_accuracy: 0.4938\n",
            "Epoch 5/200\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.9607 - accuracy: 0.5298 - val_loss: 0.6740 - val_accuracy: 0.4938\n",
            "Epoch 6/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.8150 - accuracy: 0.5345 - val_loss: 0.6739 - val_accuracy: 0.4812\n",
            "Epoch 7/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.7761 - accuracy: 0.5219 - val_loss: 0.6853 - val_accuracy: 0.4187\n",
            "Epoch 8/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.7375 - accuracy: 0.5533 - val_loss: 0.6354 - val_accuracy: 0.4375\n",
            "Epoch 9/200\n",
            "20/20 [==============================] - 0s 6ms/step - loss: 0.7218 - accuracy: 0.5674 - val_loss: 0.6101 - val_accuracy: 0.6313\n",
            "Epoch 10/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.7233 - accuracy: 0.5768 - val_loss: 0.5979 - val_accuracy: 0.6750\n",
            "Epoch 11/200\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.7652 - accuracy: 0.5502 - val_loss: 0.6098 - val_accuracy: 0.6250\n",
            "Epoch 12/200\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.7075 - accuracy: 0.5392 - val_loss: 0.6000 - val_accuracy: 0.6750\n",
            "Epoch 13/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.7033 - accuracy: 0.5423 - val_loss: 0.6093 - val_accuracy: 0.5375\n",
            "Epoch 14/200\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.6969 - accuracy: 0.5611 - val_loss: 0.6252 - val_accuracy: 0.5000\n",
            "Epoch 15/200\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.7095 - accuracy: 0.5219 - val_loss: 0.6238 - val_accuracy: 0.5000\n",
            "Epoch 16/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.6730 - accuracy: 0.5737 - val_loss: 0.6195 - val_accuracy: 0.5063\n",
            "Epoch 17/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.6757 - accuracy: 0.5549 - val_loss: 0.6087 - val_accuracy: 0.6750\n",
            "Epoch 18/200\n",
            "20/20 [==============================] - 0s 6ms/step - loss: 0.6718 - accuracy: 0.5376 - val_loss: 0.6210 - val_accuracy: 0.5000\n",
            "Epoch 19/200\n",
            "20/20 [==============================] - 0s 7ms/step - loss: 0.6634 - accuracy: 0.5956 - val_loss: 0.6127 - val_accuracy: 0.6750\n",
            "Epoch 20/200\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.6659 - accuracy: 0.5423 - val_loss: 0.6280 - val_accuracy: 0.4938\n",
            "Epoch 21/200\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.6658 - accuracy: 0.5768 - val_loss: 0.6225 - val_accuracy: 0.5000\n",
            "Epoch 22/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.6612 - accuracy: 0.6019 - val_loss: 0.5937 - val_accuracy: 0.7000\n",
            "Epoch 23/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.6777 - accuracy: 0.5282 - val_loss: 0.6072 - val_accuracy: 0.6687\n",
            "Epoch 24/200\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.6593 - accuracy: 0.5643 - val_loss: 0.6183 - val_accuracy: 0.5063\n",
            "Epoch 25/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.6340 - accuracy: 0.5925 - val_loss: 0.6045 - val_accuracy: 0.7625\n",
            "Epoch 26/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.6463 - accuracy: 0.5893 - val_loss: 0.6100 - val_accuracy: 0.7500\n",
            "Epoch 27/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.6680 - accuracy: 0.5893 - val_loss: 0.6095 - val_accuracy: 0.7188\n",
            "Epoch 28/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.6628 - accuracy: 0.6066 - val_loss: 0.6053 - val_accuracy: 0.7312\n",
            "Epoch 29/200\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.6682 - accuracy: 0.6066 - val_loss: 0.6020 - val_accuracy: 0.7250\n",
            "Epoch 30/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.6441 - accuracy: 0.6082 - val_loss: 0.6085 - val_accuracy: 0.6438\n",
            "Epoch 31/200\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.6393 - accuracy: 0.6395 - val_loss: 0.5985 - val_accuracy: 0.7063\n",
            "Epoch 32/200\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.6361 - accuracy: 0.6176 - val_loss: 0.6027 - val_accuracy: 0.6875\n",
            "Epoch 33/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.6386 - accuracy: 0.6442 - val_loss: 0.6071 - val_accuracy: 0.6313\n",
            "Epoch 34/200\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.6558 - accuracy: 0.6317 - val_loss: 0.6160 - val_accuracy: 0.5750\n",
            "Epoch 35/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.6348 - accuracy: 0.6630 - val_loss: 0.6092 - val_accuracy: 0.6313\n",
            "Epoch 36/200\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.6233 - accuracy: 0.6364 - val_loss: 0.6159 - val_accuracy: 0.5688\n",
            "Epoch 37/200\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.6424 - accuracy: 0.6458 - val_loss: 0.5986 - val_accuracy: 0.6562\n",
            "Epoch 38/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.6387 - accuracy: 0.6505 - val_loss: 0.6226 - val_accuracy: 0.5437\n",
            "Epoch 39/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.6320 - accuracy: 0.6442 - val_loss: 0.6145 - val_accuracy: 0.6125\n",
            "Epoch 40/200\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.6081 - accuracy: 0.6552 - val_loss: 0.6056 - val_accuracy: 0.6375\n",
            "Epoch 41/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.6231 - accuracy: 0.6552 - val_loss: 0.5887 - val_accuracy: 0.7125\n",
            "Epoch 42/200\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.6277 - accuracy: 0.6787 - val_loss: 0.5771 - val_accuracy: 0.7188\n",
            "Epoch 43/200\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.6168 - accuracy: 0.6897 - val_loss: 0.5879 - val_accuracy: 0.7188\n",
            "Epoch 44/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.6034 - accuracy: 0.6693 - val_loss: 0.6114 - val_accuracy: 0.6000\n",
            "Epoch 45/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.6375 - accuracy: 0.6364 - val_loss: 0.6273 - val_accuracy: 0.5500\n",
            "Epoch 46/200\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.6099 - accuracy: 0.6975 - val_loss: 0.5685 - val_accuracy: 0.7250\n",
            "Epoch 47/200\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.5981 - accuracy: 0.6865 - val_loss: 0.5895 - val_accuracy: 0.7000\n",
            "Epoch 48/200\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.6122 - accuracy: 0.6834 - val_loss: 0.5836 - val_accuracy: 0.7000\n",
            "Epoch 49/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.5993 - accuracy: 0.6975 - val_loss: 0.5791 - val_accuracy: 0.7125\n",
            "Epoch 50/200\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.5901 - accuracy: 0.6959 - val_loss: 0.5803 - val_accuracy: 0.6625\n",
            "Epoch 51/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.5964 - accuracy: 0.7038 - val_loss: 0.5656 - val_accuracy: 0.7188\n",
            "Epoch 52/200\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.5951 - accuracy: 0.6928 - val_loss: 0.5692 - val_accuracy: 0.7063\n",
            "Epoch 53/200\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.5974 - accuracy: 0.6818 - val_loss: 0.5526 - val_accuracy: 0.7312\n",
            "Epoch 54/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.6041 - accuracy: 0.7085 - val_loss: 0.5544 - val_accuracy: 0.7437\n",
            "Epoch 55/200\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.5903 - accuracy: 0.7194 - val_loss: 0.5570 - val_accuracy: 0.7500\n",
            "Epoch 56/200\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.5720 - accuracy: 0.7335 - val_loss: 0.5645 - val_accuracy: 0.7312\n",
            "Epoch 57/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.5494 - accuracy: 0.7508 - val_loss: 0.5478 - val_accuracy: 0.7437\n",
            "Epoch 58/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.5803 - accuracy: 0.7163 - val_loss: 0.5598 - val_accuracy: 0.7312\n",
            "Epoch 59/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.5718 - accuracy: 0.7257 - val_loss: 0.5331 - val_accuracy: 0.7625\n",
            "Epoch 60/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.5642 - accuracy: 0.7304 - val_loss: 0.5745 - val_accuracy: 0.7063\n",
            "Epoch 61/200\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.5503 - accuracy: 0.7226 - val_loss: 0.5892 - val_accuracy: 0.6500\n",
            "Epoch 62/200\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.5688 - accuracy: 0.7273 - val_loss: 0.5431 - val_accuracy: 0.7375\n",
            "Epoch 63/200\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.5583 - accuracy: 0.7304 - val_loss: 0.5307 - val_accuracy: 0.7375\n",
            "Epoch 64/200\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.5648 - accuracy: 0.7320 - val_loss: 0.5264 - val_accuracy: 0.7437\n",
            "Epoch 65/200\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.5596 - accuracy: 0.7320 - val_loss: 0.5635 - val_accuracy: 0.6875\n",
            "Epoch 66/200\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.5595 - accuracy: 0.7414 - val_loss: 0.5347 - val_accuracy: 0.7750\n",
            "Epoch 67/200\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.5432 - accuracy: 0.7476 - val_loss: 0.5431 - val_accuracy: 0.7375\n",
            "Epoch 68/200\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.5405 - accuracy: 0.7508 - val_loss: 0.5120 - val_accuracy: 0.7563\n",
            "Epoch 69/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.5444 - accuracy: 0.7398 - val_loss: 0.5328 - val_accuracy: 0.7375\n",
            "Epoch 70/200\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.5447 - accuracy: 0.7367 - val_loss: 0.4901 - val_accuracy: 0.8062\n",
            "Epoch 71/200\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.5337 - accuracy: 0.7571 - val_loss: 0.5232 - val_accuracy: 0.7437\n",
            "Epoch 72/200\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.5499 - accuracy: 0.7398 - val_loss: 0.5079 - val_accuracy: 0.7563\n",
            "Epoch 73/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.5323 - accuracy: 0.7445 - val_loss: 0.5051 - val_accuracy: 0.7563\n",
            "Epoch 74/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.5385 - accuracy: 0.7508 - val_loss: 0.5109 - val_accuracy: 0.7625\n",
            "Epoch 75/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.5382 - accuracy: 0.7398 - val_loss: 0.4763 - val_accuracy: 0.7875\n",
            "Epoch 76/200\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.5165 - accuracy: 0.7696 - val_loss: 0.5112 - val_accuracy: 0.7375\n",
            "Epoch 77/200\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.5146 - accuracy: 0.7618 - val_loss: 0.4606 - val_accuracy: 0.8062\n",
            "Epoch 78/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.4914 - accuracy: 0.7900 - val_loss: 0.4771 - val_accuracy: 0.8062\n",
            "Epoch 79/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.5138 - accuracy: 0.7586 - val_loss: 0.4569 - val_accuracy: 0.8250\n",
            "Epoch 80/200\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.5083 - accuracy: 0.7649 - val_loss: 0.4976 - val_accuracy: 0.7750\n",
            "Epoch 81/200\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.4819 - accuracy: 0.7994 - val_loss: 0.4499 - val_accuracy: 0.8313\n",
            "Epoch 82/200\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.4820 - accuracy: 0.7994 - val_loss: 0.4542 - val_accuracy: 0.8188\n",
            "Epoch 83/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.4724 - accuracy: 0.7884 - val_loss: 0.4531 - val_accuracy: 0.8375\n",
            "Epoch 84/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.4911 - accuracy: 0.7837 - val_loss: 0.4355 - val_accuracy: 0.8250\n",
            "Epoch 85/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.4716 - accuracy: 0.7947 - val_loss: 0.5187 - val_accuracy: 0.7625\n",
            "Epoch 86/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.4844 - accuracy: 0.7931 - val_loss: 0.4542 - val_accuracy: 0.8188\n",
            "Epoch 87/200\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.4802 - accuracy: 0.7994 - val_loss: 0.4930 - val_accuracy: 0.7750\n",
            "Epoch 88/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.4713 - accuracy: 0.7837 - val_loss: 0.4734 - val_accuracy: 0.7812\n",
            "Epoch 89/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.4933 - accuracy: 0.7947 - val_loss: 0.4400 - val_accuracy: 0.8125\n",
            "Epoch 90/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.4755 - accuracy: 0.7900 - val_loss: 0.4314 - val_accuracy: 0.8438\n",
            "Epoch 91/200\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.4465 - accuracy: 0.8056 - val_loss: 0.4394 - val_accuracy: 0.8250\n",
            "Epoch 92/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.4477 - accuracy: 0.8213 - val_loss: 0.4446 - val_accuracy: 0.8250\n",
            "Epoch 93/200\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.4529 - accuracy: 0.7962 - val_loss: 0.4234 - val_accuracy: 0.8438\n",
            "Epoch 94/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.4435 - accuracy: 0.8009 - val_loss: 0.4420 - val_accuracy: 0.8000\n",
            "Epoch 95/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.4528 - accuracy: 0.8119 - val_loss: 0.4279 - val_accuracy: 0.8313\n",
            "Epoch 96/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.4384 - accuracy: 0.8135 - val_loss: 0.4369 - val_accuracy: 0.8188\n",
            "Epoch 97/200\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.4282 - accuracy: 0.8292 - val_loss: 0.4128 - val_accuracy: 0.8313\n",
            "Epoch 98/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.4292 - accuracy: 0.8213 - val_loss: 0.4626 - val_accuracy: 0.7937\n",
            "Epoch 99/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.4160 - accuracy: 0.8354 - val_loss: 0.4054 - val_accuracy: 0.8438\n",
            "Epoch 100/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.4440 - accuracy: 0.8182 - val_loss: 0.4115 - val_accuracy: 0.8438\n",
            "Epoch 101/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.4236 - accuracy: 0.8386 - val_loss: 0.4151 - val_accuracy: 0.8375\n",
            "Epoch 102/200\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.4077 - accuracy: 0.8448 - val_loss: 0.5140 - val_accuracy: 0.7937\n",
            "Epoch 103/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.4268 - accuracy: 0.8103 - val_loss: 0.4117 - val_accuracy: 0.8438\n",
            "Epoch 104/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.4199 - accuracy: 0.8197 - val_loss: 0.4087 - val_accuracy: 0.8438\n",
            "Epoch 105/200\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.4137 - accuracy: 0.8292 - val_loss: 0.3871 - val_accuracy: 0.8562\n",
            "Epoch 106/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.4080 - accuracy: 0.8354 - val_loss: 0.4526 - val_accuracy: 0.8250\n",
            "Epoch 107/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.3981 - accuracy: 0.8401 - val_loss: 0.4557 - val_accuracy: 0.8313\n",
            "Epoch 108/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.4076 - accuracy: 0.8260 - val_loss: 0.3888 - val_accuracy: 0.8500\n",
            "Epoch 109/200\n",
            "20/20 [==============================] - 0s 6ms/step - loss: 0.3966 - accuracy: 0.8417 - val_loss: 0.4147 - val_accuracy: 0.8438\n",
            "Epoch 110/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.3932 - accuracy: 0.8401 - val_loss: 0.4617 - val_accuracy: 0.8313\n",
            "Epoch 111/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.4067 - accuracy: 0.8292 - val_loss: 0.3822 - val_accuracy: 0.8687\n",
            "Epoch 112/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.3970 - accuracy: 0.8401 - val_loss: 0.3862 - val_accuracy: 0.8625\n",
            "Epoch 113/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.3751 - accuracy: 0.8542 - val_loss: 0.4066 - val_accuracy: 0.8438\n",
            "Epoch 114/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.4080 - accuracy: 0.8150 - val_loss: 0.3940 - val_accuracy: 0.8562\n",
            "Epoch 115/200\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.3957 - accuracy: 0.8448 - val_loss: 0.4755 - val_accuracy: 0.8062\n",
            "Epoch 116/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.3769 - accuracy: 0.8464 - val_loss: 0.3722 - val_accuracy: 0.8625\n",
            "Epoch 117/200\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.3870 - accuracy: 0.8401 - val_loss: 0.3867 - val_accuracy: 0.8500\n",
            "Epoch 118/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.3769 - accuracy: 0.8417 - val_loss: 0.3923 - val_accuracy: 0.8500\n",
            "Epoch 119/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.3773 - accuracy: 0.8433 - val_loss: 0.4300 - val_accuracy: 0.8375\n",
            "Epoch 120/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.3559 - accuracy: 0.8480 - val_loss: 0.3875 - val_accuracy: 0.8562\n",
            "Epoch 121/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.3892 - accuracy: 0.8197 - val_loss: 0.3935 - val_accuracy: 0.8562\n",
            "Epoch 122/200\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.3531 - accuracy: 0.8558 - val_loss: 0.4635 - val_accuracy: 0.8125\n",
            "Epoch 123/200\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.3634 - accuracy: 0.8448 - val_loss: 0.3927 - val_accuracy: 0.8500\n",
            "Epoch 124/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.3706 - accuracy: 0.8542 - val_loss: 0.3784 - val_accuracy: 0.8625\n",
            "Epoch 125/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.3692 - accuracy: 0.8495 - val_loss: 0.3585 - val_accuracy: 0.8625\n",
            "Epoch 126/200\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.3446 - accuracy: 0.8699 - val_loss: 0.3841 - val_accuracy: 0.8562\n",
            "Epoch 127/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.3639 - accuracy: 0.8605 - val_loss: 0.4683 - val_accuracy: 0.8000\n",
            "Epoch 128/200\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.3638 - accuracy: 0.8527 - val_loss: 0.4029 - val_accuracy: 0.8313\n",
            "Epoch 129/200\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.3702 - accuracy: 0.8464 - val_loss: 0.3868 - val_accuracy: 0.8438\n",
            "Epoch 130/200\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.3542 - accuracy: 0.8574 - val_loss: 0.3951 - val_accuracy: 0.8438\n",
            "Epoch 131/200\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.3577 - accuracy: 0.8480 - val_loss: 0.4039 - val_accuracy: 0.8375\n",
            "Epoch 132/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.3624 - accuracy: 0.8558 - val_loss: 0.3702 - val_accuracy: 0.8500\n",
            "Epoch 133/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.3565 - accuracy: 0.8730 - val_loss: 0.3687 - val_accuracy: 0.8625\n",
            "Epoch 134/200\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.3652 - accuracy: 0.8480 - val_loss: 0.3709 - val_accuracy: 0.8562\n",
            "Epoch 135/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.3477 - accuracy: 0.8527 - val_loss: 0.3673 - val_accuracy: 0.8562\n",
            "Epoch 136/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.3587 - accuracy: 0.8683 - val_loss: 0.3549 - val_accuracy: 0.8562\n",
            "Epoch 137/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.3624 - accuracy: 0.8448 - val_loss: 0.3612 - val_accuracy: 0.8625\n",
            "Epoch 138/200\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.3489 - accuracy: 0.8621 - val_loss: 0.3627 - val_accuracy: 0.8813\n",
            "Epoch 139/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.3501 - accuracy: 0.8589 - val_loss: 0.5054 - val_accuracy: 0.7812\n",
            "Epoch 140/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.3660 - accuracy: 0.8558 - val_loss: 0.4144 - val_accuracy: 0.8375\n",
            "Epoch 141/200\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.3359 - accuracy: 0.8668 - val_loss: 0.3599 - val_accuracy: 0.8750\n",
            "Epoch 142/200\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.3571 - accuracy: 0.8605 - val_loss: 0.3667 - val_accuracy: 0.8687\n",
            "Epoch 143/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.3754 - accuracy: 0.8417 - val_loss: 0.4237 - val_accuracy: 0.8125\n",
            "Epoch 144/200\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.3546 - accuracy: 0.8605 - val_loss: 0.3980 - val_accuracy: 0.8313\n",
            "Epoch 145/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.3460 - accuracy: 0.8574 - val_loss: 0.3470 - val_accuracy: 0.8813\n",
            "Epoch 146/200\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.3357 - accuracy: 0.8683 - val_loss: 0.4010 - val_accuracy: 0.8313\n",
            "Epoch 147/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.3336 - accuracy: 0.8542 - val_loss: 0.3796 - val_accuracy: 0.8500\n",
            "Epoch 148/200\n",
            "20/20 [==============================] - 0s 6ms/step - loss: 0.3445 - accuracy: 0.8683 - val_loss: 0.3806 - val_accuracy: 0.8500\n",
            "Epoch 149/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.3003 - accuracy: 0.8730 - val_loss: 0.3933 - val_accuracy: 0.8438\n",
            "Epoch 150/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.3222 - accuracy: 0.8777 - val_loss: 0.4048 - val_accuracy: 0.8250\n",
            "Epoch 151/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.3349 - accuracy: 0.8652 - val_loss: 0.3643 - val_accuracy: 0.8625\n",
            "Epoch 152/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.3369 - accuracy: 0.8730 - val_loss: 0.3874 - val_accuracy: 0.8500\n",
            "Epoch 153/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.3404 - accuracy: 0.8589 - val_loss: 0.3660 - val_accuracy: 0.8625\n",
            "Epoch 154/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.3345 - accuracy: 0.8636 - val_loss: 0.3788 - val_accuracy: 0.8438\n",
            "Epoch 155/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.3316 - accuracy: 0.8777 - val_loss: 0.4247 - val_accuracy: 0.8188\n",
            "Epoch 156/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.3208 - accuracy: 0.8746 - val_loss: 0.3717 - val_accuracy: 0.8438\n",
            "Epoch 157/200\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.3439 - accuracy: 0.8621 - val_loss: 0.4481 - val_accuracy: 0.8188\n",
            "Epoch 158/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.3278 - accuracy: 0.8762 - val_loss: 0.3512 - val_accuracy: 0.8750\n",
            "Epoch 159/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.3239 - accuracy: 0.8699 - val_loss: 0.3850 - val_accuracy: 0.8375\n",
            "Epoch 160/200\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.3210 - accuracy: 0.8793 - val_loss: 0.3861 - val_accuracy: 0.8375\n",
            "Epoch 161/200\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.3143 - accuracy: 0.8715 - val_loss: 0.3937 - val_accuracy: 0.8438\n",
            "Epoch 162/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.3157 - accuracy: 0.8746 - val_loss: 0.3900 - val_accuracy: 0.8687\n",
            "Epoch 163/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.3189 - accuracy: 0.8809 - val_loss: 0.3659 - val_accuracy: 0.8687\n",
            "Epoch 164/200\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.3221 - accuracy: 0.8730 - val_loss: 0.3699 - val_accuracy: 0.8625\n",
            "Epoch 165/200\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.3151 - accuracy: 0.8840 - val_loss: 0.4196 - val_accuracy: 0.8250\n",
            "Epoch 166/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.3418 - accuracy: 0.8574 - val_loss: 0.3668 - val_accuracy: 0.8687\n",
            "Epoch 167/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.3253 - accuracy: 0.8668 - val_loss: 0.4722 - val_accuracy: 0.7875\n",
            "Epoch 168/200\n",
            "20/20 [==============================] - 0s 6ms/step - loss: 0.3523 - accuracy: 0.8652 - val_loss: 0.4182 - val_accuracy: 0.8188\n",
            "Epoch 169/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.3306 - accuracy: 0.8636 - val_loss: 0.3808 - val_accuracy: 0.8438\n",
            "Epoch 170/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.3168 - accuracy: 0.8746 - val_loss: 0.3886 - val_accuracy: 0.8500\n",
            "Epoch 171/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.3143 - accuracy: 0.8715 - val_loss: 0.3793 - val_accuracy: 0.8438\n",
            "Epoch 172/200\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.3017 - accuracy: 0.8871 - val_loss: 0.4119 - val_accuracy: 0.8313\n",
            "Epoch 173/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.3305 - accuracy: 0.8809 - val_loss: 0.4703 - val_accuracy: 0.7812\n",
            "Epoch 174/200\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.3052 - accuracy: 0.8683 - val_loss: 0.4116 - val_accuracy: 0.8438\n",
            "Epoch 175/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.3351 - accuracy: 0.8762 - val_loss: 0.4310 - val_accuracy: 0.8062\n",
            "Epoch 176/200\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.3107 - accuracy: 0.8777 - val_loss: 0.3770 - val_accuracy: 0.8625\n",
            "Epoch 177/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.3161 - accuracy: 0.8887 - val_loss: 0.3765 - val_accuracy: 0.8625\n",
            "Epoch 178/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.3245 - accuracy: 0.8715 - val_loss: 0.4228 - val_accuracy: 0.8188\n",
            "Epoch 179/200\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.3023 - accuracy: 0.8840 - val_loss: 0.4267 - val_accuracy: 0.8250\n",
            "Epoch 180/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.3097 - accuracy: 0.8668 - val_loss: 0.3567 - val_accuracy: 0.8750\n",
            "Epoch 181/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.3287 - accuracy: 0.8589 - val_loss: 0.3791 - val_accuracy: 0.8562\n",
            "Epoch 182/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.3025 - accuracy: 0.8762 - val_loss: 0.4587 - val_accuracy: 0.8062\n",
            "Epoch 183/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.3155 - accuracy: 0.8699 - val_loss: 0.3594 - val_accuracy: 0.8687\n",
            "Epoch 184/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.3258 - accuracy: 0.8683 - val_loss: 0.4176 - val_accuracy: 0.8375\n",
            "Epoch 185/200\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.3094 - accuracy: 0.8715 - val_loss: 0.4069 - val_accuracy: 0.8313\n",
            "Epoch 186/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.3036 - accuracy: 0.8840 - val_loss: 0.4082 - val_accuracy: 0.8375\n",
            "Epoch 187/200\n",
            "20/20 [==============================] - 0s 6ms/step - loss: 0.2994 - accuracy: 0.8683 - val_loss: 0.4310 - val_accuracy: 0.8375\n",
            "Epoch 188/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.3337 - accuracy: 0.8699 - val_loss: 0.3595 - val_accuracy: 0.8625\n",
            "Epoch 189/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.3216 - accuracy: 0.8793 - val_loss: 0.3586 - val_accuracy: 0.8813\n",
            "Epoch 190/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.3148 - accuracy: 0.8699 - val_loss: 0.4325 - val_accuracy: 0.8062\n",
            "Epoch 191/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.3006 - accuracy: 0.8699 - val_loss: 0.4273 - val_accuracy: 0.8250\n",
            "Epoch 192/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.3102 - accuracy: 0.8824 - val_loss: 0.4113 - val_accuracy: 0.8250\n",
            "Epoch 193/200\n",
            "20/20 [==============================] - 0s 6ms/step - loss: 0.3212 - accuracy: 0.8840 - val_loss: 0.3598 - val_accuracy: 0.8687\n",
            "Epoch 194/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.3201 - accuracy: 0.8777 - val_loss: 0.3614 - val_accuracy: 0.8625\n",
            "Epoch 195/200\n",
            "20/20 [==============================] - 0s 6ms/step - loss: 0.3072 - accuracy: 0.8699 - val_loss: 0.4423 - val_accuracy: 0.8000\n",
            "Epoch 196/200\n",
            "20/20 [==============================] - 0s 6ms/step - loss: 0.3072 - accuracy: 0.8793 - val_loss: 0.3743 - val_accuracy: 0.8687\n",
            "Epoch 197/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.3103 - accuracy: 0.8699 - val_loss: 0.4385 - val_accuracy: 0.8062\n",
            "Epoch 198/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.3120 - accuracy: 0.8777 - val_loss: 0.3871 - val_accuracy: 0.8250\n",
            "Epoch 199/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.3039 - accuracy: 0.8730 - val_loss: 0.4050 - val_accuracy: 0.8313\n",
            "Epoch 200/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.3000 - accuracy: 0.8793 - val_loss: 0.3973 - val_accuracy: 0.8438\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 0.3884 - accuracy: 0.8500\n",
            "## evaluation loss and_metrics ##\n",
            "[0.3883517384529114, 0.8500000238418579]\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "0.8857142857142857\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "ChestPainType_TA"
      ],
      "metadata": {
        "id": "gDcA92nsq8rg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "heart = pd.read_csv(f_path)\n",
        "\n",
        "heart = pd.get_dummies(heart)\n",
        "\n",
        "x = heart.drop('HeartDisease', axis=1)\n",
        "y = pd.get_dummies(heart[\"HeartDisease\"])\n",
        "\n",
        "heart['ChestPainType_TA'] = 0\n",
        "\n",
        "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size = 0.13,shuffle=True, random_state = 42)\n",
        "\n",
        "print(\"X_train: \", x_train.shape)\n",
        "print(\"y_train: \", y_train.shape)\n",
        "\n",
        "print(\"X_test: \", x_test.shape)\n",
        "print(\"y_test: \", y_test.shape)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "ModelExceptChestPainType_TA = Sequential()\n",
        "\n",
        "\n",
        "ModelExceptChestPainType_TA.add(Dense(128, activation = \"relu\",input_dim=20))\n",
        "ModelExceptChestPainType_TA.add(Dropout(rate=0.2))\n",
        "ModelExceptChestPainType_TA.add(Dense(64, activation = \"relu\"))\n",
        "ModelExceptChestPainType_TA.add(Dropout(rate=0.2))\n",
        "ModelExceptChestPainType_TA.add(Dense(32, activation = \"relu\"))\n",
        "ModelExceptChestPainType_TA.add(Dropout(rate=0.1))\n",
        "ModelExceptChestPainType_TA.add(Dense(16, activation = \"relu\"))\n",
        "ModelExceptChestPainType_TA.add(Dense(8, activation = \"relu\"))\n",
        "ModelExceptChestPainType_TA.add(Dense(2, activation = \"sigmoid\"))\n",
        "\n",
        "ModelExceptChestPainType_TA.compile(optimizer = \"adam\", loss = \"categorical_crossentropy\", metrics = [\"accuracy\"])\n",
        "ModelExceptChestPainType_TA.summary()\n",
        "\n",
        "hin=ModelExceptChestPainType_TA.fit(x_train,y_train,epochs=200, validation_split=0.2)\n",
        "\n",
        "loss_and_metrics = ModelExceptChestPainType_TA.evaluate(x_test, y_test, batch_size=32)\n",
        "print('## evaluation loss and_metrics ##')\n",
        "print(loss_and_metrics)\n",
        "\n",
        "y_predChestPainType_TA = ModelExceptChestPainType_TA.predict(x_test)\n",
        "y_predChestPainType_TA\n",
        "\n",
        "y_pred_classChestPainType_TA = np.argmax(y_predChestPainType_TA, axis=1)\n",
        "y_pred_classChestPainType_TA\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "y_test  = y_test.to_numpy()\n",
        "y_test\n",
        "\n",
        "y_test = np.argmax(y_test,axis=1)\n",
        "y_test\n",
        "\n",
        "np.mean(y_test == y_pred_classChestPainType_TA)\n",
        "ChestPainType_TAscore=recall_score(y_test,y_pred_classChestPainType_TA)\n",
        "print(ChestPainType_TAscore)"
      ],
      "metadata": {
        "id": "0a6QJL9by9BA",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e48e5979-efd0-477b-a868-d09fd82f81e1"
      },
      "execution_count": 94,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "X_train:  (798, 20)\n",
            "y_train:  (798, 2)\n",
            "X_test:  (120, 20)\n",
            "y_test:  (120, 2)\n",
            "Model: \"sequential_16\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense_96 (Dense)            (None, 128)               2688      \n",
            "                                                                 \n",
            " dropout_48 (Dropout)        (None, 128)               0         \n",
            "                                                                 \n",
            " dense_97 (Dense)            (None, 64)                8256      \n",
            "                                                                 \n",
            " dropout_49 (Dropout)        (None, 64)                0         \n",
            "                                                                 \n",
            " dense_98 (Dense)            (None, 32)                2080      \n",
            "                                                                 \n",
            " dropout_50 (Dropout)        (None, 32)                0         \n",
            "                                                                 \n",
            " dense_99 (Dense)            (None, 16)                528       \n",
            "                                                                 \n",
            " dense_100 (Dense)           (None, 8)                 136       \n",
            "                                                                 \n",
            " dense_101 (Dense)           (None, 2)                 18        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 13,706\n",
            "Trainable params: 13,706\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/200\n",
            "20/20 [==============================] - 1s 14ms/step - loss: 1.5497 - accuracy: 0.5219 - val_loss: 0.6931 - val_accuracy: 0.5063\n",
            "Epoch 2/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.7559 - accuracy: 0.4561 - val_loss: 0.6931 - val_accuracy: 0.5063\n",
            "Epoch 3/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.7012 - accuracy: 0.5313 - val_loss: 0.6933 - val_accuracy: 0.4938\n",
            "Epoch 4/200\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.6950 - accuracy: 0.5549 - val_loss: 0.6936 - val_accuracy: 0.4938\n",
            "Epoch 5/200\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.6877 - accuracy: 0.5564 - val_loss: 0.6940 - val_accuracy: 0.4938\n",
            "Epoch 6/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.7009 - accuracy: 0.5564 - val_loss: 0.6945 - val_accuracy: 0.4938\n",
            "Epoch 7/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.6897 - accuracy: 0.5564 - val_loss: 0.6949 - val_accuracy: 0.4938\n",
            "Epoch 8/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.6887 - accuracy: 0.5627 - val_loss: 0.6951 - val_accuracy: 0.4938\n",
            "Epoch 9/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.6869 - accuracy: 0.5674 - val_loss: 0.6365 - val_accuracy: 0.4938\n",
            "Epoch 10/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.6830 - accuracy: 0.5658 - val_loss: 0.6954 - val_accuracy: 0.4938\n",
            "Epoch 11/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.6989 - accuracy: 0.5674 - val_loss: 0.6949 - val_accuracy: 0.4938\n",
            "Epoch 12/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.6568 - accuracy: 0.5643 - val_loss: 0.6363 - val_accuracy: 0.4938\n",
            "Epoch 13/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.7018 - accuracy: 0.5564 - val_loss: 0.6451 - val_accuracy: 0.4938\n",
            "Epoch 14/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.6565 - accuracy: 0.5674 - val_loss: 0.6392 - val_accuracy: 0.4938\n",
            "Epoch 15/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.6542 - accuracy: 0.5658 - val_loss: 0.6408 - val_accuracy: 0.4938\n",
            "Epoch 16/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.6544 - accuracy: 0.5705 - val_loss: 0.6360 - val_accuracy: 0.4938\n",
            "Epoch 17/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.6662 - accuracy: 0.5627 - val_loss: 0.6414 - val_accuracy: 0.4938\n",
            "Epoch 18/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.6836 - accuracy: 0.5502 - val_loss: 0.6491 - val_accuracy: 0.4938\n",
            "Epoch 19/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.6543 - accuracy: 0.5658 - val_loss: 0.6352 - val_accuracy: 0.4938\n",
            "Epoch 20/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.6652 - accuracy: 0.5517 - val_loss: 0.6364 - val_accuracy: 0.4938\n",
            "Epoch 21/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.6765 - accuracy: 0.5643 - val_loss: 0.6357 - val_accuracy: 0.4938\n",
            "Epoch 22/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.6633 - accuracy: 0.5611 - val_loss: 0.6401 - val_accuracy: 0.4938\n",
            "Epoch 23/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.6588 - accuracy: 0.5596 - val_loss: 0.6455 - val_accuracy: 0.4938\n",
            "Epoch 24/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.6466 - accuracy: 0.5611 - val_loss: 0.6440 - val_accuracy: 0.4938\n",
            "Epoch 25/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.6665 - accuracy: 0.5627 - val_loss: 0.6377 - val_accuracy: 0.4938\n",
            "Epoch 26/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.6472 - accuracy: 0.5705 - val_loss: 0.6431 - val_accuracy: 0.4938\n",
            "Epoch 27/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.6460 - accuracy: 0.5705 - val_loss: 0.6224 - val_accuracy: 0.4938\n",
            "Epoch 28/200\n",
            "20/20 [==============================] - 0s 6ms/step - loss: 0.6696 - accuracy: 0.5643 - val_loss: 0.6344 - val_accuracy: 0.4938\n",
            "Epoch 29/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.6514 - accuracy: 0.5564 - val_loss: 0.6318 - val_accuracy: 0.4938\n",
            "Epoch 30/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.6472 - accuracy: 0.5721 - val_loss: 0.6281 - val_accuracy: 0.4938\n",
            "Epoch 31/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.6578 - accuracy: 0.5611 - val_loss: 0.6268 - val_accuracy: 0.4938\n",
            "Epoch 32/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.6528 - accuracy: 0.5674 - val_loss: 0.6239 - val_accuracy: 0.4938\n",
            "Epoch 33/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.6402 - accuracy: 0.5737 - val_loss: 0.6264 - val_accuracy: 0.4938\n",
            "Epoch 34/200\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.6525 - accuracy: 0.5596 - val_loss: 0.6231 - val_accuracy: 0.4938\n",
            "Epoch 35/200\n",
            "20/20 [==============================] - 0s 6ms/step - loss: 0.6415 - accuracy: 0.5439 - val_loss: 0.6257 - val_accuracy: 0.4938\n",
            "Epoch 36/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.6308 - accuracy: 0.5768 - val_loss: 0.6240 - val_accuracy: 0.4938\n",
            "Epoch 37/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.6508 - accuracy: 0.5596 - val_loss: 0.6236 - val_accuracy: 0.4938\n",
            "Epoch 38/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.6575 - accuracy: 0.5752 - val_loss: 0.6265 - val_accuracy: 0.4938\n",
            "Epoch 39/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.6422 - accuracy: 0.5643 - val_loss: 0.6246 - val_accuracy: 0.4938\n",
            "Epoch 40/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.6527 - accuracy: 0.5549 - val_loss: 0.6240 - val_accuracy: 0.4938\n",
            "Epoch 41/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.6387 - accuracy: 0.5658 - val_loss: 0.6232 - val_accuracy: 0.4938\n",
            "Epoch 42/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.6465 - accuracy: 0.5627 - val_loss: 0.6229 - val_accuracy: 0.4938\n",
            "Epoch 43/200\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.6471 - accuracy: 0.5486 - val_loss: 0.6215 - val_accuracy: 0.4938\n",
            "Epoch 44/200\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.6284 - accuracy: 0.5627 - val_loss: 0.6205 - val_accuracy: 0.4938\n",
            "Epoch 45/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.6321 - accuracy: 0.5643 - val_loss: 0.6216 - val_accuracy: 0.4938\n",
            "Epoch 46/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.6377 - accuracy: 0.5517 - val_loss: 0.6201 - val_accuracy: 0.4938\n",
            "Epoch 47/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.6429 - accuracy: 0.5705 - val_loss: 0.6167 - val_accuracy: 0.4938\n",
            "Epoch 48/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.6521 - accuracy: 0.5580 - val_loss: 0.6140 - val_accuracy: 0.4938\n",
            "Epoch 49/200\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.6552 - accuracy: 0.5690 - val_loss: 0.6254 - val_accuracy: 0.4938\n",
            "Epoch 50/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.6389 - accuracy: 0.5611 - val_loss: 0.6199 - val_accuracy: 0.4938\n",
            "Epoch 51/200\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.6469 - accuracy: 0.5580 - val_loss: 0.6223 - val_accuracy: 0.4938\n",
            "Epoch 52/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.6405 - accuracy: 0.5737 - val_loss: 0.6176 - val_accuracy: 0.4938\n",
            "Epoch 53/200\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.6387 - accuracy: 0.5627 - val_loss: 0.6191 - val_accuracy: 0.4938\n",
            "Epoch 54/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.6421 - accuracy: 0.5752 - val_loss: 0.6184 - val_accuracy: 0.4938\n",
            "Epoch 55/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.6436 - accuracy: 0.5658 - val_loss: 0.6199 - val_accuracy: 0.4938\n",
            "Epoch 56/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.6407 - accuracy: 0.5674 - val_loss: 0.6177 - val_accuracy: 0.4938\n",
            "Epoch 57/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.6273 - accuracy: 0.5596 - val_loss: 0.6185 - val_accuracy: 0.4938\n",
            "Epoch 58/200\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.6396 - accuracy: 0.5690 - val_loss: 0.6185 - val_accuracy: 0.4938\n",
            "Epoch 59/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.6318 - accuracy: 0.5721 - val_loss: 0.6192 - val_accuracy: 0.4938\n",
            "Epoch 60/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.6376 - accuracy: 0.5580 - val_loss: 0.6168 - val_accuracy: 0.6750\n",
            "Epoch 61/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.6357 - accuracy: 0.5517 - val_loss: 0.6160 - val_accuracy: 0.4938\n",
            "Epoch 62/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.6363 - accuracy: 0.5690 - val_loss: 0.6169 - val_accuracy: 0.6750\n",
            "Epoch 63/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.6361 - accuracy: 0.5737 - val_loss: 0.6175 - val_accuracy: 0.6750\n",
            "Epoch 64/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.6399 - accuracy: 0.5815 - val_loss: 0.6177 - val_accuracy: 0.6750\n",
            "Epoch 65/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.6351 - accuracy: 0.5721 - val_loss: 0.6168 - val_accuracy: 0.6750\n",
            "Epoch 66/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.6347 - accuracy: 0.5721 - val_loss: 0.6158 - val_accuracy: 0.6750\n",
            "Epoch 67/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.6327 - accuracy: 0.5737 - val_loss: 0.6145 - val_accuracy: 0.6750\n",
            "Epoch 68/200\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.6336 - accuracy: 0.5737 - val_loss: 0.6145 - val_accuracy: 0.6750\n",
            "Epoch 69/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.6452 - accuracy: 0.5737 - val_loss: 0.6146 - val_accuracy: 0.6750\n",
            "Epoch 70/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.6368 - accuracy: 0.5752 - val_loss: 0.6153 - val_accuracy: 0.6750\n",
            "Epoch 71/200\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.6353 - accuracy: 0.5690 - val_loss: 0.6160 - val_accuracy: 0.6750\n",
            "Epoch 72/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.6387 - accuracy: 0.5752 - val_loss: 0.6140 - val_accuracy: 0.6750\n",
            "Epoch 73/200\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.6443 - accuracy: 0.5658 - val_loss: 0.6165 - val_accuracy: 0.6750\n",
            "Epoch 74/200\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.6363 - accuracy: 0.5737 - val_loss: 0.6154 - val_accuracy: 0.6750\n",
            "Epoch 75/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.6308 - accuracy: 0.5768 - val_loss: 0.6135 - val_accuracy: 0.6750\n",
            "Epoch 76/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.6331 - accuracy: 0.5768 - val_loss: 0.6133 - val_accuracy: 0.6750\n",
            "Epoch 77/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.6433 - accuracy: 0.5705 - val_loss: 0.6176 - val_accuracy: 0.6750\n",
            "Epoch 78/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.6309 - accuracy: 0.5721 - val_loss: 0.6162 - val_accuracy: 0.6750\n",
            "Epoch 79/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.6265 - accuracy: 0.5580 - val_loss: 0.6098 - val_accuracy: 0.6250\n",
            "Epoch 80/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.6306 - accuracy: 0.6003 - val_loss: 0.6112 - val_accuracy: 0.6125\n",
            "Epoch 81/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.6257 - accuracy: 0.6614 - val_loss: 0.5713 - val_accuracy: 0.7500\n",
            "Epoch 82/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.6257 - accuracy: 0.6677 - val_loss: 0.6022 - val_accuracy: 0.6875\n",
            "Epoch 83/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.6150 - accuracy: 0.6567 - val_loss: 0.6109 - val_accuracy: 0.5875\n",
            "Epoch 84/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.6265 - accuracy: 0.6505 - val_loss: 0.6000 - val_accuracy: 0.7000\n",
            "Epoch 85/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.6101 - accuracy: 0.6630 - val_loss: 0.5877 - val_accuracy: 0.7063\n",
            "Epoch 86/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.6092 - accuracy: 0.6818 - val_loss: 0.6006 - val_accuracy: 0.7125\n",
            "Epoch 87/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.6086 - accuracy: 0.6944 - val_loss: 0.5656 - val_accuracy: 0.7188\n",
            "Epoch 88/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.5973 - accuracy: 0.6646 - val_loss: 0.5962 - val_accuracy: 0.6062\n",
            "Epoch 89/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.5994 - accuracy: 0.6928 - val_loss: 0.5959 - val_accuracy: 0.6687\n",
            "Epoch 90/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.5799 - accuracy: 0.7100 - val_loss: 0.5341 - val_accuracy: 0.7500\n",
            "Epoch 91/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.5766 - accuracy: 0.7210 - val_loss: 0.5447 - val_accuracy: 0.7375\n",
            "Epoch 92/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.5716 - accuracy: 0.7163 - val_loss: 0.5566 - val_accuracy: 0.7500\n",
            "Epoch 93/200\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.5596 - accuracy: 0.7398 - val_loss: 0.5246 - val_accuracy: 0.7625\n",
            "Epoch 94/200\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.5582 - accuracy: 0.7304 - val_loss: 0.5240 - val_accuracy: 0.7625\n",
            "Epoch 95/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.5599 - accuracy: 0.7288 - val_loss: 0.5968 - val_accuracy: 0.5813\n",
            "Epoch 96/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.5563 - accuracy: 0.7382 - val_loss: 0.5139 - val_accuracy: 0.7688\n",
            "Epoch 97/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.5372 - accuracy: 0.7445 - val_loss: 0.5153 - val_accuracy: 0.7688\n",
            "Epoch 98/200\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.5178 - accuracy: 0.7524 - val_loss: 0.4814 - val_accuracy: 0.7937\n",
            "Epoch 99/200\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.5283 - accuracy: 0.7304 - val_loss: 0.4640 - val_accuracy: 0.8062\n",
            "Epoch 100/200\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.5208 - accuracy: 0.7398 - val_loss: 0.4706 - val_accuracy: 0.8188\n",
            "Epoch 101/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.4969 - accuracy: 0.7774 - val_loss: 0.4803 - val_accuracy: 0.8000\n",
            "Epoch 102/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.4902 - accuracy: 0.7790 - val_loss: 0.4762 - val_accuracy: 0.8000\n",
            "Epoch 103/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.4684 - accuracy: 0.7947 - val_loss: 0.4494 - val_accuracy: 0.8188\n",
            "Epoch 104/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.4922 - accuracy: 0.7774 - val_loss: 0.5133 - val_accuracy: 0.7500\n",
            "Epoch 105/200\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.4784 - accuracy: 0.7774 - val_loss: 0.4667 - val_accuracy: 0.7875\n",
            "Epoch 106/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.4714 - accuracy: 0.8056 - val_loss: 0.4175 - val_accuracy: 0.8438\n",
            "Epoch 107/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.4781 - accuracy: 0.7821 - val_loss: 0.4952 - val_accuracy: 0.7688\n",
            "Epoch 108/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.4473 - accuracy: 0.7994 - val_loss: 0.4421 - val_accuracy: 0.8250\n",
            "Epoch 109/200\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.4427 - accuracy: 0.8025 - val_loss: 0.4068 - val_accuracy: 0.8438\n",
            "Epoch 110/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.4308 - accuracy: 0.8103 - val_loss: 0.3997 - val_accuracy: 0.8438\n",
            "Epoch 111/200\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.4078 - accuracy: 0.8213 - val_loss: 0.3919 - val_accuracy: 0.8500\n",
            "Epoch 112/200\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.4184 - accuracy: 0.8150 - val_loss: 0.4140 - val_accuracy: 0.8375\n",
            "Epoch 113/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.4313 - accuracy: 0.7900 - val_loss: 0.3888 - val_accuracy: 0.8562\n",
            "Epoch 114/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.4141 - accuracy: 0.8213 - val_loss: 0.3862 - val_accuracy: 0.8500\n",
            "Epoch 115/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.4084 - accuracy: 0.8229 - val_loss: 0.3764 - val_accuracy: 0.8500\n",
            "Epoch 116/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.4006 - accuracy: 0.8386 - val_loss: 0.3784 - val_accuracy: 0.8562\n",
            "Epoch 117/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.3933 - accuracy: 0.8354 - val_loss: 0.3758 - val_accuracy: 0.8562\n",
            "Epoch 118/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.4358 - accuracy: 0.8072 - val_loss: 0.3942 - val_accuracy: 0.8625\n",
            "Epoch 119/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.3972 - accuracy: 0.8197 - val_loss: 0.3978 - val_accuracy: 0.8375\n",
            "Epoch 120/200\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.3797 - accuracy: 0.8480 - val_loss: 0.4670 - val_accuracy: 0.8125\n",
            "Epoch 121/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.3851 - accuracy: 0.8386 - val_loss: 0.4312 - val_accuracy: 0.8375\n",
            "Epoch 122/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.4032 - accuracy: 0.8150 - val_loss: 0.4624 - val_accuracy: 0.8125\n",
            "Epoch 123/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.3868 - accuracy: 0.8433 - val_loss: 0.3787 - val_accuracy: 0.8500\n",
            "Epoch 124/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.3986 - accuracy: 0.8417 - val_loss: 0.3637 - val_accuracy: 0.8562\n",
            "Epoch 125/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.3621 - accuracy: 0.8464 - val_loss: 0.3681 - val_accuracy: 0.8562\n",
            "Epoch 126/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.3808 - accuracy: 0.8511 - val_loss: 0.3575 - val_accuracy: 0.8562\n",
            "Epoch 127/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.3760 - accuracy: 0.8448 - val_loss: 0.3433 - val_accuracy: 0.8562\n",
            "Epoch 128/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.3524 - accuracy: 0.8589 - val_loss: 0.3674 - val_accuracy: 0.8562\n",
            "Epoch 129/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.3425 - accuracy: 0.8605 - val_loss: 0.3520 - val_accuracy: 0.8687\n",
            "Epoch 130/200\n",
            "20/20 [==============================] - 0s 6ms/step - loss: 0.3803 - accuracy: 0.8495 - val_loss: 0.3701 - val_accuracy: 0.8625\n",
            "Epoch 131/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.3401 - accuracy: 0.8683 - val_loss: 0.3478 - val_accuracy: 0.8750\n",
            "Epoch 132/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.3222 - accuracy: 0.8636 - val_loss: 0.3624 - val_accuracy: 0.8687\n",
            "Epoch 133/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.3436 - accuracy: 0.8542 - val_loss: 0.3570 - val_accuracy: 0.8625\n",
            "Epoch 134/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.3665 - accuracy: 0.8464 - val_loss: 0.3538 - val_accuracy: 0.8625\n",
            "Epoch 135/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.3456 - accuracy: 0.8574 - val_loss: 0.3532 - val_accuracy: 0.8625\n",
            "Epoch 136/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.3475 - accuracy: 0.8495 - val_loss: 0.3953 - val_accuracy: 0.8438\n",
            "Epoch 137/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.3437 - accuracy: 0.8511 - val_loss: 0.4143 - val_accuracy: 0.8250\n",
            "Epoch 138/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.3337 - accuracy: 0.8605 - val_loss: 0.3843 - val_accuracy: 0.8438\n",
            "Epoch 139/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.3344 - accuracy: 0.8668 - val_loss: 0.3841 - val_accuracy: 0.8500\n",
            "Epoch 140/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.3420 - accuracy: 0.8636 - val_loss: 0.4421 - val_accuracy: 0.8125\n",
            "Epoch 141/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.3434 - accuracy: 0.8636 - val_loss: 0.3921 - val_accuracy: 0.8250\n",
            "Epoch 142/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.3511 - accuracy: 0.8558 - val_loss: 0.3580 - val_accuracy: 0.8562\n",
            "Epoch 143/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.3336 - accuracy: 0.8605 - val_loss: 0.3529 - val_accuracy: 0.8625\n",
            "Epoch 144/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.3363 - accuracy: 0.8652 - val_loss: 0.3758 - val_accuracy: 0.8438\n",
            "Epoch 145/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.3266 - accuracy: 0.8746 - val_loss: 0.3531 - val_accuracy: 0.8625\n",
            "Epoch 146/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.3519 - accuracy: 0.8558 - val_loss: 0.3682 - val_accuracy: 0.8500\n",
            "Epoch 147/200\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.3237 - accuracy: 0.8621 - val_loss: 0.3647 - val_accuracy: 0.8500\n",
            "Epoch 148/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.3350 - accuracy: 0.8683 - val_loss: 0.3851 - val_accuracy: 0.8500\n",
            "Epoch 149/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.3227 - accuracy: 0.8605 - val_loss: 0.4171 - val_accuracy: 0.8125\n",
            "Epoch 150/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.3151 - accuracy: 0.8746 - val_loss: 0.3642 - val_accuracy: 0.8625\n",
            "Epoch 151/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.3209 - accuracy: 0.8652 - val_loss: 0.3619 - val_accuracy: 0.8687\n",
            "Epoch 152/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.3229 - accuracy: 0.8652 - val_loss: 0.3806 - val_accuracy: 0.8500\n",
            "Epoch 153/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.3056 - accuracy: 0.8809 - val_loss: 0.3958 - val_accuracy: 0.8500\n",
            "Epoch 154/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.3220 - accuracy: 0.8699 - val_loss: 0.3646 - val_accuracy: 0.8687\n",
            "Epoch 155/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.3230 - accuracy: 0.8589 - val_loss: 0.3554 - val_accuracy: 0.8750\n",
            "Epoch 156/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.3307 - accuracy: 0.8589 - val_loss: 0.3583 - val_accuracy: 0.8687\n",
            "Epoch 157/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.3268 - accuracy: 0.8777 - val_loss: 0.3674 - val_accuracy: 0.8687\n",
            "Epoch 158/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.3159 - accuracy: 0.8636 - val_loss: 0.4149 - val_accuracy: 0.8375\n",
            "Epoch 159/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.3284 - accuracy: 0.8621 - val_loss: 0.3521 - val_accuracy: 0.8750\n",
            "Epoch 160/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.3190 - accuracy: 0.8715 - val_loss: 0.3815 - val_accuracy: 0.8562\n",
            "Epoch 161/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.3192 - accuracy: 0.8652 - val_loss: 0.3886 - val_accuracy: 0.8562\n",
            "Epoch 162/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.3211 - accuracy: 0.8762 - val_loss: 0.4012 - val_accuracy: 0.8375\n",
            "Epoch 163/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.3108 - accuracy: 0.8715 - val_loss: 0.3956 - val_accuracy: 0.8562\n",
            "Epoch 164/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.3106 - accuracy: 0.8668 - val_loss: 0.3720 - val_accuracy: 0.8625\n",
            "Epoch 165/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.3173 - accuracy: 0.8730 - val_loss: 0.4217 - val_accuracy: 0.8188\n",
            "Epoch 166/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.3140 - accuracy: 0.8683 - val_loss: 0.3985 - val_accuracy: 0.8250\n",
            "Epoch 167/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.3004 - accuracy: 0.8871 - val_loss: 0.3641 - val_accuracy: 0.8813\n",
            "Epoch 168/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.2995 - accuracy: 0.8762 - val_loss: 0.4088 - val_accuracy: 0.8500\n",
            "Epoch 169/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.3072 - accuracy: 0.8762 - val_loss: 0.3767 - val_accuracy: 0.8625\n",
            "Epoch 170/200\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.2959 - accuracy: 0.8777 - val_loss: 0.3707 - val_accuracy: 0.8687\n",
            "Epoch 171/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.3225 - accuracy: 0.8699 - val_loss: 0.3516 - val_accuracy: 0.8813\n",
            "Epoch 172/200\n",
            "20/20 [==============================] - 0s 6ms/step - loss: 0.2996 - accuracy: 0.8762 - val_loss: 0.3584 - val_accuracy: 0.8562\n",
            "Epoch 173/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.3145 - accuracy: 0.8762 - val_loss: 0.3870 - val_accuracy: 0.8562\n",
            "Epoch 174/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.3153 - accuracy: 0.8683 - val_loss: 0.3953 - val_accuracy: 0.8313\n",
            "Epoch 175/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.3008 - accuracy: 0.8762 - val_loss: 0.3619 - val_accuracy: 0.8750\n",
            "Epoch 176/200\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.3180 - accuracy: 0.8636 - val_loss: 0.3952 - val_accuracy: 0.8438\n",
            "Epoch 177/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.3023 - accuracy: 0.8793 - val_loss: 0.3850 - val_accuracy: 0.8562\n",
            "Epoch 178/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.2948 - accuracy: 0.8777 - val_loss: 0.3739 - val_accuracy: 0.8687\n",
            "Epoch 179/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.3123 - accuracy: 0.8777 - val_loss: 0.3680 - val_accuracy: 0.8687\n",
            "Epoch 180/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.3072 - accuracy: 0.8652 - val_loss: 0.3722 - val_accuracy: 0.8750\n",
            "Epoch 181/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.3192 - accuracy: 0.8652 - val_loss: 0.4034 - val_accuracy: 0.8500\n",
            "Epoch 182/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.3238 - accuracy: 0.8746 - val_loss: 0.4256 - val_accuracy: 0.8125\n",
            "Epoch 183/200\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.3168 - accuracy: 0.8793 - val_loss: 0.3572 - val_accuracy: 0.8687\n",
            "Epoch 184/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.3026 - accuracy: 0.8793 - val_loss: 0.3565 - val_accuracy: 0.8687\n",
            "Epoch 185/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.2973 - accuracy: 0.8793 - val_loss: 0.3533 - val_accuracy: 0.8687\n",
            "Epoch 186/200\n",
            "20/20 [==============================] - 0s 6ms/step - loss: 0.3185 - accuracy: 0.8636 - val_loss: 0.3621 - val_accuracy: 0.8562\n",
            "Epoch 187/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.3035 - accuracy: 0.8793 - val_loss: 0.4133 - val_accuracy: 0.8438\n",
            "Epoch 188/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.3170 - accuracy: 0.8730 - val_loss: 0.4449 - val_accuracy: 0.8375\n",
            "Epoch 189/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.3016 - accuracy: 0.8746 - val_loss: 0.3745 - val_accuracy: 0.8687\n",
            "Epoch 190/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.3073 - accuracy: 0.8777 - val_loss: 0.3608 - val_accuracy: 0.8750\n",
            "Epoch 191/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.2970 - accuracy: 0.8840 - val_loss: 0.4146 - val_accuracy: 0.8313\n",
            "Epoch 192/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.3012 - accuracy: 0.8871 - val_loss: 0.3713 - val_accuracy: 0.8438\n",
            "Epoch 193/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.2801 - accuracy: 0.8918 - val_loss: 0.4091 - val_accuracy: 0.8375\n",
            "Epoch 194/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.3195 - accuracy: 0.8542 - val_loss: 0.3616 - val_accuracy: 0.8625\n",
            "Epoch 195/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.2938 - accuracy: 0.8793 - val_loss: 0.3977 - val_accuracy: 0.8687\n",
            "Epoch 196/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.3090 - accuracy: 0.8730 - val_loss: 0.3627 - val_accuracy: 0.8625\n",
            "Epoch 197/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.2978 - accuracy: 0.8715 - val_loss: 0.4181 - val_accuracy: 0.8250\n",
            "Epoch 198/200\n",
            "20/20 [==============================] - 0s 7ms/step - loss: 0.2995 - accuracy: 0.8824 - val_loss: 0.3701 - val_accuracy: 0.8750\n",
            "Epoch 199/200\n",
            "20/20 [==============================] - 0s 6ms/step - loss: 0.2825 - accuracy: 0.8840 - val_loss: 0.3820 - val_accuracy: 0.8687\n",
            "Epoch 200/200\n",
            "20/20 [==============================] - 0s 10ms/step - loss: 0.2850 - accuracy: 0.8699 - val_loss: 0.3794 - val_accuracy: 0.8687\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 0.4434 - accuracy: 0.8250\n",
            "## evaluation loss and_metrics ##\n",
            "[0.44339755177497864, 0.824999988079071]\n",
            "4/4 [==============================] - 0s 5ms/step\n",
            "0.8428571428571429\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "RestingECG_LVH"
      ],
      "metadata": {
        "id": "YNvoZUAYq-lv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "heart = pd.read_csv(f_path)\n",
        "\n",
        "heart = pd.get_dummies(heart)\n",
        "\n",
        "x = heart.drop('HeartDisease', axis=1)\n",
        "y = pd.get_dummies(heart[\"HeartDisease\"])\n",
        "\n",
        "heart['RestingECG_LVH'] = 0\n",
        "\n",
        "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size = 0.13,shuffle=True, random_state = 42)\n",
        "\n",
        "print(\"X_train: \", x_train.shape)\n",
        "print(\"y_train: \", y_train.shape)\n",
        "\n",
        "print(\"X_test: \", x_test.shape)\n",
        "print(\"y_test: \", y_test.shape)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "ModelExceptRestingECG_LVH = Sequential()\n",
        "\n",
        "\n",
        "ModelExceptRestingECG_LVH.add(Dense(128, activation = \"relu\",input_dim=20))\n",
        "ModelExceptRestingECG_LVH.add(Dropout(rate=0.2))\n",
        "ModelExceptRestingECG_LVH.add(Dense(64, activation = \"relu\"))\n",
        "ModelExceptRestingECG_LVH.add(Dropout(rate=0.2))\n",
        "ModelExceptRestingECG_LVH.add(Dense(32, activation = \"relu\"))\n",
        "ModelExceptRestingECG_LVH.add(Dropout(rate=0.1))\n",
        "ModelExceptRestingECG_LVH.add(Dense(16, activation = \"relu\"))\n",
        "ModelExceptRestingECG_LVH.add(Dense(8, activation = \"relu\"))\n",
        "ModelExceptRestingECG_LVH.add(Dense(2, activation = \"sigmoid\"))\n",
        "\n",
        "ModelExceptRestingECG_LVH.compile(optimizer = \"adam\", loss = \"categorical_crossentropy\", metrics = [\"accuracy\"])\n",
        "ModelExceptRestingECG_LVH.summary()\n",
        "\n",
        "hin=ModelExceptRestingECG_LVH.fit(x_train,y_train,epochs=200, validation_split=0.2)\n",
        "\n",
        "loss_and_metrics = ModelExceptRestingECG_LVH.evaluate(x_test, y_test, batch_size=32)\n",
        "print('## evaluation loss and_metrics ##')\n",
        "print(loss_and_metrics)\n",
        "\n",
        "y_predRestingECG_LVH = ModelExceptRestingECG_LVH.predict(x_test)\n",
        "y_predRestingECG_LVH\n",
        "\n",
        "y_pred_classRestingECG_LVH = np.argmax(y_predRestingECG_LVH, axis=1)\n",
        "y_pred_classRestingECG_LVH\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "y_test  = y_test.to_numpy()\n",
        "y_test\n",
        "\n",
        "y_test = np.argmax(y_test,axis=1)\n",
        "y_test\n",
        "\n",
        "np.mean(y_test == y_pred_classRestingECG_LVH)\n",
        "RestingECG_LVHscore=recall_score(y_test,y_pred_classRestingECG_LVH)\n",
        "print(RestingECG_LVHscore)"
      ],
      "metadata": {
        "id": "cEQh51Bcy9yc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "557cfafe-8935-497e-f1c9-001bfa4c2db6"
      },
      "execution_count": 95,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "X_train:  (798, 20)\n",
            "y_train:  (798, 2)\n",
            "X_test:  (120, 20)\n",
            "y_test:  (120, 2)\n",
            "Model: \"sequential_17\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense_102 (Dense)           (None, 128)               2688      \n",
            "                                                                 \n",
            " dropout_51 (Dropout)        (None, 128)               0         \n",
            "                                                                 \n",
            " dense_103 (Dense)           (None, 64)                8256      \n",
            "                                                                 \n",
            " dropout_52 (Dropout)        (None, 64)                0         \n",
            "                                                                 \n",
            " dense_104 (Dense)           (None, 32)                2080      \n",
            "                                                                 \n",
            " dropout_53 (Dropout)        (None, 32)                0         \n",
            "                                                                 \n",
            " dense_105 (Dense)           (None, 16)                528       \n",
            "                                                                 \n",
            " dense_106 (Dense)           (None, 8)                 136       \n",
            "                                                                 \n",
            " dense_107 (Dense)           (None, 2)                 18        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 13,706\n",
            "Trainable params: 13,706\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/200\n",
            "20/20 [==============================] - 1s 12ms/step - loss: 2.1710 - accuracy: 0.5690 - val_loss: 0.7665 - val_accuracy: 0.4938\n",
            "Epoch 2/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 1.1158 - accuracy: 0.5408 - val_loss: 0.6214 - val_accuracy: 0.7063\n",
            "Epoch 3/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.7886 - accuracy: 0.5799 - val_loss: 0.5910 - val_accuracy: 0.7563\n",
            "Epoch 4/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.7024 - accuracy: 0.6254 - val_loss: 0.5930 - val_accuracy: 0.7563\n",
            "Epoch 5/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.6940 - accuracy: 0.6129 - val_loss: 0.5971 - val_accuracy: 0.7437\n",
            "Epoch 6/200\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.6676 - accuracy: 0.6144 - val_loss: 0.5957 - val_accuracy: 0.6938\n",
            "Epoch 7/200\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.6731 - accuracy: 0.6019 - val_loss: 0.6035 - val_accuracy: 0.6625\n",
            "Epoch 8/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.6479 - accuracy: 0.6176 - val_loss: 0.5793 - val_accuracy: 0.7312\n",
            "Epoch 9/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.6275 - accuracy: 0.6395 - val_loss: 0.5906 - val_accuracy: 0.7063\n",
            "Epoch 10/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.6532 - accuracy: 0.6332 - val_loss: 0.5905 - val_accuracy: 0.7063\n",
            "Epoch 11/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.6104 - accuracy: 0.6897 - val_loss: 0.6117 - val_accuracy: 0.6625\n",
            "Epoch 12/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.6401 - accuracy: 0.6473 - val_loss: 0.5782 - val_accuracy: 0.7500\n",
            "Epoch 13/200\n",
            "20/20 [==============================] - 0s 6ms/step - loss: 0.6267 - accuracy: 0.6787 - val_loss: 0.5961 - val_accuracy: 0.7125\n",
            "Epoch 14/200\n",
            "20/20 [==============================] - 0s 7ms/step - loss: 0.6374 - accuracy: 0.6254 - val_loss: 0.5818 - val_accuracy: 0.7125\n",
            "Epoch 15/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.6119 - accuracy: 0.6661 - val_loss: 0.5961 - val_accuracy: 0.6500\n",
            "Epoch 16/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.6107 - accuracy: 0.6818 - val_loss: 0.5571 - val_accuracy: 0.7250\n",
            "Epoch 17/200\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.6051 - accuracy: 0.6991 - val_loss: 0.5726 - val_accuracy: 0.7250\n",
            "Epoch 18/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.5883 - accuracy: 0.6959 - val_loss: 0.5691 - val_accuracy: 0.7000\n",
            "Epoch 19/200\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.5836 - accuracy: 0.6928 - val_loss: 0.5503 - val_accuracy: 0.7312\n",
            "Epoch 20/200\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.5815 - accuracy: 0.6912 - val_loss: 0.5635 - val_accuracy: 0.6938\n",
            "Epoch 21/200\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.5993 - accuracy: 0.6975 - val_loss: 0.5385 - val_accuracy: 0.7437\n",
            "Epoch 22/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.5875 - accuracy: 0.7194 - val_loss: 0.5505 - val_accuracy: 0.7437\n",
            "Epoch 23/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.5727 - accuracy: 0.7022 - val_loss: 0.5623 - val_accuracy: 0.7063\n",
            "Epoch 24/200\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.5548 - accuracy: 0.7335 - val_loss: 0.5320 - val_accuracy: 0.7625\n",
            "Epoch 25/200\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.6094 - accuracy: 0.6959 - val_loss: 0.5358 - val_accuracy: 0.7625\n",
            "Epoch 26/200\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.5692 - accuracy: 0.7147 - val_loss: 0.5295 - val_accuracy: 0.7563\n",
            "Epoch 27/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.5549 - accuracy: 0.7382 - val_loss: 0.5225 - val_accuracy: 0.7688\n",
            "Epoch 28/200\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.5551 - accuracy: 0.7476 - val_loss: 0.5130 - val_accuracy: 0.7812\n",
            "Epoch 29/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.5562 - accuracy: 0.7210 - val_loss: 0.5599 - val_accuracy: 0.7000\n",
            "Epoch 30/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.5378 - accuracy: 0.7414 - val_loss: 0.5128 - val_accuracy: 0.7812\n",
            "Epoch 31/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.5180 - accuracy: 0.7524 - val_loss: 0.5230 - val_accuracy: 0.7688\n",
            "Epoch 32/200\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.5420 - accuracy: 0.7367 - val_loss: 0.5140 - val_accuracy: 0.7750\n",
            "Epoch 33/200\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.5296 - accuracy: 0.7571 - val_loss: 0.5129 - val_accuracy: 0.7688\n",
            "Epoch 34/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.5367 - accuracy: 0.7320 - val_loss: 0.5205 - val_accuracy: 0.7625\n",
            "Epoch 35/200\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.5459 - accuracy: 0.7194 - val_loss: 0.5488 - val_accuracy: 0.7063\n",
            "Epoch 36/200\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.5219 - accuracy: 0.7508 - val_loss: 0.5326 - val_accuracy: 0.7375\n",
            "Epoch 37/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.5382 - accuracy: 0.7665 - val_loss: 0.5375 - val_accuracy: 0.7312\n",
            "Epoch 38/200\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.5182 - accuracy: 0.7586 - val_loss: 0.4790 - val_accuracy: 0.7937\n",
            "Epoch 39/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.5501 - accuracy: 0.7524 - val_loss: 0.5109 - val_accuracy: 0.7563\n",
            "Epoch 40/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.5177 - accuracy: 0.7618 - val_loss: 0.5033 - val_accuracy: 0.7625\n",
            "Epoch 41/200\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.5166 - accuracy: 0.7571 - val_loss: 0.5060 - val_accuracy: 0.7688\n",
            "Epoch 42/200\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.5062 - accuracy: 0.7774 - val_loss: 0.4869 - val_accuracy: 0.7937\n",
            "Epoch 43/200\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.5098 - accuracy: 0.7712 - val_loss: 0.4775 - val_accuracy: 0.7937\n",
            "Epoch 44/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.4906 - accuracy: 0.7743 - val_loss: 0.5183 - val_accuracy: 0.7500\n",
            "Epoch 45/200\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.4887 - accuracy: 0.7931 - val_loss: 0.4782 - val_accuracy: 0.8000\n",
            "Epoch 46/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.4767 - accuracy: 0.7837 - val_loss: 0.4767 - val_accuracy: 0.7875\n",
            "Epoch 47/200\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.4911 - accuracy: 0.7743 - val_loss: 0.5046 - val_accuracy: 0.7500\n",
            "Epoch 48/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.4898 - accuracy: 0.7806 - val_loss: 0.4596 - val_accuracy: 0.8062\n",
            "Epoch 49/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.4663 - accuracy: 0.7947 - val_loss: 0.4681 - val_accuracy: 0.8000\n",
            "Epoch 50/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.4727 - accuracy: 0.8009 - val_loss: 0.4624 - val_accuracy: 0.8000\n",
            "Epoch 51/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.4874 - accuracy: 0.7806 - val_loss: 0.4860 - val_accuracy: 0.7688\n",
            "Epoch 52/200\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.4679 - accuracy: 0.7994 - val_loss: 0.4776 - val_accuracy: 0.7750\n",
            "Epoch 53/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.4733 - accuracy: 0.7947 - val_loss: 0.4327 - val_accuracy: 0.8438\n",
            "Epoch 54/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.4474 - accuracy: 0.8088 - val_loss: 0.4418 - val_accuracy: 0.8313\n",
            "Epoch 55/200\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.4738 - accuracy: 0.8041 - val_loss: 0.4403 - val_accuracy: 0.8313\n",
            "Epoch 56/200\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.4609 - accuracy: 0.7931 - val_loss: 0.4646 - val_accuracy: 0.7812\n",
            "Epoch 57/200\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.4637 - accuracy: 0.8072 - val_loss: 0.4696 - val_accuracy: 0.7750\n",
            "Epoch 58/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.4341 - accuracy: 0.8197 - val_loss: 0.4442 - val_accuracy: 0.8125\n",
            "Epoch 59/200\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.4269 - accuracy: 0.8182 - val_loss: 0.4332 - val_accuracy: 0.8313\n",
            "Epoch 60/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.4062 - accuracy: 0.8354 - val_loss: 0.4366 - val_accuracy: 0.8188\n",
            "Epoch 61/200\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.4338 - accuracy: 0.8182 - val_loss: 0.4328 - val_accuracy: 0.8188\n",
            "Epoch 62/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.4316 - accuracy: 0.8197 - val_loss: 0.4915 - val_accuracy: 0.7937\n",
            "Epoch 63/200\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.4028 - accuracy: 0.8464 - val_loss: 0.3950 - val_accuracy: 0.8438\n",
            "Epoch 64/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.4506 - accuracy: 0.8229 - val_loss: 0.4379 - val_accuracy: 0.8313\n",
            "Epoch 65/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.4274 - accuracy: 0.8182 - val_loss: 0.4580 - val_accuracy: 0.8375\n",
            "Epoch 66/200\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.4068 - accuracy: 0.8229 - val_loss: 0.4037 - val_accuracy: 0.8500\n",
            "Epoch 67/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.3979 - accuracy: 0.8354 - val_loss: 0.4809 - val_accuracy: 0.8062\n",
            "Epoch 68/200\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.4152 - accuracy: 0.8213 - val_loss: 0.4499 - val_accuracy: 0.8188\n",
            "Epoch 69/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.3951 - accuracy: 0.8401 - val_loss: 0.4080 - val_accuracy: 0.8438\n",
            "Epoch 70/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.3976 - accuracy: 0.8401 - val_loss: 0.4092 - val_accuracy: 0.8438\n",
            "Epoch 71/200\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.4004 - accuracy: 0.8354 - val_loss: 0.4380 - val_accuracy: 0.8188\n",
            "Epoch 72/200\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.3866 - accuracy: 0.8417 - val_loss: 0.4143 - val_accuracy: 0.8500\n",
            "Epoch 73/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.4053 - accuracy: 0.8197 - val_loss: 0.4229 - val_accuracy: 0.8375\n",
            "Epoch 74/200\n",
            "20/20 [==============================] - 0s 6ms/step - loss: 0.3744 - accuracy: 0.8464 - val_loss: 0.4965 - val_accuracy: 0.7875\n",
            "Epoch 75/200\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.3756 - accuracy: 0.8339 - val_loss: 0.4159 - val_accuracy: 0.8125\n",
            "Epoch 76/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.3862 - accuracy: 0.8354 - val_loss: 0.3755 - val_accuracy: 0.8562\n",
            "Epoch 77/200\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.3602 - accuracy: 0.8558 - val_loss: 0.3854 - val_accuracy: 0.8438\n",
            "Epoch 78/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.3757 - accuracy: 0.8401 - val_loss: 0.3909 - val_accuracy: 0.8438\n",
            "Epoch 79/200\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.3456 - accuracy: 0.8589 - val_loss: 0.3842 - val_accuracy: 0.8438\n",
            "Epoch 80/200\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.3534 - accuracy: 0.8558 - val_loss: 0.3642 - val_accuracy: 0.8625\n",
            "Epoch 81/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.3590 - accuracy: 0.8433 - val_loss: 0.3833 - val_accuracy: 0.8562\n",
            "Epoch 82/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.3580 - accuracy: 0.8621 - val_loss: 0.3957 - val_accuracy: 0.8438\n",
            "Epoch 83/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.3759 - accuracy: 0.8448 - val_loss: 0.3729 - val_accuracy: 0.8687\n",
            "Epoch 84/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.3599 - accuracy: 0.8495 - val_loss: 0.4495 - val_accuracy: 0.8000\n",
            "Epoch 85/200\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.3600 - accuracy: 0.8542 - val_loss: 0.3957 - val_accuracy: 0.8625\n",
            "Epoch 86/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.3617 - accuracy: 0.8621 - val_loss: 0.3985 - val_accuracy: 0.8500\n",
            "Epoch 87/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.3757 - accuracy: 0.8339 - val_loss: 0.3819 - val_accuracy: 0.8500\n",
            "Epoch 88/200\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.3476 - accuracy: 0.8715 - val_loss: 0.4191 - val_accuracy: 0.8375\n",
            "Epoch 89/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.3516 - accuracy: 0.8652 - val_loss: 0.4082 - val_accuracy: 0.8375\n",
            "Epoch 90/200\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.3492 - accuracy: 0.8495 - val_loss: 0.3823 - val_accuracy: 0.8438\n",
            "Epoch 91/200\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.3583 - accuracy: 0.8511 - val_loss: 0.3808 - val_accuracy: 0.8500\n",
            "Epoch 92/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.3525 - accuracy: 0.8574 - val_loss: 0.3672 - val_accuracy: 0.8562\n",
            "Epoch 93/200\n",
            "20/20 [==============================] - 0s 6ms/step - loss: 0.3272 - accuracy: 0.8746 - val_loss: 0.3873 - val_accuracy: 0.8625\n",
            "Epoch 94/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.3389 - accuracy: 0.8668 - val_loss: 0.3724 - val_accuracy: 0.8562\n",
            "Epoch 95/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.3339 - accuracy: 0.8730 - val_loss: 0.4274 - val_accuracy: 0.8125\n",
            "Epoch 96/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.3383 - accuracy: 0.8605 - val_loss: 0.3704 - val_accuracy: 0.8625\n",
            "Epoch 97/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.3340 - accuracy: 0.8636 - val_loss: 0.3495 - val_accuracy: 0.8687\n",
            "Epoch 98/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.3279 - accuracy: 0.8621 - val_loss: 0.3580 - val_accuracy: 0.8750\n",
            "Epoch 99/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.3485 - accuracy: 0.8589 - val_loss: 0.3561 - val_accuracy: 0.8687\n",
            "Epoch 100/200\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.3833 - accuracy: 0.8589 - val_loss: 0.3532 - val_accuracy: 0.8750\n",
            "Epoch 101/200\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.3689 - accuracy: 0.8448 - val_loss: 0.3568 - val_accuracy: 0.8625\n",
            "Epoch 102/200\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.3422 - accuracy: 0.8605 - val_loss: 0.4047 - val_accuracy: 0.8375\n",
            "Epoch 103/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.3242 - accuracy: 0.8621 - val_loss: 0.3444 - val_accuracy: 0.8750\n",
            "Epoch 104/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.3454 - accuracy: 0.8699 - val_loss: 0.3912 - val_accuracy: 0.8562\n",
            "Epoch 105/200\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.3148 - accuracy: 0.8793 - val_loss: 0.4215 - val_accuracy: 0.8438\n",
            "Epoch 106/200\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.3262 - accuracy: 0.8621 - val_loss: 0.4089 - val_accuracy: 0.8188\n",
            "Epoch 107/200\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.3357 - accuracy: 0.8636 - val_loss: 0.3827 - val_accuracy: 0.8500\n",
            "Epoch 108/200\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.3270 - accuracy: 0.8621 - val_loss: 0.3862 - val_accuracy: 0.8625\n",
            "Epoch 109/200\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.3199 - accuracy: 0.8730 - val_loss: 0.3786 - val_accuracy: 0.8500\n",
            "Epoch 110/200\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.3306 - accuracy: 0.8715 - val_loss: 0.3470 - val_accuracy: 0.8687\n",
            "Epoch 111/200\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.3297 - accuracy: 0.8542 - val_loss: 0.3643 - val_accuracy: 0.8625\n",
            "Epoch 112/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.3258 - accuracy: 0.8668 - val_loss: 0.4338 - val_accuracy: 0.8188\n",
            "Epoch 113/200\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.3433 - accuracy: 0.8683 - val_loss: 0.3967 - val_accuracy: 0.8500\n",
            "Epoch 114/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.3228 - accuracy: 0.8856 - val_loss: 0.3512 - val_accuracy: 0.8625\n",
            "Epoch 115/200\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.3349 - accuracy: 0.8558 - val_loss: 0.3583 - val_accuracy: 0.8687\n",
            "Epoch 116/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.3360 - accuracy: 0.8730 - val_loss: 0.3918 - val_accuracy: 0.8438\n",
            "Epoch 117/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.3320 - accuracy: 0.8605 - val_loss: 0.3661 - val_accuracy: 0.8687\n",
            "Epoch 118/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.3185 - accuracy: 0.8793 - val_loss: 0.3515 - val_accuracy: 0.8625\n",
            "Epoch 119/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.3196 - accuracy: 0.8730 - val_loss: 0.3825 - val_accuracy: 0.8500\n",
            "Epoch 120/200\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.3055 - accuracy: 0.8762 - val_loss: 0.4055 - val_accuracy: 0.8313\n",
            "Epoch 121/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.3191 - accuracy: 0.8668 - val_loss: 0.3931 - val_accuracy: 0.8313\n",
            "Epoch 122/200\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.3167 - accuracy: 0.8699 - val_loss: 0.4058 - val_accuracy: 0.8125\n",
            "Epoch 123/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.3114 - accuracy: 0.8605 - val_loss: 0.3615 - val_accuracy: 0.8750\n",
            "Epoch 124/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.3129 - accuracy: 0.8699 - val_loss: 0.3786 - val_accuracy: 0.8438\n",
            "Epoch 125/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.3079 - accuracy: 0.8856 - val_loss: 0.3793 - val_accuracy: 0.8625\n",
            "Epoch 126/200\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.3188 - accuracy: 0.8777 - val_loss: 0.3595 - val_accuracy: 0.8625\n",
            "Epoch 127/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.3082 - accuracy: 0.8856 - val_loss: 0.3759 - val_accuracy: 0.8625\n",
            "Epoch 128/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.2950 - accuracy: 0.8871 - val_loss: 0.3891 - val_accuracy: 0.8625\n",
            "Epoch 129/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.2986 - accuracy: 0.8824 - val_loss: 0.3895 - val_accuracy: 0.8500\n",
            "Epoch 130/200\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.2942 - accuracy: 0.8871 - val_loss: 0.3668 - val_accuracy: 0.8625\n",
            "Epoch 131/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.3295 - accuracy: 0.8621 - val_loss: 0.4575 - val_accuracy: 0.7875\n",
            "Epoch 132/200\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.3046 - accuracy: 0.8699 - val_loss: 0.3546 - val_accuracy: 0.8687\n",
            "Epoch 133/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.3034 - accuracy: 0.8715 - val_loss: 0.3477 - val_accuracy: 0.8750\n",
            "Epoch 134/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.3144 - accuracy: 0.8699 - val_loss: 0.3866 - val_accuracy: 0.8313\n",
            "Epoch 135/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.3100 - accuracy: 0.8840 - val_loss: 0.4147 - val_accuracy: 0.8125\n",
            "Epoch 136/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.2972 - accuracy: 0.8809 - val_loss: 0.3885 - val_accuracy: 0.8500\n",
            "Epoch 137/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.3136 - accuracy: 0.8715 - val_loss: 0.3810 - val_accuracy: 0.8562\n",
            "Epoch 138/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.2966 - accuracy: 0.8809 - val_loss: 0.3805 - val_accuracy: 0.8625\n",
            "Epoch 139/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.3116 - accuracy: 0.8730 - val_loss: 0.3608 - val_accuracy: 0.8813\n",
            "Epoch 140/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.3040 - accuracy: 0.8746 - val_loss: 0.3749 - val_accuracy: 0.8438\n",
            "Epoch 141/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.3034 - accuracy: 0.8746 - val_loss: 0.4069 - val_accuracy: 0.8313\n",
            "Epoch 142/200\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.2993 - accuracy: 0.8840 - val_loss: 0.3828 - val_accuracy: 0.8500\n",
            "Epoch 143/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.3054 - accuracy: 0.8730 - val_loss: 0.3978 - val_accuracy: 0.8313\n",
            "Epoch 144/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.3036 - accuracy: 0.8777 - val_loss: 0.3821 - val_accuracy: 0.8375\n",
            "Epoch 145/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.3010 - accuracy: 0.8762 - val_loss: 0.3666 - val_accuracy: 0.8500\n",
            "Epoch 146/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.3123 - accuracy: 0.8793 - val_loss: 0.3751 - val_accuracy: 0.8687\n",
            "Epoch 147/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.3056 - accuracy: 0.8746 - val_loss: 0.3817 - val_accuracy: 0.8313\n",
            "Epoch 148/200\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.3055 - accuracy: 0.8809 - val_loss: 0.3986 - val_accuracy: 0.8250\n",
            "Epoch 149/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.2877 - accuracy: 0.8809 - val_loss: 0.3836 - val_accuracy: 0.8625\n",
            "Epoch 150/200\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.3104 - accuracy: 0.8856 - val_loss: 0.3631 - val_accuracy: 0.8750\n",
            "Epoch 151/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.2911 - accuracy: 0.8903 - val_loss: 0.3749 - val_accuracy: 0.8438\n",
            "Epoch 152/200\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.2986 - accuracy: 0.8777 - val_loss: 0.3713 - val_accuracy: 0.8625\n",
            "Epoch 153/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.2951 - accuracy: 0.8856 - val_loss: 0.3874 - val_accuracy: 0.8562\n",
            "Epoch 154/200\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.2984 - accuracy: 0.8809 - val_loss: 0.3719 - val_accuracy: 0.8562\n",
            "Epoch 155/200\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.2853 - accuracy: 0.8793 - val_loss: 0.3807 - val_accuracy: 0.8687\n",
            "Epoch 156/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.2872 - accuracy: 0.8840 - val_loss: 0.3951 - val_accuracy: 0.8313\n",
            "Epoch 157/200\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.3059 - accuracy: 0.8699 - val_loss: 0.4430 - val_accuracy: 0.7750\n",
            "Epoch 158/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.3305 - accuracy: 0.8699 - val_loss: 0.3493 - val_accuracy: 0.8813\n",
            "Epoch 159/200\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.3013 - accuracy: 0.8840 - val_loss: 0.3902 - val_accuracy: 0.8438\n",
            "Epoch 160/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.2931 - accuracy: 0.8777 - val_loss: 0.4448 - val_accuracy: 0.8125\n",
            "Epoch 161/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.3065 - accuracy: 0.8762 - val_loss: 0.3931 - val_accuracy: 0.8438\n",
            "Epoch 162/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.2950 - accuracy: 0.8777 - val_loss: 0.3623 - val_accuracy: 0.8875\n",
            "Epoch 163/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.3063 - accuracy: 0.8699 - val_loss: 0.4019 - val_accuracy: 0.8250\n",
            "Epoch 164/200\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.2961 - accuracy: 0.8793 - val_loss: 0.4144 - val_accuracy: 0.8188\n",
            "Epoch 165/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.2910 - accuracy: 0.8793 - val_loss: 0.4354 - val_accuracy: 0.8062\n",
            "Epoch 166/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.2908 - accuracy: 0.8715 - val_loss: 0.3738 - val_accuracy: 0.8438\n",
            "Epoch 167/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.2869 - accuracy: 0.8856 - val_loss: 0.3795 - val_accuracy: 0.8438\n",
            "Epoch 168/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.2759 - accuracy: 0.8950 - val_loss: 0.3844 - val_accuracy: 0.8438\n",
            "Epoch 169/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.2763 - accuracy: 0.8903 - val_loss: 0.4069 - val_accuracy: 0.8438\n",
            "Epoch 170/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.2879 - accuracy: 0.8809 - val_loss: 0.3674 - val_accuracy: 0.8625\n",
            "Epoch 171/200\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.3158 - accuracy: 0.8746 - val_loss: 0.3721 - val_accuracy: 0.8500\n",
            "Epoch 172/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.2973 - accuracy: 0.8903 - val_loss: 0.3620 - val_accuracy: 0.8687\n",
            "Epoch 173/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.2873 - accuracy: 0.8997 - val_loss: 0.4215 - val_accuracy: 0.8313\n",
            "Epoch 174/200\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.2694 - accuracy: 0.8840 - val_loss: 0.3648 - val_accuracy: 0.8562\n",
            "Epoch 175/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.2843 - accuracy: 0.8824 - val_loss: 0.3742 - val_accuracy: 0.8375\n",
            "Epoch 176/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.2811 - accuracy: 0.8887 - val_loss: 0.3943 - val_accuracy: 0.8313\n",
            "Epoch 177/200\n",
            "20/20 [==============================] - 0s 6ms/step - loss: 0.3019 - accuracy: 0.8746 - val_loss: 0.4658 - val_accuracy: 0.7750\n",
            "Epoch 178/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.2934 - accuracy: 0.8777 - val_loss: 0.4096 - val_accuracy: 0.8125\n",
            "Epoch 179/200\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.2983 - accuracy: 0.8668 - val_loss: 0.3829 - val_accuracy: 0.8375\n",
            "Epoch 180/200\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.2796 - accuracy: 0.8824 - val_loss: 0.3820 - val_accuracy: 0.8438\n",
            "Epoch 181/200\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.2819 - accuracy: 0.8746 - val_loss: 0.4367 - val_accuracy: 0.7937\n",
            "Epoch 182/200\n",
            "20/20 [==============================] - 0s 6ms/step - loss: 0.2731 - accuracy: 0.8871 - val_loss: 0.3721 - val_accuracy: 0.8625\n",
            "Epoch 183/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.3031 - accuracy: 0.8574 - val_loss: 0.3641 - val_accuracy: 0.8813\n",
            "Epoch 184/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.2990 - accuracy: 0.8762 - val_loss: 0.3464 - val_accuracy: 0.8813\n",
            "Epoch 185/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.3026 - accuracy: 0.8777 - val_loss: 0.3813 - val_accuracy: 0.8500\n",
            "Epoch 186/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.2675 - accuracy: 0.8950 - val_loss: 0.3570 - val_accuracy: 0.8750\n",
            "Epoch 187/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.2618 - accuracy: 0.9028 - val_loss: 0.3887 - val_accuracy: 0.8687\n",
            "Epoch 188/200\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.2649 - accuracy: 0.8981 - val_loss: 0.4514 - val_accuracy: 0.8313\n",
            "Epoch 189/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.2729 - accuracy: 0.8809 - val_loss: 0.3754 - val_accuracy: 0.8750\n",
            "Epoch 190/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.2923 - accuracy: 0.8652 - val_loss: 0.4119 - val_accuracy: 0.8313\n",
            "Epoch 191/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.2787 - accuracy: 0.8856 - val_loss: 0.3889 - val_accuracy: 0.8375\n",
            "Epoch 192/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.2619 - accuracy: 0.8934 - val_loss: 0.3967 - val_accuracy: 0.8625\n",
            "Epoch 193/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.2941 - accuracy: 0.8871 - val_loss: 0.3606 - val_accuracy: 0.8687\n",
            "Epoch 194/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.2978 - accuracy: 0.8715 - val_loss: 0.4016 - val_accuracy: 0.8250\n",
            "Epoch 195/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.2893 - accuracy: 0.8840 - val_loss: 0.3959 - val_accuracy: 0.8438\n",
            "Epoch 196/200\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.2812 - accuracy: 0.8824 - val_loss: 0.4085 - val_accuracy: 0.8313\n",
            "Epoch 197/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.2845 - accuracy: 0.8793 - val_loss: 0.3854 - val_accuracy: 0.8687\n",
            "Epoch 198/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.2940 - accuracy: 0.8683 - val_loss: 0.3753 - val_accuracy: 0.8625\n",
            "Epoch 199/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.2819 - accuracy: 0.8777 - val_loss: 0.3704 - val_accuracy: 0.8500\n",
            "Epoch 200/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.2720 - accuracy: 0.8824 - val_loss: 0.4265 - val_accuracy: 0.8125\n",
            "4/4 [==============================] - 0s 6ms/step - loss: 0.4131 - accuracy: 0.8500\n",
            "## evaluation loss and_metrics ##\n",
            "[0.41307610273361206, 0.8500000238418579]\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "0.9142857142857143\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "RestingECG_Normal"
      ],
      "metadata": {
        "id": "nU3l4DmCq_tF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "heart = pd.read_csv(f_path)\n",
        "\n",
        "heart = pd.get_dummies(heart)\n",
        "\n",
        "x = heart.drop('HeartDisease', axis=1)\n",
        "y = pd.get_dummies(heart[\"HeartDisease\"])\n",
        "\n",
        "heart['RestingECG_Normal'] = 0\n",
        "\n",
        "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size = 0.13,shuffle=True, random_state = 42)\n",
        "\n",
        "print(\"X_train: \", x_train.shape)\n",
        "print(\"y_train: \", y_train.shape)\n",
        "\n",
        "print(\"X_test: \", x_test.shape)\n",
        "print(\"y_test: \", y_test.shape)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "ModelExceptRestingECG_Normal = Sequential()\n",
        "\n",
        "\n",
        "ModelExceptRestingECG_Normal.add(Dense(128, activation = \"relu\",input_dim=20))\n",
        "ModelExceptRestingECG_Normal.add(Dropout(rate=0.2))\n",
        "ModelExceptRestingECG_Normal.add(Dense(64, activation = \"relu\"))\n",
        "ModelExceptRestingECG_Normal.add(Dropout(rate=0.2))\n",
        "ModelExceptRestingECG_Normal.add(Dense(32, activation = \"relu\"))\n",
        "ModelExceptRestingECG_Normal.add(Dropout(rate=0.1))\n",
        "ModelExceptRestingECG_Normal.add(Dense(16, activation = \"relu\"))\n",
        "ModelExceptRestingECG_Normal.add(Dense(8, activation = \"relu\"))\n",
        "ModelExceptRestingECG_Normal.add(Dense(2, activation = \"sigmoid\"))\n",
        "\n",
        "ModelExceptRestingECG_Normal.compile(optimizer = \"adam\", loss = \"categorical_crossentropy\", metrics = [\"accuracy\"])\n",
        "ModelExceptRestingECG_Normal.summary()\n",
        "\n",
        "hin=ModelExceptRestingECG_Normal.fit(x_train,y_train,epochs=200, validation_split=0.2)\n",
        "\n",
        "loss_and_metrics = ModelExceptRestingECG_Normal.evaluate(x_test, y_test, batch_size=32)\n",
        "print('## evaluation loss and_metrics ##')\n",
        "print(loss_and_metrics)\n",
        "\n",
        "y_predRestingECG_Normal = ModelExceptRestingECG_Normal.predict(x_test)\n",
        "y_predRestingECG_Normal\n",
        "\n",
        "y_pred_classRestingECG_Normal = np.argmax(y_predRestingECG_Normal, axis=1)\n",
        "y_pred_classRestingECG_Normal\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "y_test  = y_test.to_numpy()\n",
        "y_test\n",
        "\n",
        "y_test = np.argmax(y_test,axis=1)\n",
        "y_test\n",
        "\n",
        "np.mean(y_test == y_pred_classRestingECG_Normal)\n",
        "RestingECG_Normalscore=recall_score(y_test,y_pred_classRestingECG_Normal)\n",
        "print(RestingECG_Normalscore)"
      ],
      "metadata": {
        "id": "-nEmxIu-y-Ze",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b959b644-b77d-4fdf-e60a-f1e1a0baf922"
      },
      "execution_count": 96,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "X_train:  (798, 20)\n",
            "y_train:  (798, 2)\n",
            "X_test:  (120, 20)\n",
            "y_test:  (120, 2)\n",
            "Model: \"sequential_18\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense_108 (Dense)           (None, 128)               2688      \n",
            "                                                                 \n",
            " dropout_54 (Dropout)        (None, 128)               0         \n",
            "                                                                 \n",
            " dense_109 (Dense)           (None, 64)                8256      \n",
            "                                                                 \n",
            " dropout_55 (Dropout)        (None, 64)                0         \n",
            "                                                                 \n",
            " dense_110 (Dense)           (None, 32)                2080      \n",
            "                                                                 \n",
            " dropout_56 (Dropout)        (None, 32)                0         \n",
            "                                                                 \n",
            " dense_111 (Dense)           (None, 16)                528       \n",
            "                                                                 \n",
            " dense_112 (Dense)           (None, 8)                 136       \n",
            "                                                                 \n",
            " dense_113 (Dense)           (None, 2)                 18        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 13,706\n",
            "Trainable params: 13,706\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/200\n",
            "20/20 [==============================] - 1s 12ms/step - loss: 2.1293 - accuracy: 0.4969 - val_loss: 0.6796 - val_accuracy: 0.4750\n",
            "Epoch 2/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.8294 - accuracy: 0.5533 - val_loss: 0.7037 - val_accuracy: 0.3063\n",
            "Epoch 3/200\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.7287 - accuracy: 0.4890 - val_loss: 0.6899 - val_accuracy: 0.5063\n",
            "Epoch 4/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.6754 - accuracy: 0.5439 - val_loss: 0.6334 - val_accuracy: 0.4938\n",
            "Epoch 5/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.7021 - accuracy: 0.5658 - val_loss: 0.6165 - val_accuracy: 0.6750\n",
            "Epoch 6/200\n",
            "20/20 [==============================] - 0s 6ms/step - loss: 0.6733 - accuracy: 0.5376 - val_loss: 0.6182 - val_accuracy: 0.6625\n",
            "Epoch 7/200\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.7020 - accuracy: 0.5564 - val_loss: 0.6271 - val_accuracy: 0.4938\n",
            "Epoch 8/200\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.6729 - accuracy: 0.5423 - val_loss: 0.6172 - val_accuracy: 0.6750\n",
            "Epoch 9/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.6556 - accuracy: 0.5455 - val_loss: 0.6312 - val_accuracy: 0.4938\n",
            "Epoch 10/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.6627 - accuracy: 0.5486 - val_loss: 0.6227 - val_accuracy: 0.6750\n",
            "Epoch 11/200\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.6451 - accuracy: 0.5627 - val_loss: 0.6247 - val_accuracy: 0.5000\n",
            "Epoch 12/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.6529 - accuracy: 0.5502 - val_loss: 0.6265 - val_accuracy: 0.4938\n",
            "Epoch 13/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.6354 - accuracy: 0.5486 - val_loss: 0.6294 - val_accuracy: 0.4938\n",
            "Epoch 14/200\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.6425 - accuracy: 0.5517 - val_loss: 0.6204 - val_accuracy: 0.6750\n",
            "Epoch 15/200\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.6463 - accuracy: 0.5690 - val_loss: 0.6215 - val_accuracy: 0.4938\n",
            "Epoch 16/200\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.6475 - accuracy: 0.5752 - val_loss: 0.6219 - val_accuracy: 0.4938\n",
            "Epoch 17/200\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.6634 - accuracy: 0.5470 - val_loss: 0.6174 - val_accuracy: 0.6750\n",
            "Epoch 18/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.6496 - accuracy: 0.5486 - val_loss: 0.6204 - val_accuracy: 0.6625\n",
            "Epoch 19/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.6443 - accuracy: 0.5439 - val_loss: 0.6106 - val_accuracy: 0.6750\n",
            "Epoch 20/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.6378 - accuracy: 0.5705 - val_loss: 0.6170 - val_accuracy: 0.6750\n",
            "Epoch 21/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.6469 - accuracy: 0.5815 - val_loss: 0.6286 - val_accuracy: 0.4938\n",
            "Epoch 22/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.6564 - accuracy: 0.5408 - val_loss: 0.6168 - val_accuracy: 0.6750\n",
            "Epoch 23/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.6478 - accuracy: 0.5643 - val_loss: 0.6161 - val_accuracy: 0.6750\n",
            "Epoch 24/200\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.6451 - accuracy: 0.5486 - val_loss: 0.6199 - val_accuracy: 0.6750\n",
            "Epoch 25/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.6457 - accuracy: 0.5768 - val_loss: 0.6138 - val_accuracy: 0.6750\n",
            "Epoch 26/200\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.6420 - accuracy: 0.5643 - val_loss: 0.6199 - val_accuracy: 0.6438\n",
            "Epoch 27/200\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.6385 - accuracy: 0.5674 - val_loss: 0.6218 - val_accuracy: 0.4938\n",
            "Epoch 28/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.6468 - accuracy: 0.5564 - val_loss: 0.6237 - val_accuracy: 0.4938\n",
            "Epoch 29/200\n",
            "20/20 [==============================] - 0s 9ms/step - loss: 0.6424 - accuracy: 0.5580 - val_loss: 0.6122 - val_accuracy: 0.6750\n",
            "Epoch 30/200\n",
            "20/20 [==============================] - 0s 9ms/step - loss: 0.6449 - accuracy: 0.5831 - val_loss: 0.6172 - val_accuracy: 0.6687\n",
            "Epoch 31/200\n",
            "20/20 [==============================] - 0s 10ms/step - loss: 0.6345 - accuracy: 0.5549 - val_loss: 0.6251 - val_accuracy: 0.4938\n",
            "Epoch 32/200\n",
            "20/20 [==============================] - 0s 11ms/step - loss: 0.6447 - accuracy: 0.5502 - val_loss: 0.6254 - val_accuracy: 0.4938\n",
            "Epoch 33/200\n",
            "20/20 [==============================] - 0s 13ms/step - loss: 0.6414 - accuracy: 0.5517 - val_loss: 0.6215 - val_accuracy: 0.4938\n",
            "Epoch 34/200\n",
            "20/20 [==============================] - 0s 8ms/step - loss: 0.6447 - accuracy: 0.5533 - val_loss: 0.6188 - val_accuracy: 0.6625\n",
            "Epoch 35/200\n",
            "20/20 [==============================] - 0s 13ms/step - loss: 0.6428 - accuracy: 0.5345 - val_loss: 0.6198 - val_accuracy: 0.6750\n",
            "Epoch 36/200\n",
            "20/20 [==============================] - 0s 10ms/step - loss: 0.6427 - accuracy: 0.5737 - val_loss: 0.6126 - val_accuracy: 0.6750\n",
            "Epoch 37/200\n",
            "20/20 [==============================] - 0s 8ms/step - loss: 0.6410 - accuracy: 0.5627 - val_loss: 0.6220 - val_accuracy: 0.4875\n",
            "Epoch 38/200\n",
            "20/20 [==============================] - 0s 12ms/step - loss: 0.6403 - accuracy: 0.5643 - val_loss: 0.6197 - val_accuracy: 0.5688\n",
            "Epoch 39/200\n",
            "20/20 [==============================] - 0s 11ms/step - loss: 0.6391 - accuracy: 0.5470 - val_loss: 0.6194 - val_accuracy: 0.6062\n",
            "Epoch 40/200\n",
            "20/20 [==============================] - 0s 9ms/step - loss: 0.6418 - accuracy: 0.5298 - val_loss: 0.6186 - val_accuracy: 0.6875\n",
            "Epoch 41/200\n",
            "20/20 [==============================] - 0s 7ms/step - loss: 0.6356 - accuracy: 0.5846 - val_loss: 0.6178 - val_accuracy: 0.6750\n",
            "Epoch 42/200\n",
            "20/20 [==============================] - 0s 7ms/step - loss: 0.6450 - accuracy: 0.5752 - val_loss: 0.6191 - val_accuracy: 0.6750\n",
            "Epoch 43/200\n",
            "20/20 [==============================] - 0s 7ms/step - loss: 0.6484 - accuracy: 0.5862 - val_loss: 0.6202 - val_accuracy: 0.6500\n",
            "Epoch 44/200\n",
            "20/20 [==============================] - 0s 6ms/step - loss: 0.6393 - accuracy: 0.5533 - val_loss: 0.6160 - val_accuracy: 0.6687\n",
            "Epoch 45/200\n",
            "20/20 [==============================] - 0s 7ms/step - loss: 0.6356 - accuracy: 0.5611 - val_loss: 0.6197 - val_accuracy: 0.6500\n",
            "Epoch 46/200\n",
            "20/20 [==============================] - 0s 7ms/step - loss: 0.6396 - accuracy: 0.5611 - val_loss: 0.6223 - val_accuracy: 0.4938\n",
            "Epoch 47/200\n",
            "20/20 [==============================] - 0s 7ms/step - loss: 0.6366 - accuracy: 0.5517 - val_loss: 0.6188 - val_accuracy: 0.6938\n",
            "Epoch 48/200\n",
            "20/20 [==============================] - 0s 6ms/step - loss: 0.6377 - accuracy: 0.5831 - val_loss: 0.6191 - val_accuracy: 0.6313\n",
            "Epoch 49/200\n",
            "20/20 [==============================] - 0s 6ms/step - loss: 0.6405 - accuracy: 0.5784 - val_loss: 0.6111 - val_accuracy: 0.6750\n",
            "Epoch 50/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.6391 - accuracy: 0.5846 - val_loss: 0.6193 - val_accuracy: 0.6062\n",
            "Epoch 51/200\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.6524 - accuracy: 0.5643 - val_loss: 0.6212 - val_accuracy: 0.6500\n",
            "Epoch 52/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.6465 - accuracy: 0.5878 - val_loss: 0.6141 - val_accuracy: 0.6750\n",
            "Epoch 53/200\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.6386 - accuracy: 0.6129 - val_loss: 0.6118 - val_accuracy: 0.6750\n",
            "Epoch 54/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.6301 - accuracy: 0.6129 - val_loss: 0.6034 - val_accuracy: 0.6750\n",
            "Epoch 55/200\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.6279 - accuracy: 0.6348 - val_loss: 0.6017 - val_accuracy: 0.6812\n",
            "Epoch 56/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.6240 - accuracy: 0.6270 - val_loss: 0.5905 - val_accuracy: 0.7500\n",
            "Epoch 57/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.6245 - accuracy: 0.6301 - val_loss: 0.5799 - val_accuracy: 0.7500\n",
            "Epoch 58/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.6017 - accuracy: 0.6599 - val_loss: 0.5527 - val_accuracy: 0.7500\n",
            "Epoch 59/200\n",
            "20/20 [==============================] - 0s 9ms/step - loss: 0.6176 - accuracy: 0.6865 - val_loss: 0.5688 - val_accuracy: 0.7188\n",
            "Epoch 60/200\n",
            "20/20 [==============================] - 0s 7ms/step - loss: 0.5842 - accuracy: 0.6944 - val_loss: 0.5299 - val_accuracy: 0.8000\n",
            "Epoch 61/200\n",
            "20/20 [==============================] - 0s 9ms/step - loss: 0.6012 - accuracy: 0.6646 - val_loss: 0.5741 - val_accuracy: 0.6875\n",
            "Epoch 62/200\n",
            "20/20 [==============================] - 0s 12ms/step - loss: 0.5876 - accuracy: 0.7022 - val_loss: 0.5279 - val_accuracy: 0.7563\n",
            "Epoch 63/200\n",
            "20/20 [==============================] - 0s 13ms/step - loss: 0.5790 - accuracy: 0.7069 - val_loss: 0.5112 - val_accuracy: 0.7750\n",
            "Epoch 64/200\n",
            "20/20 [==============================] - 0s 9ms/step - loss: 0.5560 - accuracy: 0.7210 - val_loss: 0.5214 - val_accuracy: 0.7625\n",
            "Epoch 65/200\n",
            "20/20 [==============================] - 0s 11ms/step - loss: 0.5426 - accuracy: 0.7555 - val_loss: 0.4927 - val_accuracy: 0.7937\n",
            "Epoch 66/200\n",
            "20/20 [==============================] - 0s 7ms/step - loss: 0.5648 - accuracy: 0.7461 - val_loss: 0.4882 - val_accuracy: 0.8000\n",
            "Epoch 67/200\n",
            "20/20 [==============================] - 0s 8ms/step - loss: 0.5339 - accuracy: 0.7492 - val_loss: 0.5025 - val_accuracy: 0.7750\n",
            "Epoch 68/200\n",
            "20/20 [==============================] - 0s 7ms/step - loss: 0.5104 - accuracy: 0.7508 - val_loss: 0.5093 - val_accuracy: 0.7563\n",
            "Epoch 69/200\n",
            "20/20 [==============================] - 0s 6ms/step - loss: 0.5285 - accuracy: 0.7476 - val_loss: 0.4990 - val_accuracy: 0.7625\n",
            "Epoch 70/200\n",
            "20/20 [==============================] - 0s 7ms/step - loss: 0.5094 - accuracy: 0.7539 - val_loss: 0.5681 - val_accuracy: 0.6938\n",
            "Epoch 71/200\n",
            "20/20 [==============================] - 0s 6ms/step - loss: 0.5352 - accuracy: 0.7727 - val_loss: 0.4840 - val_accuracy: 0.7937\n",
            "Epoch 72/200\n",
            "20/20 [==============================] - 0s 6ms/step - loss: 0.4807 - accuracy: 0.7947 - val_loss: 0.4654 - val_accuracy: 0.7937\n",
            "Epoch 73/200\n",
            "20/20 [==============================] - 0s 6ms/step - loss: 0.5259 - accuracy: 0.7774 - val_loss: 0.4704 - val_accuracy: 0.7937\n",
            "Epoch 74/200\n",
            "20/20 [==============================] - 0s 6ms/step - loss: 0.4843 - accuracy: 0.7915 - val_loss: 0.4346 - val_accuracy: 0.8188\n",
            "Epoch 75/200\n",
            "20/20 [==============================] - 0s 7ms/step - loss: 0.4990 - accuracy: 0.7696 - val_loss: 0.4386 - val_accuracy: 0.8313\n",
            "Epoch 76/200\n",
            "20/20 [==============================] - 0s 6ms/step - loss: 0.4975 - accuracy: 0.7539 - val_loss: 0.5276 - val_accuracy: 0.7563\n",
            "Epoch 77/200\n",
            "20/20 [==============================] - 0s 8ms/step - loss: 0.4769 - accuracy: 0.7884 - val_loss: 0.5131 - val_accuracy: 0.7563\n",
            "Epoch 78/200\n",
            "20/20 [==============================] - 0s 16ms/step - loss: 0.4595 - accuracy: 0.7821 - val_loss: 0.4341 - val_accuracy: 0.8438\n",
            "Epoch 79/200\n",
            "20/20 [==============================] - 0s 15ms/step - loss: 0.4624 - accuracy: 0.8072 - val_loss: 0.5511 - val_accuracy: 0.7437\n",
            "Epoch 80/200\n",
            "20/20 [==============================] - 0s 8ms/step - loss: 0.4708 - accuracy: 0.7806 - val_loss: 0.4769 - val_accuracy: 0.7875\n",
            "Epoch 81/200\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.4865 - accuracy: 0.7931 - val_loss: 0.4240 - val_accuracy: 0.8375\n",
            "Epoch 82/200\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.4465 - accuracy: 0.8056 - val_loss: 0.4335 - val_accuracy: 0.8188\n",
            "Epoch 83/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.4624 - accuracy: 0.8009 - val_loss: 0.4230 - val_accuracy: 0.8313\n",
            "Epoch 84/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.4448 - accuracy: 0.8197 - val_loss: 0.4353 - val_accuracy: 0.8125\n",
            "Epoch 85/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.4352 - accuracy: 0.8103 - val_loss: 0.4724 - val_accuracy: 0.8000\n",
            "Epoch 86/200\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.4329 - accuracy: 0.8056 - val_loss: 0.4123 - val_accuracy: 0.8313\n",
            "Epoch 87/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.4238 - accuracy: 0.8056 - val_loss: 0.4200 - val_accuracy: 0.8125\n",
            "Epoch 88/200\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.4304 - accuracy: 0.8339 - val_loss: 0.3957 - val_accuracy: 0.8500\n",
            "Epoch 89/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.4354 - accuracy: 0.8150 - val_loss: 0.3964 - val_accuracy: 0.8313\n",
            "Epoch 90/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.4265 - accuracy: 0.8307 - val_loss: 0.4281 - val_accuracy: 0.8313\n",
            "Epoch 91/200\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.4182 - accuracy: 0.8276 - val_loss: 0.4214 - val_accuracy: 0.8250\n",
            "Epoch 92/200\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.4056 - accuracy: 0.8276 - val_loss: 0.4200 - val_accuracy: 0.8375\n",
            "Epoch 93/200\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.3851 - accuracy: 0.8386 - val_loss: 0.3962 - val_accuracy: 0.8438\n",
            "Epoch 94/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.3949 - accuracy: 0.8339 - val_loss: 0.3804 - val_accuracy: 0.8500\n",
            "Epoch 95/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.3909 - accuracy: 0.8276 - val_loss: 0.3841 - val_accuracy: 0.8562\n",
            "Epoch 96/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.3841 - accuracy: 0.8354 - val_loss: 0.3816 - val_accuracy: 0.8500\n",
            "Epoch 97/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.3865 - accuracy: 0.8323 - val_loss: 0.4370 - val_accuracy: 0.8000\n",
            "Epoch 98/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.3699 - accuracy: 0.8511 - val_loss: 0.4617 - val_accuracy: 0.8188\n",
            "Epoch 99/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.4438 - accuracy: 0.8009 - val_loss: 0.4482 - val_accuracy: 0.7937\n",
            "Epoch 100/200\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.3671 - accuracy: 0.8589 - val_loss: 0.3773 - val_accuracy: 0.8500\n",
            "Epoch 101/200\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.3587 - accuracy: 0.8589 - val_loss: 0.3956 - val_accuracy: 0.8438\n",
            "Epoch 102/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.3686 - accuracy: 0.8448 - val_loss: 0.4145 - val_accuracy: 0.8313\n",
            "Epoch 103/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.3760 - accuracy: 0.8448 - val_loss: 0.3741 - val_accuracy: 0.8500\n",
            "Epoch 104/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.3681 - accuracy: 0.8480 - val_loss: 0.3957 - val_accuracy: 0.8500\n",
            "Epoch 105/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.3835 - accuracy: 0.8323 - val_loss: 0.3920 - val_accuracy: 0.8500\n",
            "Epoch 106/200\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.3506 - accuracy: 0.8527 - val_loss: 0.3960 - val_accuracy: 0.8562\n",
            "Epoch 107/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.3472 - accuracy: 0.8605 - val_loss: 0.3678 - val_accuracy: 0.8562\n",
            "Epoch 108/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.3677 - accuracy: 0.8464 - val_loss: 0.3952 - val_accuracy: 0.8500\n",
            "Epoch 109/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.3586 - accuracy: 0.8558 - val_loss: 0.3537 - val_accuracy: 0.8625\n",
            "Epoch 110/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.3528 - accuracy: 0.8636 - val_loss: 0.3834 - val_accuracy: 0.8562\n",
            "Epoch 111/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.3671 - accuracy: 0.8542 - val_loss: 0.3492 - val_accuracy: 0.8500\n",
            "Epoch 112/200\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.3502 - accuracy: 0.8621 - val_loss: 0.3591 - val_accuracy: 0.8625\n",
            "Epoch 113/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.3643 - accuracy: 0.8495 - val_loss: 0.3668 - val_accuracy: 0.8562\n",
            "Epoch 114/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.3382 - accuracy: 0.8574 - val_loss: 0.3575 - val_accuracy: 0.8687\n",
            "Epoch 115/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.3482 - accuracy: 0.8558 - val_loss: 0.4016 - val_accuracy: 0.8250\n",
            "Epoch 116/200\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.3694 - accuracy: 0.8589 - val_loss: 0.3916 - val_accuracy: 0.8500\n",
            "Epoch 117/200\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.3341 - accuracy: 0.8636 - val_loss: 0.3701 - val_accuracy: 0.8562\n",
            "Epoch 118/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.3482 - accuracy: 0.8542 - val_loss: 0.4000 - val_accuracy: 0.8313\n",
            "Epoch 119/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.3337 - accuracy: 0.8621 - val_loss: 0.3538 - val_accuracy: 0.8687\n",
            "Epoch 120/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.3571 - accuracy: 0.8542 - val_loss: 0.3486 - val_accuracy: 0.8750\n",
            "Epoch 121/200\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.3485 - accuracy: 0.8527 - val_loss: 0.4077 - val_accuracy: 0.8375\n",
            "Epoch 122/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.3511 - accuracy: 0.8495 - val_loss: 0.4083 - val_accuracy: 0.8250\n",
            "Epoch 123/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.3629 - accuracy: 0.8621 - val_loss: 0.4660 - val_accuracy: 0.8125\n",
            "Epoch 124/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.3451 - accuracy: 0.8527 - val_loss: 0.4076 - val_accuracy: 0.8250\n",
            "Epoch 125/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.3395 - accuracy: 0.8589 - val_loss: 0.3875 - val_accuracy: 0.8375\n",
            "Epoch 126/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.3182 - accuracy: 0.8715 - val_loss: 0.3896 - val_accuracy: 0.8375\n",
            "Epoch 127/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.3278 - accuracy: 0.8793 - val_loss: 0.3787 - val_accuracy: 0.8313\n",
            "Epoch 128/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.3405 - accuracy: 0.8542 - val_loss: 0.3632 - val_accuracy: 0.8313\n",
            "Epoch 129/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.3213 - accuracy: 0.8793 - val_loss: 0.3875 - val_accuracy: 0.8438\n",
            "Epoch 130/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.3235 - accuracy: 0.8621 - val_loss: 0.3862 - val_accuracy: 0.8438\n",
            "Epoch 131/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.3315 - accuracy: 0.8652 - val_loss: 0.3698 - val_accuracy: 0.8562\n",
            "Epoch 132/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.3393 - accuracy: 0.8715 - val_loss: 0.3885 - val_accuracy: 0.8375\n",
            "Epoch 133/200\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.3176 - accuracy: 0.8699 - val_loss: 0.3873 - val_accuracy: 0.8375\n",
            "Epoch 134/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.3238 - accuracy: 0.8715 - val_loss: 0.4155 - val_accuracy: 0.8062\n",
            "Epoch 135/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.3292 - accuracy: 0.8824 - val_loss: 0.3802 - val_accuracy: 0.8438\n",
            "Epoch 136/200\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.3405 - accuracy: 0.8527 - val_loss: 0.3673 - val_accuracy: 0.8687\n",
            "Epoch 137/200\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.3181 - accuracy: 0.8715 - val_loss: 0.3664 - val_accuracy: 0.8687\n",
            "Epoch 138/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.3454 - accuracy: 0.8527 - val_loss: 0.3504 - val_accuracy: 0.8875\n",
            "Epoch 139/200\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.3270 - accuracy: 0.8668 - val_loss: 0.3743 - val_accuracy: 0.8562\n",
            "Epoch 140/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.3262 - accuracy: 0.8605 - val_loss: 0.3577 - val_accuracy: 0.8813\n",
            "Epoch 141/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.3352 - accuracy: 0.8605 - val_loss: 0.3911 - val_accuracy: 0.8375\n",
            "Epoch 142/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.3264 - accuracy: 0.8715 - val_loss: 0.3831 - val_accuracy: 0.8375\n",
            "Epoch 143/200\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.3135 - accuracy: 0.8762 - val_loss: 0.3854 - val_accuracy: 0.8562\n",
            "Epoch 144/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.3227 - accuracy: 0.8699 - val_loss: 0.3641 - val_accuracy: 0.8625\n",
            "Epoch 145/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.3373 - accuracy: 0.8605 - val_loss: 0.3561 - val_accuracy: 0.8750\n",
            "Epoch 146/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.3229 - accuracy: 0.8605 - val_loss: 0.4087 - val_accuracy: 0.8188\n",
            "Epoch 147/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.3315 - accuracy: 0.8715 - val_loss: 0.3621 - val_accuracy: 0.8625\n",
            "Epoch 148/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.3184 - accuracy: 0.8715 - val_loss: 0.4112 - val_accuracy: 0.8062\n",
            "Epoch 149/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.3232 - accuracy: 0.8605 - val_loss: 0.4183 - val_accuracy: 0.8062\n",
            "Epoch 150/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.3340 - accuracy: 0.8762 - val_loss: 0.3819 - val_accuracy: 0.8500\n",
            "Epoch 151/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.3240 - accuracy: 0.8746 - val_loss: 0.3809 - val_accuracy: 0.8500\n",
            "Epoch 152/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.3156 - accuracy: 0.8715 - val_loss: 0.4156 - val_accuracy: 0.8188\n",
            "Epoch 153/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.3176 - accuracy: 0.8762 - val_loss: 0.4395 - val_accuracy: 0.8000\n",
            "Epoch 154/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.3239 - accuracy: 0.8715 - val_loss: 0.3859 - val_accuracy: 0.8313\n",
            "Epoch 155/200\n",
            "20/20 [==============================] - 0s 6ms/step - loss: 0.3251 - accuracy: 0.8668 - val_loss: 0.3946 - val_accuracy: 0.8375\n",
            "Epoch 156/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.2922 - accuracy: 0.8918 - val_loss: 0.4262 - val_accuracy: 0.8125\n",
            "Epoch 157/200\n",
            "20/20 [==============================] - 0s 6ms/step - loss: 0.3054 - accuracy: 0.8824 - val_loss: 0.3686 - val_accuracy: 0.8625\n",
            "Epoch 158/200\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.3264 - accuracy: 0.8715 - val_loss: 0.3803 - val_accuracy: 0.8500\n",
            "Epoch 159/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.3128 - accuracy: 0.8793 - val_loss: 0.3970 - val_accuracy: 0.8313\n",
            "Epoch 160/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.3274 - accuracy: 0.8777 - val_loss: 0.4162 - val_accuracy: 0.8188\n",
            "Epoch 161/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.3101 - accuracy: 0.8809 - val_loss: 0.3618 - val_accuracy: 0.8625\n",
            "Epoch 162/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.3023 - accuracy: 0.8730 - val_loss: 0.4167 - val_accuracy: 0.8125\n",
            "Epoch 163/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.3031 - accuracy: 0.8793 - val_loss: 0.3903 - val_accuracy: 0.8500\n",
            "Epoch 164/200\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.3048 - accuracy: 0.8856 - val_loss: 0.3775 - val_accuracy: 0.8375\n",
            "Epoch 165/200\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.3115 - accuracy: 0.8809 - val_loss: 0.3805 - val_accuracy: 0.8562\n",
            "Epoch 166/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.3109 - accuracy: 0.8856 - val_loss: 0.4092 - val_accuracy: 0.8250\n",
            "Epoch 167/200\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.3056 - accuracy: 0.8777 - val_loss: 0.4485 - val_accuracy: 0.8000\n",
            "Epoch 168/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.3085 - accuracy: 0.8746 - val_loss: 0.4319 - val_accuracy: 0.8000\n",
            "Epoch 169/200\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.3190 - accuracy: 0.8777 - val_loss: 0.4376 - val_accuracy: 0.8125\n",
            "Epoch 170/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.3064 - accuracy: 0.8746 - val_loss: 0.4082 - val_accuracy: 0.8250\n",
            "Epoch 171/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.3105 - accuracy: 0.8871 - val_loss: 0.4082 - val_accuracy: 0.8250\n",
            "Epoch 172/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.3139 - accuracy: 0.8636 - val_loss: 0.4529 - val_accuracy: 0.7812\n",
            "Epoch 173/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.3148 - accuracy: 0.8699 - val_loss: 0.3771 - val_accuracy: 0.8500\n",
            "Epoch 174/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.3114 - accuracy: 0.8793 - val_loss: 0.3824 - val_accuracy: 0.8438\n",
            "Epoch 175/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.3061 - accuracy: 0.8840 - val_loss: 0.3855 - val_accuracy: 0.8562\n",
            "Epoch 176/200\n",
            "20/20 [==============================] - 0s 6ms/step - loss: 0.3161 - accuracy: 0.8856 - val_loss: 0.3917 - val_accuracy: 0.8500\n",
            "Epoch 177/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.2860 - accuracy: 0.8871 - val_loss: 0.4194 - val_accuracy: 0.8250\n",
            "Epoch 178/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.3039 - accuracy: 0.8699 - val_loss: 0.3719 - val_accuracy: 0.8687\n",
            "Epoch 179/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.3273 - accuracy: 0.8636 - val_loss: 0.3832 - val_accuracy: 0.8313\n",
            "Epoch 180/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.3324 - accuracy: 0.8636 - val_loss: 0.4011 - val_accuracy: 0.8375\n",
            "Epoch 181/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.3037 - accuracy: 0.8824 - val_loss: 0.3995 - val_accuracy: 0.8313\n",
            "Epoch 182/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.3043 - accuracy: 0.8777 - val_loss: 0.3888 - val_accuracy: 0.8375\n",
            "Epoch 183/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.3106 - accuracy: 0.8777 - val_loss: 0.4469 - val_accuracy: 0.7688\n",
            "Epoch 184/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.2993 - accuracy: 0.8777 - val_loss: 0.3786 - val_accuracy: 0.8625\n",
            "Epoch 185/200\n",
            "20/20 [==============================] - 0s 6ms/step - loss: 0.2903 - accuracy: 0.8730 - val_loss: 0.4053 - val_accuracy: 0.8313\n",
            "Epoch 186/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.2941 - accuracy: 0.8809 - val_loss: 0.4388 - val_accuracy: 0.8188\n",
            "Epoch 187/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.2908 - accuracy: 0.8809 - val_loss: 0.4116 - val_accuracy: 0.8313\n",
            "Epoch 188/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.3013 - accuracy: 0.8809 - val_loss: 0.4192 - val_accuracy: 0.8062\n",
            "Epoch 189/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.2987 - accuracy: 0.8903 - val_loss: 0.4005 - val_accuracy: 0.8313\n",
            "Epoch 190/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.3040 - accuracy: 0.8840 - val_loss: 0.4143 - val_accuracy: 0.8438\n",
            "Epoch 191/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.2955 - accuracy: 0.8856 - val_loss: 0.3819 - val_accuracy: 0.8438\n",
            "Epoch 192/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.3008 - accuracy: 0.8730 - val_loss: 0.3813 - val_accuracy: 0.8375\n",
            "Epoch 193/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.2781 - accuracy: 0.8950 - val_loss: 0.3777 - val_accuracy: 0.8375\n",
            "Epoch 194/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.2908 - accuracy: 0.8840 - val_loss: 0.4078 - val_accuracy: 0.8375\n",
            "Epoch 195/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.3035 - accuracy: 0.8824 - val_loss: 0.3630 - val_accuracy: 0.8625\n",
            "Epoch 196/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.2959 - accuracy: 0.8871 - val_loss: 0.3659 - val_accuracy: 0.8438\n",
            "Epoch 197/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.2864 - accuracy: 0.8856 - val_loss: 0.3669 - val_accuracy: 0.8687\n",
            "Epoch 198/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.3083 - accuracy: 0.8683 - val_loss: 0.3648 - val_accuracy: 0.8562\n",
            "Epoch 199/200\n",
            "20/20 [==============================] - 0s 6ms/step - loss: 0.2871 - accuracy: 0.8809 - val_loss: 0.4388 - val_accuracy: 0.8125\n",
            "Epoch 200/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.2949 - accuracy: 0.8777 - val_loss: 0.3862 - val_accuracy: 0.8313\n",
            "4/4 [==============================] - 0s 6ms/step - loss: 0.4566 - accuracy: 0.8500\n",
            "## evaluation loss and_metrics ##\n",
            "[0.456572949886322, 0.8500000238418579]\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "0.9\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "RestingECG_ST"
      ],
      "metadata": {
        "id": "zN27fEHNrBcX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "heart = pd.read_csv(f_path)\n",
        "\n",
        "heart = pd.get_dummies(heart)\n",
        "\n",
        "x = heart.drop('HeartDisease', axis=1)\n",
        "y = pd.get_dummies(heart[\"HeartDisease\"])\n",
        "\n",
        "heart['RestingECG_ST'] = 0\n",
        "\n",
        "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size = 0.13,shuffle=True, random_state = 42)\n",
        "\n",
        "print(\"X_train: \", x_train.shape)\n",
        "print(\"y_train: \", y_train.shape)\n",
        "\n",
        "print(\"X_test: \", x_test.shape)\n",
        "print(\"y_test: \", y_test.shape)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "ModelExceptRestingECG_ST = Sequential()\n",
        "\n",
        "\n",
        "ModelExceptRestingECG_ST.add(Dense(128, activation = \"relu\",input_dim=20))\n",
        "ModelExceptRestingECG_ST.add(Dropout(rate=0.2))\n",
        "ModelExceptRestingECG_ST.add(Dense(64, activation = \"relu\"))\n",
        "ModelExceptRestingECG_ST.add(Dropout(rate=0.2))\n",
        "ModelExceptRestingECG_ST.add(Dense(32, activation = \"relu\"))\n",
        "ModelExceptRestingECG_ST.add(Dropout(rate=0.1))\n",
        "ModelExceptRestingECG_ST.add(Dense(16, activation = \"relu\"))\n",
        "ModelExceptRestingECG_ST.add(Dense(8, activation = \"relu\"))\n",
        "ModelExceptRestingECG_ST.add(Dense(2, activation = \"sigmoid\"))\n",
        "\n",
        "ModelExceptRestingECG_ST.compile(optimizer = \"adam\", loss = \"categorical_crossentropy\", metrics = [\"accuracy\"])\n",
        "ModelExceptRestingECG_ST.summary()\n",
        "\n",
        "hin=ModelExceptRestingECG_ST.fit(x_train,y_train,epochs=200, validation_split=0.2)\n",
        "\n",
        "loss_and_metrics = ModelExceptRestingECG_ST.evaluate(x_test, y_test, batch_size=32)\n",
        "print('## evaluation loss and_metrics ##')\n",
        "print(loss_and_metrics)\n",
        "\n",
        "y_predRestingECG_ST = ModelExceptRestingECG_ST.predict(x_test)\n",
        "y_predRestingECG_ST\n",
        "\n",
        "y_pred_classRestingECG_ST = np.argmax(y_predRestingECG_ST, axis=1)\n",
        "y_pred_classRestingECG_ST\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "y_test  = y_test.to_numpy()\n",
        "y_test\n",
        "\n",
        "y_test = np.argmax(y_test,axis=1)\n",
        "y_test\n",
        "\n",
        "np.mean(y_test == y_pred_classRestingECG_ST)\n",
        "RestingECG_STscore=recall_score(y_test,y_pred_classRestingECG_ST)\n",
        "print(RestingECG_STscore)"
      ],
      "metadata": {
        "id": "usT_lK9Ky-8m",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e5cf0b3d-fb91-4098-c777-7873500e4de3"
      },
      "execution_count": 97,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "X_train:  (798, 20)\n",
            "y_train:  (798, 2)\n",
            "X_test:  (120, 20)\n",
            "y_test:  (120, 2)\n",
            "Model: \"sequential_19\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense_114 (Dense)           (None, 128)               2688      \n",
            "                                                                 \n",
            " dropout_57 (Dropout)        (None, 128)               0         \n",
            "                                                                 \n",
            " dense_115 (Dense)           (None, 64)                8256      \n",
            "                                                                 \n",
            " dropout_58 (Dropout)        (None, 64)                0         \n",
            "                                                                 \n",
            " dense_116 (Dense)           (None, 32)                2080      \n",
            "                                                                 \n",
            " dropout_59 (Dropout)        (None, 32)                0         \n",
            "                                                                 \n",
            " dense_117 (Dense)           (None, 16)                528       \n",
            "                                                                 \n",
            " dense_118 (Dense)           (None, 8)                 136       \n",
            "                                                                 \n",
            " dense_119 (Dense)           (None, 2)                 18        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 13,706\n",
            "Trainable params: 13,706\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/200\n",
            "20/20 [==============================] - 1s 12ms/step - loss: 1.6137 - accuracy: 0.5266 - val_loss: 0.6376 - val_accuracy: 0.6562\n",
            "Epoch 2/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.8919 - accuracy: 0.4702 - val_loss: 0.6645 - val_accuracy: 0.5875\n",
            "Epoch 3/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.7084 - accuracy: 0.5125 - val_loss: 0.6692 - val_accuracy: 0.6750\n",
            "Epoch 4/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.6890 - accuracy: 0.5690 - val_loss: 0.6596 - val_accuracy: 0.4938\n",
            "Epoch 5/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.6959 - accuracy: 0.5502 - val_loss: 0.6414 - val_accuracy: 0.4938\n",
            "Epoch 6/200\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.6842 - accuracy: 0.5643 - val_loss: 0.6396 - val_accuracy: 0.5500\n",
            "Epoch 7/200\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.6822 - accuracy: 0.5737 - val_loss: 0.6309 - val_accuracy: 0.6313\n",
            "Epoch 8/200\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.6588 - accuracy: 0.5455 - val_loss: 0.6266 - val_accuracy: 0.4938\n",
            "Epoch 9/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.6634 - accuracy: 0.5799 - val_loss: 0.6242 - val_accuracy: 0.5688\n",
            "Epoch 10/200\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.6740 - accuracy: 0.5878 - val_loss: 0.6631 - val_accuracy: 0.7000\n",
            "Epoch 11/200\n",
            "20/20 [==============================] - 0s 6ms/step - loss: 0.6629 - accuracy: 0.5956 - val_loss: 0.6243 - val_accuracy: 0.5000\n",
            "Epoch 12/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.6582 - accuracy: 0.5721 - val_loss: 0.6170 - val_accuracy: 0.7125\n",
            "Epoch 13/200\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.6819 - accuracy: 0.5596 - val_loss: 0.6485 - val_accuracy: 0.7125\n",
            "Epoch 14/200\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.6633 - accuracy: 0.5455 - val_loss: 0.6253 - val_accuracy: 0.5437\n",
            "Epoch 15/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.6717 - accuracy: 0.5627 - val_loss: 0.6276 - val_accuracy: 0.4875\n",
            "Epoch 16/200\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.6576 - accuracy: 0.5925 - val_loss: 0.6195 - val_accuracy: 0.7188\n",
            "Epoch 17/200\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.6518 - accuracy: 0.5752 - val_loss: 0.6258 - val_accuracy: 0.6625\n",
            "Epoch 18/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.6554 - accuracy: 0.5721 - val_loss: 0.6186 - val_accuracy: 0.7063\n",
            "Epoch 19/200\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.6561 - accuracy: 0.5831 - val_loss: 0.6107 - val_accuracy: 0.6750\n",
            "Epoch 20/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.6646 - accuracy: 0.5972 - val_loss: 0.6153 - val_accuracy: 0.7125\n",
            "Epoch 21/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.6512 - accuracy: 0.5925 - val_loss: 0.6143 - val_accuracy: 0.6625\n",
            "Epoch 22/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.6604 - accuracy: 0.5925 - val_loss: 0.6202 - val_accuracy: 0.6687\n",
            "Epoch 23/200\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.6418 - accuracy: 0.6034 - val_loss: 0.6216 - val_accuracy: 0.7000\n",
            "Epoch 24/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.6494 - accuracy: 0.6019 - val_loss: 0.6150 - val_accuracy: 0.6812\n",
            "Epoch 25/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.6463 - accuracy: 0.5846 - val_loss: 0.6123 - val_accuracy: 0.7250\n",
            "Epoch 26/200\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.6592 - accuracy: 0.5784 - val_loss: 0.6277 - val_accuracy: 0.6687\n",
            "Epoch 27/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.6401 - accuracy: 0.6176 - val_loss: 0.6081 - val_accuracy: 0.7375\n",
            "Epoch 28/200\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.6540 - accuracy: 0.6034 - val_loss: 0.6038 - val_accuracy: 0.6750\n",
            "Epoch 29/200\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.6270 - accuracy: 0.6317 - val_loss: 0.6032 - val_accuracy: 0.7063\n",
            "Epoch 30/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.6418 - accuracy: 0.5862 - val_loss: 0.6087 - val_accuracy: 0.7500\n",
            "Epoch 31/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.6339 - accuracy: 0.6254 - val_loss: 0.6107 - val_accuracy: 0.7500\n",
            "Epoch 32/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.6472 - accuracy: 0.6144 - val_loss: 0.6023 - val_accuracy: 0.7312\n",
            "Epoch 33/200\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.6428 - accuracy: 0.6458 - val_loss: 0.6079 - val_accuracy: 0.7375\n",
            "Epoch 34/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.6378 - accuracy: 0.6379 - val_loss: 0.5914 - val_accuracy: 0.7125\n",
            "Epoch 35/200\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.6373 - accuracy: 0.6395 - val_loss: 0.5977 - val_accuracy: 0.7500\n",
            "Epoch 36/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.6385 - accuracy: 0.6160 - val_loss: 0.6128 - val_accuracy: 0.7063\n",
            "Epoch 37/200\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.6325 - accuracy: 0.6034 - val_loss: 0.6004 - val_accuracy: 0.7250\n",
            "Epoch 38/200\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.6361 - accuracy: 0.6301 - val_loss: 0.5957 - val_accuracy: 0.7250\n",
            "Epoch 39/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.6200 - accuracy: 0.6364 - val_loss: 0.5831 - val_accuracy: 0.7188\n",
            "Epoch 40/200\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.6179 - accuracy: 0.6442 - val_loss: 0.5803 - val_accuracy: 0.7188\n",
            "Epoch 41/200\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.6131 - accuracy: 0.6724 - val_loss: 0.5747 - val_accuracy: 0.7500\n",
            "Epoch 42/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.6077 - accuracy: 0.6740 - val_loss: 0.5575 - val_accuracy: 0.7375\n",
            "Epoch 43/200\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.5981 - accuracy: 0.6740 - val_loss: 0.5600 - val_accuracy: 0.7312\n",
            "Epoch 44/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.6258 - accuracy: 0.6803 - val_loss: 0.5426 - val_accuracy: 0.7250\n",
            "Epoch 45/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.5928 - accuracy: 0.6912 - val_loss: 0.5203 - val_accuracy: 0.7750\n",
            "Epoch 46/200\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.6037 - accuracy: 0.6959 - val_loss: 0.5530 - val_accuracy: 0.7375\n",
            "Epoch 47/200\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.6511 - accuracy: 0.6818 - val_loss: 0.5264 - val_accuracy: 0.7688\n",
            "Epoch 48/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.6133 - accuracy: 0.7132 - val_loss: 0.6140 - val_accuracy: 0.6750\n",
            "Epoch 49/200\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.6110 - accuracy: 0.7069 - val_loss: 0.5296 - val_accuracy: 0.7625\n",
            "Epoch 50/200\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.5847 - accuracy: 0.7100 - val_loss: 0.5334 - val_accuracy: 0.7625\n",
            "Epoch 51/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.5618 - accuracy: 0.7241 - val_loss: 0.5275 - val_accuracy: 0.7500\n",
            "Epoch 52/200\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.5910 - accuracy: 0.7006 - val_loss: 0.5465 - val_accuracy: 0.7437\n",
            "Epoch 53/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.5777 - accuracy: 0.7006 - val_loss: 0.5312 - val_accuracy: 0.7625\n",
            "Epoch 54/200\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.5581 - accuracy: 0.7163 - val_loss: 0.5102 - val_accuracy: 0.7625\n",
            "Epoch 55/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.5527 - accuracy: 0.7257 - val_loss: 0.5219 - val_accuracy: 0.7437\n",
            "Epoch 56/200\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.5477 - accuracy: 0.7492 - val_loss: 0.5299 - val_accuracy: 0.7437\n",
            "Epoch 57/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.5247 - accuracy: 0.7429 - val_loss: 0.5144 - val_accuracy: 0.7688\n",
            "Epoch 58/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.5450 - accuracy: 0.7461 - val_loss: 0.4962 - val_accuracy: 0.7812\n",
            "Epoch 59/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.5397 - accuracy: 0.7571 - val_loss: 0.5042 - val_accuracy: 0.7812\n",
            "Epoch 60/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.5547 - accuracy: 0.7194 - val_loss: 0.5587 - val_accuracy: 0.7063\n",
            "Epoch 61/200\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.5459 - accuracy: 0.7633 - val_loss: 0.5268 - val_accuracy: 0.7688\n",
            "Epoch 62/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.5316 - accuracy: 0.7524 - val_loss: 0.5252 - val_accuracy: 0.7688\n",
            "Epoch 63/200\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.5352 - accuracy: 0.7571 - val_loss: 0.5167 - val_accuracy: 0.7750\n",
            "Epoch 64/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.5135 - accuracy: 0.7555 - val_loss: 0.5522 - val_accuracy: 0.7375\n",
            "Epoch 65/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.5242 - accuracy: 0.7618 - val_loss: 0.4747 - val_accuracy: 0.8000\n",
            "Epoch 66/200\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.5089 - accuracy: 0.7665 - val_loss: 0.5689 - val_accuracy: 0.7250\n",
            "Epoch 67/200\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.5065 - accuracy: 0.7618 - val_loss: 0.4661 - val_accuracy: 0.8125\n",
            "Epoch 68/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.5226 - accuracy: 0.7649 - val_loss: 0.4995 - val_accuracy: 0.8062\n",
            "Epoch 69/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.5108 - accuracy: 0.7853 - val_loss: 0.5031 - val_accuracy: 0.7937\n",
            "Epoch 70/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.5050 - accuracy: 0.7712 - val_loss: 0.4697 - val_accuracy: 0.8125\n",
            "Epoch 71/200\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.4874 - accuracy: 0.7696 - val_loss: 0.4898 - val_accuracy: 0.7875\n",
            "Epoch 72/200\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.5104 - accuracy: 0.7665 - val_loss: 0.4659 - val_accuracy: 0.8125\n",
            "Epoch 73/200\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.4949 - accuracy: 0.7931 - val_loss: 0.4850 - val_accuracy: 0.8062\n",
            "Epoch 74/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.4888 - accuracy: 0.7743 - val_loss: 0.4899 - val_accuracy: 0.7812\n",
            "Epoch 75/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.4886 - accuracy: 0.7994 - val_loss: 0.5050 - val_accuracy: 0.7812\n",
            "Epoch 76/200\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.4641 - accuracy: 0.8150 - val_loss: 0.4430 - val_accuracy: 0.8250\n",
            "Epoch 77/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.4718 - accuracy: 0.7978 - val_loss: 0.4574 - val_accuracy: 0.8375\n",
            "Epoch 78/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.4876 - accuracy: 0.7900 - val_loss: 0.5444 - val_accuracy: 0.7500\n",
            "Epoch 79/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.4710 - accuracy: 0.7994 - val_loss: 0.4431 - val_accuracy: 0.8438\n",
            "Epoch 80/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.4779 - accuracy: 0.7994 - val_loss: 0.4504 - val_accuracy: 0.8375\n",
            "Epoch 81/200\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.4576 - accuracy: 0.7994 - val_loss: 0.4392 - val_accuracy: 0.8438\n",
            "Epoch 82/200\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.4620 - accuracy: 0.8103 - val_loss: 0.4353 - val_accuracy: 0.8438\n",
            "Epoch 83/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.4341 - accuracy: 0.8041 - val_loss: 0.4882 - val_accuracy: 0.7812\n",
            "Epoch 84/200\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.4655 - accuracy: 0.8009 - val_loss: 0.4232 - val_accuracy: 0.8438\n",
            "Epoch 85/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.4445 - accuracy: 0.8025 - val_loss: 0.4227 - val_accuracy: 0.8438\n",
            "Epoch 86/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.4321 - accuracy: 0.8339 - val_loss: 0.4379 - val_accuracy: 0.8188\n",
            "Epoch 87/200\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.4205 - accuracy: 0.8119 - val_loss: 0.4141 - val_accuracy: 0.8313\n",
            "Epoch 88/200\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.4166 - accuracy: 0.8229 - val_loss: 0.4481 - val_accuracy: 0.8375\n",
            "Epoch 89/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.4386 - accuracy: 0.7978 - val_loss: 0.4293 - val_accuracy: 0.8313\n",
            "Epoch 90/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.4233 - accuracy: 0.8386 - val_loss: 0.3999 - val_accuracy: 0.8500\n",
            "Epoch 91/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.4330 - accuracy: 0.8150 - val_loss: 0.4037 - val_accuracy: 0.8500\n",
            "Epoch 92/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.4203 - accuracy: 0.8150 - val_loss: 0.4024 - val_accuracy: 0.8562\n",
            "Epoch 93/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.4196 - accuracy: 0.8370 - val_loss: 0.4273 - val_accuracy: 0.8438\n",
            "Epoch 94/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.4160 - accuracy: 0.8245 - val_loss: 0.4402 - val_accuracy: 0.8313\n",
            "Epoch 95/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.4110 - accuracy: 0.8229 - val_loss: 0.3865 - val_accuracy: 0.8562\n",
            "Epoch 96/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.3748 - accuracy: 0.8495 - val_loss: 0.3798 - val_accuracy: 0.8562\n",
            "Epoch 97/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.3974 - accuracy: 0.8197 - val_loss: 0.3724 - val_accuracy: 0.8625\n",
            "Epoch 98/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.3853 - accuracy: 0.8401 - val_loss: 0.4119 - val_accuracy: 0.8625\n",
            "Epoch 99/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.3804 - accuracy: 0.8401 - val_loss: 0.3911 - val_accuracy: 0.8687\n",
            "Epoch 100/200\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.4005 - accuracy: 0.8386 - val_loss: 0.3557 - val_accuracy: 0.8687\n",
            "Epoch 101/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.3864 - accuracy: 0.8339 - val_loss: 0.3736 - val_accuracy: 0.8625\n",
            "Epoch 102/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.3820 - accuracy: 0.8323 - val_loss: 0.3799 - val_accuracy: 0.8625\n",
            "Epoch 103/200\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.3716 - accuracy: 0.8574 - val_loss: 0.4159 - val_accuracy: 0.8375\n",
            "Epoch 104/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.3723 - accuracy: 0.8527 - val_loss: 0.3821 - val_accuracy: 0.8625\n",
            "Epoch 105/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.3791 - accuracy: 0.8448 - val_loss: 0.3535 - val_accuracy: 0.8687\n",
            "Epoch 106/200\n",
            "20/20 [==============================] - 0s 6ms/step - loss: 0.3574 - accuracy: 0.8417 - val_loss: 0.3691 - val_accuracy: 0.8813\n",
            "Epoch 107/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.3562 - accuracy: 0.8448 - val_loss: 0.3959 - val_accuracy: 0.8500\n",
            "Epoch 108/200\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.3573 - accuracy: 0.8527 - val_loss: 0.3840 - val_accuracy: 0.8500\n",
            "Epoch 109/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.3663 - accuracy: 0.8448 - val_loss: 0.4210 - val_accuracy: 0.8375\n",
            "Epoch 110/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.3531 - accuracy: 0.8464 - val_loss: 0.3947 - val_accuracy: 0.8562\n",
            "Epoch 111/200\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.3649 - accuracy: 0.8574 - val_loss: 0.3715 - val_accuracy: 0.8750\n",
            "Epoch 112/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.3618 - accuracy: 0.8542 - val_loss: 0.3666 - val_accuracy: 0.8625\n",
            "Epoch 113/200\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.3539 - accuracy: 0.8699 - val_loss: 0.3474 - val_accuracy: 0.8687\n",
            "Epoch 114/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.3612 - accuracy: 0.8527 - val_loss: 0.4131 - val_accuracy: 0.8375\n",
            "Epoch 115/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.3475 - accuracy: 0.8542 - val_loss: 0.3762 - val_accuracy: 0.8625\n",
            "Epoch 116/200\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.3526 - accuracy: 0.8527 - val_loss: 0.3829 - val_accuracy: 0.8438\n",
            "Epoch 117/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.3544 - accuracy: 0.8480 - val_loss: 0.3694 - val_accuracy: 0.8562\n",
            "Epoch 118/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.3481 - accuracy: 0.8652 - val_loss: 0.4235 - val_accuracy: 0.8250\n",
            "Epoch 119/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.3414 - accuracy: 0.8558 - val_loss: 0.3875 - val_accuracy: 0.8438\n",
            "Epoch 120/200\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.3520 - accuracy: 0.8636 - val_loss: 0.4185 - val_accuracy: 0.8250\n",
            "Epoch 121/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.3427 - accuracy: 0.8699 - val_loss: 0.3999 - val_accuracy: 0.8500\n",
            "Epoch 122/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.3828 - accuracy: 0.8464 - val_loss: 0.4259 - val_accuracy: 0.8250\n",
            "Epoch 123/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.3442 - accuracy: 0.8495 - val_loss: 0.3918 - val_accuracy: 0.8562\n",
            "Epoch 124/200\n",
            "20/20 [==============================] - 0s 6ms/step - loss: 0.3905 - accuracy: 0.8448 - val_loss: 0.4149 - val_accuracy: 0.8438\n",
            "Epoch 125/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.3444 - accuracy: 0.8621 - val_loss: 0.3757 - val_accuracy: 0.8687\n",
            "Epoch 126/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.3411 - accuracy: 0.8621 - val_loss: 0.4107 - val_accuracy: 0.8375\n",
            "Epoch 127/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.3323 - accuracy: 0.8589 - val_loss: 0.3677 - val_accuracy: 0.8687\n",
            "Epoch 128/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.3197 - accuracy: 0.8699 - val_loss: 0.3576 - val_accuracy: 0.8813\n",
            "Epoch 129/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.3294 - accuracy: 0.8668 - val_loss: 0.4198 - val_accuracy: 0.8188\n",
            "Epoch 130/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.3438 - accuracy: 0.8574 - val_loss: 0.3635 - val_accuracy: 0.8500\n",
            "Epoch 131/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.3168 - accuracy: 0.8683 - val_loss: 0.3542 - val_accuracy: 0.8813\n",
            "Epoch 132/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.3444 - accuracy: 0.8527 - val_loss: 0.3537 - val_accuracy: 0.8750\n",
            "Epoch 133/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.3439 - accuracy: 0.8605 - val_loss: 0.3812 - val_accuracy: 0.8500\n",
            "Epoch 134/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.3096 - accuracy: 0.8636 - val_loss: 0.4427 - val_accuracy: 0.8188\n",
            "Epoch 135/200\n",
            "20/20 [==============================] - 0s 6ms/step - loss: 0.3729 - accuracy: 0.8495 - val_loss: 0.3500 - val_accuracy: 0.8750\n",
            "Epoch 136/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.3336 - accuracy: 0.8668 - val_loss: 0.3702 - val_accuracy: 0.8562\n",
            "Epoch 137/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.3140 - accuracy: 0.8668 - val_loss: 0.3555 - val_accuracy: 0.8625\n",
            "Epoch 138/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.3267 - accuracy: 0.8683 - val_loss: 0.3644 - val_accuracy: 0.8562\n",
            "Epoch 139/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.3116 - accuracy: 0.8824 - val_loss: 0.4071 - val_accuracy: 0.8375\n",
            "Epoch 140/200\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.3259 - accuracy: 0.8589 - val_loss: 0.4052 - val_accuracy: 0.8562\n",
            "Epoch 141/200\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.3357 - accuracy: 0.8668 - val_loss: 0.4024 - val_accuracy: 0.8375\n",
            "Epoch 142/200\n",
            "20/20 [==============================] - 0s 6ms/step - loss: 0.3243 - accuracy: 0.8636 - val_loss: 0.3694 - val_accuracy: 0.8625\n",
            "Epoch 143/200\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.3267 - accuracy: 0.8636 - val_loss: 0.3616 - val_accuracy: 0.8687\n",
            "Epoch 144/200\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.3193 - accuracy: 0.8668 - val_loss: 0.3969 - val_accuracy: 0.8562\n",
            "Epoch 145/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.3192 - accuracy: 0.8809 - val_loss: 0.3623 - val_accuracy: 0.8687\n",
            "Epoch 146/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.3284 - accuracy: 0.8793 - val_loss: 0.3803 - val_accuracy: 0.8562\n",
            "Epoch 147/200\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.3119 - accuracy: 0.8668 - val_loss: 0.3775 - val_accuracy: 0.8562\n",
            "Epoch 148/200\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.3120 - accuracy: 0.8746 - val_loss: 0.3559 - val_accuracy: 0.8750\n",
            "Epoch 149/200\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.3151 - accuracy: 0.8621 - val_loss: 0.3864 - val_accuracy: 0.8500\n",
            "Epoch 150/200\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.3057 - accuracy: 0.8809 - val_loss: 0.4221 - val_accuracy: 0.8438\n",
            "Epoch 151/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.2986 - accuracy: 0.8777 - val_loss: 0.3436 - val_accuracy: 0.8687\n",
            "Epoch 152/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.3284 - accuracy: 0.8715 - val_loss: 0.4083 - val_accuracy: 0.8313\n",
            "Epoch 153/200\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.3208 - accuracy: 0.8746 - val_loss: 0.3918 - val_accuracy: 0.8625\n",
            "Epoch 154/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.3241 - accuracy: 0.8589 - val_loss: 0.3533 - val_accuracy: 0.8750\n",
            "Epoch 155/200\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.3340 - accuracy: 0.8668 - val_loss: 0.3534 - val_accuracy: 0.8687\n",
            "Epoch 156/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.3282 - accuracy: 0.8746 - val_loss: 0.3741 - val_accuracy: 0.8562\n",
            "Epoch 157/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.3229 - accuracy: 0.8746 - val_loss: 0.3594 - val_accuracy: 0.8750\n",
            "Epoch 158/200\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.3037 - accuracy: 0.8887 - val_loss: 0.3774 - val_accuracy: 0.8750\n",
            "Epoch 159/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.3106 - accuracy: 0.8762 - val_loss: 0.4454 - val_accuracy: 0.8188\n",
            "Epoch 160/200\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.3205 - accuracy: 0.8746 - val_loss: 0.3836 - val_accuracy: 0.8500\n",
            "Epoch 161/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.3101 - accuracy: 0.8715 - val_loss: 0.3794 - val_accuracy: 0.8687\n",
            "Epoch 162/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.3054 - accuracy: 0.8715 - val_loss: 0.3532 - val_accuracy: 0.8813\n",
            "Epoch 163/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.3190 - accuracy: 0.8777 - val_loss: 0.4004 - val_accuracy: 0.8438\n",
            "Epoch 164/200\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.3039 - accuracy: 0.8777 - val_loss: 0.4075 - val_accuracy: 0.8250\n",
            "Epoch 165/200\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.3074 - accuracy: 0.8824 - val_loss: 0.3665 - val_accuracy: 0.8625\n",
            "Epoch 166/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.3056 - accuracy: 0.8762 - val_loss: 0.3677 - val_accuracy: 0.8562\n",
            "Epoch 167/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.2875 - accuracy: 0.8762 - val_loss: 0.3507 - val_accuracy: 0.8813\n",
            "Epoch 168/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.3051 - accuracy: 0.8715 - val_loss: 0.4136 - val_accuracy: 0.8438\n",
            "Epoch 169/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.3068 - accuracy: 0.8824 - val_loss: 0.3574 - val_accuracy: 0.8813\n",
            "Epoch 170/200\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.3288 - accuracy: 0.8636 - val_loss: 0.4174 - val_accuracy: 0.8188\n",
            "Epoch 171/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.3071 - accuracy: 0.8699 - val_loss: 0.3535 - val_accuracy: 0.8750\n",
            "Epoch 172/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.3013 - accuracy: 0.8762 - val_loss: 0.3688 - val_accuracy: 0.8625\n",
            "Epoch 173/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.3028 - accuracy: 0.8871 - val_loss: 0.3792 - val_accuracy: 0.8625\n",
            "Epoch 174/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.3021 - accuracy: 0.8762 - val_loss: 0.4759 - val_accuracy: 0.8125\n",
            "Epoch 175/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.2978 - accuracy: 0.8683 - val_loss: 0.4009 - val_accuracy: 0.8500\n",
            "Epoch 176/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.3027 - accuracy: 0.8809 - val_loss: 0.3995 - val_accuracy: 0.8375\n",
            "Epoch 177/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.3006 - accuracy: 0.8762 - val_loss: 0.3922 - val_accuracy: 0.8500\n",
            "Epoch 178/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.3017 - accuracy: 0.8699 - val_loss: 0.4551 - val_accuracy: 0.8313\n",
            "Epoch 179/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.3164 - accuracy: 0.8715 - val_loss: 0.3550 - val_accuracy: 0.8813\n",
            "Epoch 180/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.3176 - accuracy: 0.8621 - val_loss: 0.4488 - val_accuracy: 0.8188\n",
            "Epoch 181/200\n",
            "20/20 [==============================] - 0s 6ms/step - loss: 0.2947 - accuracy: 0.8730 - val_loss: 0.4301 - val_accuracy: 0.8313\n",
            "Epoch 182/200\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.2911 - accuracy: 0.8762 - val_loss: 0.4201 - val_accuracy: 0.8625\n",
            "Epoch 183/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.2817 - accuracy: 0.8903 - val_loss: 0.4237 - val_accuracy: 0.8438\n",
            "Epoch 184/200\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.2914 - accuracy: 0.8730 - val_loss: 0.3745 - val_accuracy: 0.8750\n",
            "Epoch 185/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.2909 - accuracy: 0.8621 - val_loss: 0.4236 - val_accuracy: 0.8375\n",
            "Epoch 186/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.3127 - accuracy: 0.8652 - val_loss: 0.3823 - val_accuracy: 0.8750\n",
            "Epoch 187/200\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.3038 - accuracy: 0.8746 - val_loss: 0.5751 - val_accuracy: 0.8188\n",
            "Epoch 188/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.2958 - accuracy: 0.8840 - val_loss: 0.3682 - val_accuracy: 0.8750\n",
            "Epoch 189/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.2860 - accuracy: 0.8871 - val_loss: 0.3756 - val_accuracy: 0.8750\n",
            "Epoch 190/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.3137 - accuracy: 0.8809 - val_loss: 0.4033 - val_accuracy: 0.8562\n",
            "Epoch 191/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.2965 - accuracy: 0.8762 - val_loss: 0.4566 - val_accuracy: 0.8313\n",
            "Epoch 192/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.2965 - accuracy: 0.8824 - val_loss: 0.4660 - val_accuracy: 0.8125\n",
            "Epoch 193/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.2883 - accuracy: 0.8903 - val_loss: 0.3746 - val_accuracy: 0.8625\n",
            "Epoch 194/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.2810 - accuracy: 0.8856 - val_loss: 0.4125 - val_accuracy: 0.8250\n",
            "Epoch 195/200\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.2985 - accuracy: 0.8683 - val_loss: 0.3919 - val_accuracy: 0.8562\n",
            "Epoch 196/200\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.2789 - accuracy: 0.8746 - val_loss: 0.4268 - val_accuracy: 0.8375\n",
            "Epoch 197/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.2809 - accuracy: 0.8824 - val_loss: 0.4238 - val_accuracy: 0.8500\n",
            "Epoch 198/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.2919 - accuracy: 0.8746 - val_loss: 0.4252 - val_accuracy: 0.8500\n",
            "Epoch 199/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.2826 - accuracy: 0.8856 - val_loss: 0.5326 - val_accuracy: 0.8000\n",
            "Epoch 200/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.3014 - accuracy: 0.8699 - val_loss: 0.3986 - val_accuracy: 0.8562\n",
            "4/4 [==============================] - 0s 6ms/step - loss: 0.4046 - accuracy: 0.8500\n",
            "## evaluation loss and_metrics ##\n",
            "[0.40462881326675415, 0.8500000238418579]\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "0.8714285714285714\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "ExerciseAngina_N"
      ],
      "metadata": {
        "id": "9tgss6ydrCR-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "heart = pd.read_csv(f_path)\n",
        "\n",
        "heart = pd.get_dummies(heart)\n",
        "\n",
        "x = heart.drop('HeartDisease', axis=1)\n",
        "y = pd.get_dummies(heart[\"HeartDisease\"])\n",
        "\n",
        "heart['ExerciseAngina_N'] = 0\n",
        "\n",
        "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size = 0.13,shuffle=True, random_state = 42)\n",
        "\n",
        "print(\"X_train: \", x_train.shape)\n",
        "print(\"y_train: \", y_train.shape)\n",
        "\n",
        "print(\"X_test: \", x_test.shape)\n",
        "print(\"y_test: \", y_test.shape)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "ModelExceptExerciseAngina_N = Sequential()\n",
        "\n",
        "\n",
        "ModelExceptExerciseAngina_N.add(Dense(128, activation = \"relu\",input_dim=20))\n",
        "ModelExceptExerciseAngina_N.add(Dropout(rate=0.2))\n",
        "ModelExceptExerciseAngina_N.add(Dense(64, activation = \"relu\"))\n",
        "ModelExceptExerciseAngina_N.add(Dropout(rate=0.2))\n",
        "ModelExceptExerciseAngina_N.add(Dense(32, activation = \"relu\"))\n",
        "ModelExceptExerciseAngina_N.add(Dropout(rate=0.1))\n",
        "ModelExceptExerciseAngina_N.add(Dense(16, activation = \"relu\"))\n",
        "ModelExceptExerciseAngina_N.add(Dense(8, activation = \"relu\"))\n",
        "ModelExceptExerciseAngina_N.add(Dense(2, activation = \"sigmoid\"))\n",
        "\n",
        "ModelExceptExerciseAngina_N.compile(optimizer = \"adam\", loss = \"categorical_crossentropy\", metrics = [\"accuracy\"])\n",
        "ModelExceptExerciseAngina_N.summary()\n",
        "\n",
        "hin=ModelExceptExerciseAngina_N.fit(x_train,y_train,epochs=200, validation_split=0.2)\n",
        "\n",
        "loss_and_metrics = ModelExceptExerciseAngina_N.evaluate(x_test, y_test, batch_size=32)\n",
        "print('## evaluation loss and_metrics ##')\n",
        "print(loss_and_metrics)\n",
        "\n",
        "y_predExerciseAngina_N = ModelExceptExerciseAngina_N.predict(x_test)\n",
        "y_predExerciseAngina_N\n",
        "\n",
        "y_pred_classExerciseAngina_N = np.argmax(y_predExerciseAngina_N, axis=1)\n",
        "y_pred_classExerciseAngina_N\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "y_test  = y_test.to_numpy()\n",
        "y_test\n",
        "\n",
        "y_test = np.argmax(y_test,axis=1)\n",
        "y_test\n",
        "\n",
        "np.mean(y_test == y_pred_classExerciseAngina_N)\n",
        "ExerciseAngina_Nscore=recall_score(y_test,y_pred_classExerciseAngina_N)\n",
        "print(ExerciseAngina_Nscore)"
      ],
      "metadata": {
        "id": "i93upX0Zy_hj",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "64473a90-0e36-4702-e68c-12f4e8e920b1"
      },
      "execution_count": 98,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "X_train:  (798, 20)\n",
            "y_train:  (798, 2)\n",
            "X_test:  (120, 20)\n",
            "y_test:  (120, 2)\n",
            "Model: \"sequential_20\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense_120 (Dense)           (None, 128)               2688      \n",
            "                                                                 \n",
            " dropout_60 (Dropout)        (None, 128)               0         \n",
            "                                                                 \n",
            " dense_121 (Dense)           (None, 64)                8256      \n",
            "                                                                 \n",
            " dropout_61 (Dropout)        (None, 64)                0         \n",
            "                                                                 \n",
            " dense_122 (Dense)           (None, 32)                2080      \n",
            "                                                                 \n",
            " dropout_62 (Dropout)        (None, 32)                0         \n",
            "                                                                 \n",
            " dense_123 (Dense)           (None, 16)                528       \n",
            "                                                                 \n",
            " dense_124 (Dense)           (None, 8)                 136       \n",
            "                                                                 \n",
            " dense_125 (Dense)           (None, 2)                 18        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 13,706\n",
            "Trainable params: 13,706\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/200\n",
            "20/20 [==============================] - 1s 21ms/step - loss: 6.3552 - accuracy: 0.5564 - val_loss: 1.6472 - val_accuracy: 0.3063\n",
            "Epoch 2/200\n",
            "20/20 [==============================] - 0s 12ms/step - loss: 1.2431 - accuracy: 0.4655 - val_loss: 0.8090 - val_accuracy: 0.6375\n",
            "Epoch 3/200\n",
            "20/20 [==============================] - 0s 11ms/step - loss: 0.8435 - accuracy: 0.5141 - val_loss: 0.6985 - val_accuracy: 0.4812\n",
            "Epoch 4/200\n",
            "20/20 [==============================] - 0s 7ms/step - loss: 0.7594 - accuracy: 0.5564 - val_loss: 0.6689 - val_accuracy: 0.4812\n",
            "Epoch 5/200\n",
            "20/20 [==============================] - 0s 8ms/step - loss: 0.7189 - accuracy: 0.5423 - val_loss: 0.6544 - val_accuracy: 0.5437\n",
            "Epoch 6/200\n",
            "20/20 [==============================] - 0s 8ms/step - loss: 0.7007 - accuracy: 0.5329 - val_loss: 0.6313 - val_accuracy: 0.5813\n",
            "Epoch 7/200\n",
            "20/20 [==============================] - 0s 10ms/step - loss: 0.7163 - accuracy: 0.5110 - val_loss: 0.6220 - val_accuracy: 0.6000\n",
            "Epoch 8/200\n",
            "20/20 [==============================] - 0s 7ms/step - loss: 0.6861 - accuracy: 0.5408 - val_loss: 0.6125 - val_accuracy: 0.6750\n",
            "Epoch 9/200\n",
            "20/20 [==============================] - 0s 6ms/step - loss: 0.6765 - accuracy: 0.5549 - val_loss: 0.6140 - val_accuracy: 0.6687\n",
            "Epoch 10/200\n",
            "20/20 [==============================] - 0s 6ms/step - loss: 0.6875 - accuracy: 0.5878 - val_loss: 0.6209 - val_accuracy: 0.5938\n",
            "Epoch 11/200\n",
            "20/20 [==============================] - 0s 7ms/step - loss: 0.6765 - accuracy: 0.5533 - val_loss: 0.6247 - val_accuracy: 0.6000\n",
            "Epoch 12/200\n",
            "20/20 [==============================] - 0s 6ms/step - loss: 0.6670 - accuracy: 0.5643 - val_loss: 0.6203 - val_accuracy: 0.6625\n",
            "Epoch 13/200\n",
            "20/20 [==============================] - 0s 6ms/step - loss: 0.6636 - accuracy: 0.5423 - val_loss: 0.6216 - val_accuracy: 0.5813\n",
            "Epoch 14/200\n",
            "20/20 [==============================] - 0s 7ms/step - loss: 0.6607 - accuracy: 0.5000 - val_loss: 0.6209 - val_accuracy: 0.6062\n",
            "Epoch 15/200\n",
            "20/20 [==============================] - 0s 6ms/step - loss: 0.6679 - accuracy: 0.5329 - val_loss: 0.6201 - val_accuracy: 0.6062\n",
            "Epoch 16/200\n",
            "20/20 [==============================] - 0s 7ms/step - loss: 0.6688 - accuracy: 0.5455 - val_loss: 0.6306 - val_accuracy: 0.5938\n",
            "Epoch 17/200\n",
            "20/20 [==============================] - 0s 6ms/step - loss: 0.6631 - accuracy: 0.5893 - val_loss: 0.6234 - val_accuracy: 0.6687\n",
            "Epoch 18/200\n",
            "20/20 [==============================] - 0s 6ms/step - loss: 0.6801 - accuracy: 0.5486 - val_loss: 0.6192 - val_accuracy: 0.6812\n",
            "Epoch 19/200\n",
            "20/20 [==============================] - 0s 6ms/step - loss: 0.6498 - accuracy: 0.5502 - val_loss: 0.6221 - val_accuracy: 0.6062\n",
            "Epoch 20/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.6589 - accuracy: 0.5799 - val_loss: 0.6215 - val_accuracy: 0.6750\n",
            "Epoch 21/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.6479 - accuracy: 0.5423 - val_loss: 0.6275 - val_accuracy: 0.4938\n",
            "Epoch 22/200\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.6545 - accuracy: 0.5596 - val_loss: 0.6319 - val_accuracy: 0.5875\n",
            "Epoch 23/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.6579 - accuracy: 0.5674 - val_loss: 0.6294 - val_accuracy: 0.4812\n",
            "Epoch 24/200\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.6403 - accuracy: 0.5846 - val_loss: 0.6204 - val_accuracy: 0.6187\n",
            "Epoch 25/200\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.6411 - accuracy: 0.5721 - val_loss: 0.6150 - val_accuracy: 0.6750\n",
            "Epoch 26/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.6437 - accuracy: 0.5784 - val_loss: 0.6129 - val_accuracy: 0.6750\n",
            "Epoch 27/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.6485 - accuracy: 0.6003 - val_loss: 0.6114 - val_accuracy: 0.6750\n",
            "Epoch 28/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.6463 - accuracy: 0.5878 - val_loss: 0.6253 - val_accuracy: 0.5375\n",
            "Epoch 29/200\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.6407 - accuracy: 0.5878 - val_loss: 0.6228 - val_accuracy: 0.5063\n",
            "Epoch 30/200\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.6430 - accuracy: 0.5737 - val_loss: 0.6224 - val_accuracy: 0.5562\n",
            "Epoch 31/200\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.6551 - accuracy: 0.5564 - val_loss: 0.6197 - val_accuracy: 0.6062\n",
            "Epoch 32/200\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.6325 - accuracy: 0.6066 - val_loss: 0.6289 - val_accuracy: 0.4875\n",
            "Epoch 33/200\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.6507 - accuracy: 0.5564 - val_loss: 0.6328 - val_accuracy: 0.5063\n",
            "Epoch 34/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.6365 - accuracy: 0.5705 - val_loss: 0.6174 - val_accuracy: 0.6375\n",
            "Epoch 35/200\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.6349 - accuracy: 0.5925 - val_loss: 0.6185 - val_accuracy: 0.6250\n",
            "Epoch 36/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.6483 - accuracy: 0.5737 - val_loss: 0.6262 - val_accuracy: 0.6562\n",
            "Epoch 37/200\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.6371 - accuracy: 0.5674 - val_loss: 0.6185 - val_accuracy: 0.6687\n",
            "Epoch 38/200\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.6424 - accuracy: 0.5940 - val_loss: 0.6136 - val_accuracy: 0.6812\n",
            "Epoch 39/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.6367 - accuracy: 0.5831 - val_loss: 0.6177 - val_accuracy: 0.6750\n",
            "Epoch 40/200\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.6447 - accuracy: 0.6034 - val_loss: 0.6191 - val_accuracy: 0.6375\n",
            "Epoch 41/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.6431 - accuracy: 0.6050 - val_loss: 0.6145 - val_accuracy: 0.6875\n",
            "Epoch 42/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.6342 - accuracy: 0.6113 - val_loss: 0.6190 - val_accuracy: 0.6438\n",
            "Epoch 43/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.6419 - accuracy: 0.5940 - val_loss: 0.6143 - val_accuracy: 0.6875\n",
            "Epoch 44/200\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.6415 - accuracy: 0.6019 - val_loss: 0.6095 - val_accuracy: 0.6875\n",
            "Epoch 45/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.6344 - accuracy: 0.6050 - val_loss: 0.6187 - val_accuracy: 0.7000\n",
            "Epoch 46/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.6295 - accuracy: 0.6097 - val_loss: 0.6192 - val_accuracy: 0.6125\n",
            "Epoch 47/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.6329 - accuracy: 0.6364 - val_loss: 0.6148 - val_accuracy: 0.7500\n",
            "Epoch 48/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.6287 - accuracy: 0.6379 - val_loss: 0.5949 - val_accuracy: 0.7437\n",
            "Epoch 49/200\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.6229 - accuracy: 0.6270 - val_loss: 0.5864 - val_accuracy: 0.6875\n",
            "Epoch 50/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.6274 - accuracy: 0.6348 - val_loss: 0.5924 - val_accuracy: 0.7563\n",
            "Epoch 51/200\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.6276 - accuracy: 0.6505 - val_loss: 0.5903 - val_accuracy: 0.7250\n",
            "Epoch 52/200\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.6227 - accuracy: 0.6661 - val_loss: 0.5666 - val_accuracy: 0.7688\n",
            "Epoch 53/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.6008 - accuracy: 0.6755 - val_loss: 0.5586 - val_accuracy: 0.7500\n",
            "Epoch 54/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.6115 - accuracy: 0.6646 - val_loss: 0.5598 - val_accuracy: 0.7188\n",
            "Epoch 55/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.5877 - accuracy: 0.6881 - val_loss: 0.5419 - val_accuracy: 0.7812\n",
            "Epoch 56/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.5995 - accuracy: 0.6975 - val_loss: 0.5290 - val_accuracy: 0.7875\n",
            "Epoch 57/200\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.5885 - accuracy: 0.6975 - val_loss: 0.5362 - val_accuracy: 0.7750\n",
            "Epoch 58/200\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.5893 - accuracy: 0.6818 - val_loss: 0.5239 - val_accuracy: 0.7688\n",
            "Epoch 59/200\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.5871 - accuracy: 0.7194 - val_loss: 0.5165 - val_accuracy: 0.7688\n",
            "Epoch 60/200\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.5774 - accuracy: 0.7132 - val_loss: 0.5266 - val_accuracy: 0.7500\n",
            "Epoch 61/200\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.5569 - accuracy: 0.7382 - val_loss: 0.5243 - val_accuracy: 0.7625\n",
            "Epoch 62/200\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.5435 - accuracy: 0.7241 - val_loss: 0.5175 - val_accuracy: 0.7563\n",
            "Epoch 63/200\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.5308 - accuracy: 0.7618 - val_loss: 0.4922 - val_accuracy: 0.7812\n",
            "Epoch 64/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.5462 - accuracy: 0.7492 - val_loss: 0.5087 - val_accuracy: 0.7688\n",
            "Epoch 65/200\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.5471 - accuracy: 0.7445 - val_loss: 0.5068 - val_accuracy: 0.7937\n",
            "Epoch 66/200\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.5454 - accuracy: 0.7382 - val_loss: 0.4816 - val_accuracy: 0.7750\n",
            "Epoch 67/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.5417 - accuracy: 0.7461 - val_loss: 0.5048 - val_accuracy: 0.7875\n",
            "Epoch 68/200\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.5449 - accuracy: 0.7382 - val_loss: 0.4840 - val_accuracy: 0.8125\n",
            "Epoch 69/200\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.5204 - accuracy: 0.7618 - val_loss: 0.5293 - val_accuracy: 0.7437\n",
            "Epoch 70/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.5206 - accuracy: 0.7618 - val_loss: 0.4763 - val_accuracy: 0.8188\n",
            "Epoch 71/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.5286 - accuracy: 0.7508 - val_loss: 0.4974 - val_accuracy: 0.7563\n",
            "Epoch 72/200\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.5297 - accuracy: 0.7618 - val_loss: 0.4852 - val_accuracy: 0.7937\n",
            "Epoch 73/200\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.5233 - accuracy: 0.7555 - val_loss: 0.5082 - val_accuracy: 0.7625\n",
            "Epoch 74/200\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.4988 - accuracy: 0.7837 - val_loss: 0.4729 - val_accuracy: 0.7875\n",
            "Epoch 75/200\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.5137 - accuracy: 0.7680 - val_loss: 0.4445 - val_accuracy: 0.8062\n",
            "Epoch 76/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.4804 - accuracy: 0.7743 - val_loss: 0.4454 - val_accuracy: 0.8250\n",
            "Epoch 77/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.4857 - accuracy: 0.7868 - val_loss: 0.4742 - val_accuracy: 0.7875\n",
            "Epoch 78/200\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.4786 - accuracy: 0.7900 - val_loss: 0.4487 - val_accuracy: 0.7937\n",
            "Epoch 79/200\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.4858 - accuracy: 0.7900 - val_loss: 0.4496 - val_accuracy: 0.8188\n",
            "Epoch 80/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.4751 - accuracy: 0.7978 - val_loss: 0.4407 - val_accuracy: 0.8188\n",
            "Epoch 81/200\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.4757 - accuracy: 0.7853 - val_loss: 0.4487 - val_accuracy: 0.8125\n",
            "Epoch 82/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.4703 - accuracy: 0.7994 - val_loss: 0.4369 - val_accuracy: 0.8313\n",
            "Epoch 83/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.4579 - accuracy: 0.8150 - val_loss: 0.4254 - val_accuracy: 0.8438\n",
            "Epoch 84/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.4967 - accuracy: 0.7759 - val_loss: 0.4232 - val_accuracy: 0.8375\n",
            "Epoch 85/200\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.4539 - accuracy: 0.8009 - val_loss: 0.4281 - val_accuracy: 0.8375\n",
            "Epoch 86/200\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.4538 - accuracy: 0.8103 - val_loss: 0.4208 - val_accuracy: 0.8250\n",
            "Epoch 87/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.4436 - accuracy: 0.8166 - val_loss: 0.4174 - val_accuracy: 0.8250\n",
            "Epoch 88/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.4455 - accuracy: 0.8150 - val_loss: 0.4278 - val_accuracy: 0.8188\n",
            "Epoch 89/200\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.4743 - accuracy: 0.8009 - val_loss: 0.4250 - val_accuracy: 0.8375\n",
            "Epoch 90/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.4279 - accuracy: 0.8150 - val_loss: 0.4211 - val_accuracy: 0.8188\n",
            "Epoch 91/200\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.4315 - accuracy: 0.8213 - val_loss: 0.3945 - val_accuracy: 0.8438\n",
            "Epoch 92/200\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.4235 - accuracy: 0.8276 - val_loss: 0.3966 - val_accuracy: 0.8438\n",
            "Epoch 93/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.4060 - accuracy: 0.8213 - val_loss: 0.3916 - val_accuracy: 0.8438\n",
            "Epoch 94/200\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.4136 - accuracy: 0.8307 - val_loss: 0.3891 - val_accuracy: 0.8500\n",
            "Epoch 95/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.3910 - accuracy: 0.8433 - val_loss: 0.3955 - val_accuracy: 0.8438\n",
            "Epoch 96/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.4114 - accuracy: 0.8401 - val_loss: 0.4177 - val_accuracy: 0.8313\n",
            "Epoch 97/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.3857 - accuracy: 0.8417 - val_loss: 0.3994 - val_accuracy: 0.8438\n",
            "Epoch 98/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.4074 - accuracy: 0.8354 - val_loss: 0.3672 - val_accuracy: 0.8562\n",
            "Epoch 99/200\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.4022 - accuracy: 0.8386 - val_loss: 0.3746 - val_accuracy: 0.8500\n",
            "Epoch 100/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.3909 - accuracy: 0.8354 - val_loss: 0.3791 - val_accuracy: 0.8562\n",
            "Epoch 101/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.3875 - accuracy: 0.8401 - val_loss: 0.3911 - val_accuracy: 0.8375\n",
            "Epoch 102/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.3766 - accuracy: 0.8433 - val_loss: 0.3742 - val_accuracy: 0.8562\n",
            "Epoch 103/200\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.3780 - accuracy: 0.8433 - val_loss: 0.3806 - val_accuracy: 0.8438\n",
            "Epoch 104/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.3866 - accuracy: 0.8386 - val_loss: 0.3808 - val_accuracy: 0.8438\n",
            "Epoch 105/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.3763 - accuracy: 0.8495 - val_loss: 0.3712 - val_accuracy: 0.8625\n",
            "Epoch 106/200\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.3811 - accuracy: 0.8480 - val_loss: 0.3846 - val_accuracy: 0.8500\n",
            "Epoch 107/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.3798 - accuracy: 0.8417 - val_loss: 0.3787 - val_accuracy: 0.8438\n",
            "Epoch 108/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.3612 - accuracy: 0.8589 - val_loss: 0.3724 - val_accuracy: 0.8562\n",
            "Epoch 109/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.3493 - accuracy: 0.8652 - val_loss: 0.3698 - val_accuracy: 0.8500\n",
            "Epoch 110/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.3730 - accuracy: 0.8354 - val_loss: 0.3716 - val_accuracy: 0.8500\n",
            "Epoch 111/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.3835 - accuracy: 0.8260 - val_loss: 0.3659 - val_accuracy: 0.8687\n",
            "Epoch 112/200\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.3761 - accuracy: 0.8495 - val_loss: 0.3590 - val_accuracy: 0.8687\n",
            "Epoch 113/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.3658 - accuracy: 0.8542 - val_loss: 0.4990 - val_accuracy: 0.8000\n",
            "Epoch 114/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.3716 - accuracy: 0.8574 - val_loss: 0.3831 - val_accuracy: 0.8500\n",
            "Epoch 115/200\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.3552 - accuracy: 0.8652 - val_loss: 0.3660 - val_accuracy: 0.8625\n",
            "Epoch 116/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.3729 - accuracy: 0.8527 - val_loss: 0.3640 - val_accuracy: 0.8687\n",
            "Epoch 117/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.3546 - accuracy: 0.8605 - val_loss: 0.4005 - val_accuracy: 0.8375\n",
            "Epoch 118/200\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.3478 - accuracy: 0.8558 - val_loss: 0.3907 - val_accuracy: 0.8500\n",
            "Epoch 119/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.3499 - accuracy: 0.8636 - val_loss: 0.3907 - val_accuracy: 0.8500\n",
            "Epoch 120/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.3400 - accuracy: 0.8699 - val_loss: 0.3926 - val_accuracy: 0.8438\n",
            "Epoch 121/200\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.3397 - accuracy: 0.8621 - val_loss: 0.4149 - val_accuracy: 0.8250\n",
            "Epoch 122/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.3441 - accuracy: 0.8668 - val_loss: 0.3518 - val_accuracy: 0.8687\n",
            "Epoch 123/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.3446 - accuracy: 0.8589 - val_loss: 0.3660 - val_accuracy: 0.8625\n",
            "Epoch 124/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.3601 - accuracy: 0.8621 - val_loss: 0.3660 - val_accuracy: 0.8687\n",
            "Epoch 125/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.3335 - accuracy: 0.8558 - val_loss: 0.3585 - val_accuracy: 0.8687\n",
            "Epoch 126/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.3343 - accuracy: 0.8589 - val_loss: 0.3692 - val_accuracy: 0.8562\n",
            "Epoch 127/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.3478 - accuracy: 0.8621 - val_loss: 0.4141 - val_accuracy: 0.8188\n",
            "Epoch 128/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.3643 - accuracy: 0.8480 - val_loss: 0.3602 - val_accuracy: 0.8625\n",
            "Epoch 129/200\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.3481 - accuracy: 0.8433 - val_loss: 0.4216 - val_accuracy: 0.8062\n",
            "Epoch 130/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.3543 - accuracy: 0.8558 - val_loss: 0.3982 - val_accuracy: 0.8313\n",
            "Epoch 131/200\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.3153 - accuracy: 0.8683 - val_loss: 0.3694 - val_accuracy: 0.8500\n",
            "Epoch 132/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.3341 - accuracy: 0.8605 - val_loss: 0.3642 - val_accuracy: 0.8687\n",
            "Epoch 133/200\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.3276 - accuracy: 0.8652 - val_loss: 0.3893 - val_accuracy: 0.8438\n",
            "Epoch 134/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.3302 - accuracy: 0.8730 - val_loss: 0.4049 - val_accuracy: 0.8375\n",
            "Epoch 135/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.3338 - accuracy: 0.8683 - val_loss: 0.3982 - val_accuracy: 0.8562\n",
            "Epoch 136/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.3326 - accuracy: 0.8621 - val_loss: 0.3732 - val_accuracy: 0.8500\n",
            "Epoch 137/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.3334 - accuracy: 0.8574 - val_loss: 0.3667 - val_accuracy: 0.8500\n",
            "Epoch 138/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.3217 - accuracy: 0.8762 - val_loss: 0.4001 - val_accuracy: 0.8250\n",
            "Epoch 139/200\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.3339 - accuracy: 0.8621 - val_loss: 0.4383 - val_accuracy: 0.8000\n",
            "Epoch 140/200\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.3632 - accuracy: 0.8605 - val_loss: 0.3668 - val_accuracy: 0.8625\n",
            "Epoch 141/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.3348 - accuracy: 0.8621 - val_loss: 0.3865 - val_accuracy: 0.8562\n",
            "Epoch 142/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.3330 - accuracy: 0.8621 - val_loss: 0.3725 - val_accuracy: 0.8625\n",
            "Epoch 143/200\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.3205 - accuracy: 0.8746 - val_loss: 0.3867 - val_accuracy: 0.8500\n",
            "Epoch 144/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.3175 - accuracy: 0.8668 - val_loss: 0.4105 - val_accuracy: 0.8375\n",
            "Epoch 145/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.3272 - accuracy: 0.8668 - val_loss: 0.3544 - val_accuracy: 0.8750\n",
            "Epoch 146/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.3252 - accuracy: 0.8762 - val_loss: 0.3941 - val_accuracy: 0.8438\n",
            "Epoch 147/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.3374 - accuracy: 0.8621 - val_loss: 0.3657 - val_accuracy: 0.8625\n",
            "Epoch 148/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.3291 - accuracy: 0.8699 - val_loss: 0.3753 - val_accuracy: 0.8500\n",
            "Epoch 149/200\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.3438 - accuracy: 0.8589 - val_loss: 0.3593 - val_accuracy: 0.8625\n",
            "Epoch 150/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.3119 - accuracy: 0.8730 - val_loss: 0.4269 - val_accuracy: 0.8250\n",
            "Epoch 151/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.3264 - accuracy: 0.8683 - val_loss: 0.4179 - val_accuracy: 0.8625\n",
            "Epoch 152/200\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.3374 - accuracy: 0.8683 - val_loss: 0.3922 - val_accuracy: 0.8500\n",
            "Epoch 153/200\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.3296 - accuracy: 0.8574 - val_loss: 0.4160 - val_accuracy: 0.8375\n",
            "Epoch 154/200\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.3296 - accuracy: 0.8793 - val_loss: 0.4167 - val_accuracy: 0.8188\n",
            "Epoch 155/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.3135 - accuracy: 0.8730 - val_loss: 0.3682 - val_accuracy: 0.8625\n",
            "Epoch 156/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.3486 - accuracy: 0.8495 - val_loss: 0.3459 - val_accuracy: 0.8625\n",
            "Epoch 157/200\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.3222 - accuracy: 0.8715 - val_loss: 0.3924 - val_accuracy: 0.8313\n",
            "Epoch 158/200\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.3157 - accuracy: 0.8730 - val_loss: 0.4100 - val_accuracy: 0.8250\n",
            "Epoch 159/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.3200 - accuracy: 0.8840 - val_loss: 0.3844 - val_accuracy: 0.8438\n",
            "Epoch 160/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.3096 - accuracy: 0.8746 - val_loss: 0.3796 - val_accuracy: 0.8438\n",
            "Epoch 161/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.3092 - accuracy: 0.8668 - val_loss: 0.4217 - val_accuracy: 0.8062\n",
            "Epoch 162/200\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.3438 - accuracy: 0.8621 - val_loss: 0.3874 - val_accuracy: 0.8500\n",
            "Epoch 163/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.3121 - accuracy: 0.8715 - val_loss: 0.3775 - val_accuracy: 0.8500\n",
            "Epoch 164/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.3108 - accuracy: 0.8762 - val_loss: 0.3618 - val_accuracy: 0.8750\n",
            "Epoch 165/200\n",
            "20/20 [==============================] - 0s 6ms/step - loss: 0.3099 - accuracy: 0.8746 - val_loss: 0.4194 - val_accuracy: 0.8062\n",
            "Epoch 166/200\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.3258 - accuracy: 0.8652 - val_loss: 0.3785 - val_accuracy: 0.8500\n",
            "Epoch 167/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.3172 - accuracy: 0.8809 - val_loss: 0.3590 - val_accuracy: 0.8625\n",
            "Epoch 168/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.3101 - accuracy: 0.8683 - val_loss: 0.3766 - val_accuracy: 0.8500\n",
            "Epoch 169/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.3229 - accuracy: 0.8746 - val_loss: 0.3647 - val_accuracy: 0.8687\n",
            "Epoch 170/200\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.3080 - accuracy: 0.8730 - val_loss: 0.3884 - val_accuracy: 0.8500\n",
            "Epoch 171/200\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.3144 - accuracy: 0.8824 - val_loss: 0.3701 - val_accuracy: 0.8562\n",
            "Epoch 172/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.3185 - accuracy: 0.8699 - val_loss: 0.3777 - val_accuracy: 0.8500\n",
            "Epoch 173/200\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.3186 - accuracy: 0.8730 - val_loss: 0.3860 - val_accuracy: 0.8500\n",
            "Epoch 174/200\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.2927 - accuracy: 0.8793 - val_loss: 0.3802 - val_accuracy: 0.8625\n",
            "Epoch 175/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.3197 - accuracy: 0.8777 - val_loss: 0.3880 - val_accuracy: 0.8438\n",
            "Epoch 176/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.3108 - accuracy: 0.8730 - val_loss: 0.3814 - val_accuracy: 0.8438\n",
            "Epoch 177/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.3021 - accuracy: 0.8824 - val_loss: 0.3948 - val_accuracy: 0.8562\n",
            "Epoch 178/200\n",
            "20/20 [==============================] - 0s 6ms/step - loss: 0.3186 - accuracy: 0.8746 - val_loss: 0.3731 - val_accuracy: 0.8438\n",
            "Epoch 179/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.2881 - accuracy: 0.8871 - val_loss: 0.4389 - val_accuracy: 0.7937\n",
            "Epoch 180/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.3223 - accuracy: 0.8699 - val_loss: 0.3608 - val_accuracy: 0.8687\n",
            "Epoch 181/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.3177 - accuracy: 0.8715 - val_loss: 0.3699 - val_accuracy: 0.8625\n",
            "Epoch 182/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.3093 - accuracy: 0.8777 - val_loss: 0.3896 - val_accuracy: 0.8562\n",
            "Epoch 183/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.3108 - accuracy: 0.8777 - val_loss: 0.4097 - val_accuracy: 0.8375\n",
            "Epoch 184/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.3174 - accuracy: 0.8730 - val_loss: 0.3970 - val_accuracy: 0.8438\n",
            "Epoch 185/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.3061 - accuracy: 0.8715 - val_loss: 0.3921 - val_accuracy: 0.8188\n",
            "Epoch 186/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.3117 - accuracy: 0.8809 - val_loss: 0.4213 - val_accuracy: 0.7875\n",
            "Epoch 187/200\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.3191 - accuracy: 0.8793 - val_loss: 0.3943 - val_accuracy: 0.8188\n",
            "Epoch 188/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.2986 - accuracy: 0.8840 - val_loss: 0.3873 - val_accuracy: 0.8500\n",
            "Epoch 189/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.3019 - accuracy: 0.8809 - val_loss: 0.4152 - val_accuracy: 0.8375\n",
            "Epoch 190/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.3176 - accuracy: 0.8699 - val_loss: 0.3892 - val_accuracy: 0.8500\n",
            "Epoch 191/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.3058 - accuracy: 0.8856 - val_loss: 0.3771 - val_accuracy: 0.8625\n",
            "Epoch 192/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.3121 - accuracy: 0.8715 - val_loss: 0.3793 - val_accuracy: 0.8625\n",
            "Epoch 193/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.3058 - accuracy: 0.8809 - val_loss: 0.4190 - val_accuracy: 0.8188\n",
            "Epoch 194/200\n",
            "20/20 [==============================] - 0s 6ms/step - loss: 0.3067 - accuracy: 0.8762 - val_loss: 0.3637 - val_accuracy: 0.8750\n",
            "Epoch 195/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.3024 - accuracy: 0.8762 - val_loss: 0.3856 - val_accuracy: 0.8438\n",
            "Epoch 196/200\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.3032 - accuracy: 0.8840 - val_loss: 0.3836 - val_accuracy: 0.8562\n",
            "Epoch 197/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.3037 - accuracy: 0.8809 - val_loss: 0.4006 - val_accuracy: 0.8313\n",
            "Epoch 198/200\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.3061 - accuracy: 0.8762 - val_loss: 0.3855 - val_accuracy: 0.8438\n",
            "Epoch 199/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.2926 - accuracy: 0.8824 - val_loss: 0.3953 - val_accuracy: 0.8250\n",
            "Epoch 200/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.2904 - accuracy: 0.8824 - val_loss: 0.3868 - val_accuracy: 0.8438\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.4294 - accuracy: 0.8417\n",
            "## evaluation loss and_metrics ##\n",
            "[0.42936721444129944, 0.8416666388511658]\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "0.8714285714285714\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "ExerciseAngina_Y"
      ],
      "metadata": {
        "id": "qJnT_OVvrEsz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "heart = pd.read_csv(f_path)\n",
        "\n",
        "heart = pd.get_dummies(heart)\n",
        "\n",
        "x = heart.drop('HeartDisease', axis=1)\n",
        "y = pd.get_dummies(heart[\"HeartDisease\"])\n",
        "\n",
        "heart['ExerciseAngina_Y'] = 0\n",
        "\n",
        "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size = 0.13,shuffle=True, random_state = 42)\n",
        "\n",
        "print(\"X_train: \", x_train.shape)\n",
        "print(\"y_train: \", y_train.shape)\n",
        "\n",
        "print(\"X_test: \", x_test.shape)\n",
        "print(\"y_test: \", y_test.shape)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "ModelExceptExerciseAngina_Y = Sequential()\n",
        "\n",
        "\n",
        "ModelExceptExerciseAngina_Y.add(Dense(128, activation = \"relu\",input_dim=20))\n",
        "ModelExceptExerciseAngina_Y.add(Dropout(rate=0.2))\n",
        "ModelExceptExerciseAngina_Y.add(Dense(64, activation = \"relu\"))\n",
        "ModelExceptExerciseAngina_Y.add(Dropout(rate=0.2))\n",
        "ModelExceptExerciseAngina_Y.add(Dense(32, activation = \"relu\"))\n",
        "ModelExceptExerciseAngina_Y.add(Dropout(rate=0.1))\n",
        "ModelExceptExerciseAngina_Y.add(Dense(16, activation = \"relu\"))\n",
        "ModelExceptExerciseAngina_Y.add(Dense(8, activation = \"relu\"))\n",
        "ModelExceptExerciseAngina_Y.add(Dense(2, activation = \"sigmoid\"))\n",
        "\n",
        "ModelExceptExerciseAngina_Y.compile(optimizer = \"adam\", loss = \"categorical_crossentropy\", metrics = [\"accuracy\"])\n",
        "ModelExceptExerciseAngina_Y.summary()\n",
        "\n",
        "hin=ModelExceptExerciseAngina_Y.fit(x_train,y_train,epochs=200, validation_split=0.2)\n",
        "\n",
        "loss_and_metrics = ModelExceptExerciseAngina_Y.evaluate(x_test, y_test, batch_size=32)\n",
        "print('## evaluation loss and_metrics ##')\n",
        "print(loss_and_metrics)\n",
        "\n",
        "y_predExerciseAngina_Y = ModelExceptExerciseAngina_Y.predict(x_test)\n",
        "y_predExerciseAngina_Y\n",
        "\n",
        "y_pred_classExerciseAngina_Y = np.argmax(y_predExerciseAngina_Y, axis=1)\n",
        "y_pred_classExerciseAngina_Y\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "y_test  = y_test.to_numpy()\n",
        "y_test\n",
        "\n",
        "y_test = np.argmax(y_test,axis=1)\n",
        "y_test\n",
        "\n",
        "np.mean(y_test == y_pred_classExerciseAngina_Y)\n",
        "ExerciseAngina_Yscore=recall_score(y_test,y_pred_classExerciseAngina_Y)\n",
        "print(ExerciseAngina_Yscore)"
      ],
      "metadata": {
        "id": "y_m-8girzAFt",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b911fd65-6fb3-43c6-99ed-485def00019c"
      },
      "execution_count": 99,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "X_train:  (798, 20)\n",
            "y_train:  (798, 2)\n",
            "X_test:  (120, 20)\n",
            "y_test:  (120, 2)\n",
            "Model: \"sequential_21\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense_126 (Dense)           (None, 128)               2688      \n",
            "                                                                 \n",
            " dropout_63 (Dropout)        (None, 128)               0         \n",
            "                                                                 \n",
            " dense_127 (Dense)           (None, 64)                8256      \n",
            "                                                                 \n",
            " dropout_64 (Dropout)        (None, 64)                0         \n",
            "                                                                 \n",
            " dense_128 (Dense)           (None, 32)                2080      \n",
            "                                                                 \n",
            " dropout_65 (Dropout)        (None, 32)                0         \n",
            "                                                                 \n",
            " dense_129 (Dense)           (None, 16)                528       \n",
            "                                                                 \n",
            " dense_130 (Dense)           (None, 8)                 136       \n",
            "                                                                 \n",
            " dense_131 (Dense)           (None, 2)                 18        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 13,706\n",
            "Trainable params: 13,706\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/200\n",
            "20/20 [==============================] - 1s 13ms/step - loss: 3.7201 - accuracy: 0.5329 - val_loss: 0.6553 - val_accuracy: 0.6687\n",
            "Epoch 2/200\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 1.1234 - accuracy: 0.5674 - val_loss: 0.6216 - val_accuracy: 0.6750\n",
            "Epoch 3/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.8569 - accuracy: 0.5408 - val_loss: 0.6432 - val_accuracy: 0.6750\n",
            "Epoch 4/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.7770 - accuracy: 0.5658 - val_loss: 0.6428 - val_accuracy: 0.6625\n",
            "Epoch 5/200\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.7213 - accuracy: 0.5235 - val_loss: 0.6307 - val_accuracy: 0.6750\n",
            "Epoch 6/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.7054 - accuracy: 0.5502 - val_loss: 0.7031 - val_accuracy: 0.5562\n",
            "Epoch 7/200\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.6925 - accuracy: 0.5188 - val_loss: 0.6521 - val_accuracy: 0.4812\n",
            "Epoch 8/200\n",
            "20/20 [==============================] - 0s 6ms/step - loss: 0.6976 - accuracy: 0.5549 - val_loss: 0.6858 - val_accuracy: 0.4375\n",
            "Epoch 9/200\n",
            "20/20 [==============================] - 0s 6ms/step - loss: 0.6752 - accuracy: 0.5752 - val_loss: 0.6216 - val_accuracy: 0.4938\n",
            "Epoch 10/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.6920 - accuracy: 0.5517 - val_loss: 0.6255 - val_accuracy: 0.4938\n",
            "Epoch 11/200\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.6565 - accuracy: 0.5674 - val_loss: 0.6241 - val_accuracy: 0.4938\n",
            "Epoch 12/200\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.6529 - accuracy: 0.5658 - val_loss: 0.6237 - val_accuracy: 0.4938\n",
            "Epoch 13/200\n",
            "20/20 [==============================] - 0s 6ms/step - loss: 0.6676 - accuracy: 0.5486 - val_loss: 0.6205 - val_accuracy: 0.6750\n",
            "Epoch 14/200\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.6615 - accuracy: 0.5815 - val_loss: 0.6188 - val_accuracy: 0.7125\n",
            "Epoch 15/200\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.6474 - accuracy: 0.5690 - val_loss: 0.6200 - val_accuracy: 0.6750\n",
            "Epoch 16/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.6452 - accuracy: 0.6082 - val_loss: 0.6194 - val_accuracy: 0.6750\n",
            "Epoch 17/200\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.6569 - accuracy: 0.5831 - val_loss: 0.6181 - val_accuracy: 0.6750\n",
            "Epoch 18/200\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.6423 - accuracy: 0.5658 - val_loss: 0.6169 - val_accuracy: 0.6750\n",
            "Epoch 19/200\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.6429 - accuracy: 0.5831 - val_loss: 0.6165 - val_accuracy: 0.6750\n",
            "Epoch 20/200\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.6452 - accuracy: 0.6003 - val_loss: 0.6163 - val_accuracy: 0.6750\n",
            "Epoch 21/200\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.6570 - accuracy: 0.5737 - val_loss: 0.6139 - val_accuracy: 0.5562\n",
            "Epoch 22/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.6445 - accuracy: 0.6113 - val_loss: 0.6110 - val_accuracy: 0.6562\n",
            "Epoch 23/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.6743 - accuracy: 0.5940 - val_loss: 0.6218 - val_accuracy: 0.5250\n",
            "Epoch 24/200\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.6521 - accuracy: 0.6176 - val_loss: 0.6202 - val_accuracy: 0.5312\n",
            "Epoch 25/200\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.6315 - accuracy: 0.6050 - val_loss: 0.6194 - val_accuracy: 0.5125\n",
            "Epoch 26/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.6473 - accuracy: 0.6050 - val_loss: 0.6203 - val_accuracy: 0.5063\n",
            "Epoch 27/200\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.6325 - accuracy: 0.6066 - val_loss: 0.6190 - val_accuracy: 0.5063\n",
            "Epoch 28/200\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.6334 - accuracy: 0.6113 - val_loss: 0.6197 - val_accuracy: 0.5188\n",
            "Epoch 29/200\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.6362 - accuracy: 0.6019 - val_loss: 0.6012 - val_accuracy: 0.6875\n",
            "Epoch 30/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.6339 - accuracy: 0.6364 - val_loss: 0.5884 - val_accuracy: 0.7250\n",
            "Epoch 31/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.6271 - accuracy: 0.6332 - val_loss: 0.6097 - val_accuracy: 0.5500\n",
            "Epoch 32/200\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.6144 - accuracy: 0.6129 - val_loss: 0.6148 - val_accuracy: 0.5188\n",
            "Epoch 33/200\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.6391 - accuracy: 0.6364 - val_loss: 0.5999 - val_accuracy: 0.6625\n",
            "Epoch 34/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.6167 - accuracy: 0.6630 - val_loss: 0.5920 - val_accuracy: 0.7000\n",
            "Epoch 35/200\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.6399 - accuracy: 0.6661 - val_loss: 0.5824 - val_accuracy: 0.7375\n",
            "Epoch 36/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.6122 - accuracy: 0.6850 - val_loss: 0.5773 - val_accuracy: 0.7250\n",
            "Epoch 37/200\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.5870 - accuracy: 0.7085 - val_loss: 0.5656 - val_accuracy: 0.7312\n",
            "Epoch 38/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.6103 - accuracy: 0.6771 - val_loss: 0.5695 - val_accuracy: 0.7312\n",
            "Epoch 39/200\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.5924 - accuracy: 0.6818 - val_loss: 0.5753 - val_accuracy: 0.7063\n",
            "Epoch 40/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.6069 - accuracy: 0.6583 - val_loss: 0.5708 - val_accuracy: 0.7312\n",
            "Epoch 41/200\n",
            "20/20 [==============================] - 0s 6ms/step - loss: 0.5886 - accuracy: 0.6897 - val_loss: 0.5747 - val_accuracy: 0.7125\n",
            "Epoch 42/200\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.5860 - accuracy: 0.6708 - val_loss: 0.5705 - val_accuracy: 0.7437\n",
            "Epoch 43/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.5895 - accuracy: 0.7100 - val_loss: 0.5568 - val_accuracy: 0.7437\n",
            "Epoch 44/200\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.5883 - accuracy: 0.6755 - val_loss: 0.5635 - val_accuracy: 0.7500\n",
            "Epoch 45/200\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.5921 - accuracy: 0.6771 - val_loss: 0.5813 - val_accuracy: 0.6687\n",
            "Epoch 46/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.5807 - accuracy: 0.6944 - val_loss: 0.5830 - val_accuracy: 0.6687\n",
            "Epoch 47/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.5758 - accuracy: 0.6928 - val_loss: 0.5533 - val_accuracy: 0.7312\n",
            "Epoch 48/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.5533 - accuracy: 0.7210 - val_loss: 0.5340 - val_accuracy: 0.7500\n",
            "Epoch 49/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.5705 - accuracy: 0.7210 - val_loss: 0.5395 - val_accuracy: 0.7437\n",
            "Epoch 50/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.5555 - accuracy: 0.7226 - val_loss: 0.5243 - val_accuracy: 0.7625\n",
            "Epoch 51/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.5527 - accuracy: 0.7351 - val_loss: 0.5143 - val_accuracy: 0.7625\n",
            "Epoch 52/200\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.5591 - accuracy: 0.7257 - val_loss: 0.5359 - val_accuracy: 0.7437\n",
            "Epoch 53/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.5735 - accuracy: 0.7038 - val_loss: 0.5581 - val_accuracy: 0.7000\n",
            "Epoch 54/200\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.5307 - accuracy: 0.7398 - val_loss: 0.5183 - val_accuracy: 0.7500\n",
            "Epoch 55/200\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.5522 - accuracy: 0.7445 - val_loss: 0.5072 - val_accuracy: 0.7625\n",
            "Epoch 56/200\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.5589 - accuracy: 0.7351 - val_loss: 0.5372 - val_accuracy: 0.7375\n",
            "Epoch 57/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.5286 - accuracy: 0.7524 - val_loss: 0.5091 - val_accuracy: 0.7812\n",
            "Epoch 58/200\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.5343 - accuracy: 0.7524 - val_loss: 0.5029 - val_accuracy: 0.7875\n",
            "Epoch 59/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.5411 - accuracy: 0.7476 - val_loss: 0.5049 - val_accuracy: 0.7937\n",
            "Epoch 60/200\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.5361 - accuracy: 0.7367 - val_loss: 0.5362 - val_accuracy: 0.7375\n",
            "Epoch 61/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.5158 - accuracy: 0.7586 - val_loss: 0.4777 - val_accuracy: 0.8062\n",
            "Epoch 62/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.5109 - accuracy: 0.7524 - val_loss: 0.4887 - val_accuracy: 0.8125\n",
            "Epoch 63/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.4898 - accuracy: 0.7931 - val_loss: 0.4736 - val_accuracy: 0.8125\n",
            "Epoch 64/200\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.5064 - accuracy: 0.7790 - val_loss: 0.4658 - val_accuracy: 0.8188\n",
            "Epoch 65/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.5064 - accuracy: 0.7602 - val_loss: 0.5111 - val_accuracy: 0.7688\n",
            "Epoch 66/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.4932 - accuracy: 0.7915 - val_loss: 0.4680 - val_accuracy: 0.8250\n",
            "Epoch 67/200\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.5023 - accuracy: 0.7696 - val_loss: 0.4952 - val_accuracy: 0.7688\n",
            "Epoch 68/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.4862 - accuracy: 0.7743 - val_loss: 0.4631 - val_accuracy: 0.8250\n",
            "Epoch 69/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.4858 - accuracy: 0.7774 - val_loss: 0.4726 - val_accuracy: 0.7937\n",
            "Epoch 70/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.4760 - accuracy: 0.7853 - val_loss: 0.4529 - val_accuracy: 0.8375\n",
            "Epoch 71/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.4881 - accuracy: 0.7853 - val_loss: 0.4559 - val_accuracy: 0.8062\n",
            "Epoch 72/200\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.4469 - accuracy: 0.8072 - val_loss: 0.4838 - val_accuracy: 0.7875\n",
            "Epoch 73/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.4726 - accuracy: 0.7774 - val_loss: 0.4277 - val_accuracy: 0.8313\n",
            "Epoch 74/200\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.4652 - accuracy: 0.8103 - val_loss: 0.4497 - val_accuracy: 0.7937\n",
            "Epoch 75/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.4848 - accuracy: 0.7853 - val_loss: 0.4376 - val_accuracy: 0.8313\n",
            "Epoch 76/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.4667 - accuracy: 0.7962 - val_loss: 0.4196 - val_accuracy: 0.8375\n",
            "Epoch 77/200\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.4551 - accuracy: 0.8103 - val_loss: 0.4086 - val_accuracy: 0.8375\n",
            "Epoch 78/200\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.4246 - accuracy: 0.8166 - val_loss: 0.4379 - val_accuracy: 0.8062\n",
            "Epoch 79/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.4257 - accuracy: 0.8276 - val_loss: 0.3980 - val_accuracy: 0.8438\n",
            "Epoch 80/200\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.4304 - accuracy: 0.8307 - val_loss: 0.3969 - val_accuracy: 0.8438\n",
            "Epoch 81/200\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.4361 - accuracy: 0.8119 - val_loss: 0.4208 - val_accuracy: 0.8313\n",
            "Epoch 82/200\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.4391 - accuracy: 0.8197 - val_loss: 0.4110 - val_accuracy: 0.8438\n",
            "Epoch 83/200\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.4405 - accuracy: 0.7978 - val_loss: 0.3975 - val_accuracy: 0.8500\n",
            "Epoch 84/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.4157 - accuracy: 0.8245 - val_loss: 0.4424 - val_accuracy: 0.8250\n",
            "Epoch 85/200\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.4155 - accuracy: 0.8480 - val_loss: 0.3996 - val_accuracy: 0.8375\n",
            "Epoch 86/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.4184 - accuracy: 0.8386 - val_loss: 0.3871 - val_accuracy: 0.8375\n",
            "Epoch 87/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.4176 - accuracy: 0.8307 - val_loss: 0.3852 - val_accuracy: 0.8500\n",
            "Epoch 88/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.3878 - accuracy: 0.8370 - val_loss: 0.3742 - val_accuracy: 0.8562\n",
            "Epoch 89/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.4091 - accuracy: 0.8354 - val_loss: 0.3739 - val_accuracy: 0.8500\n",
            "Epoch 90/200\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.3902 - accuracy: 0.8370 - val_loss: 0.3857 - val_accuracy: 0.8562\n",
            "Epoch 91/200\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.4033 - accuracy: 0.8448 - val_loss: 0.3806 - val_accuracy: 0.8562\n",
            "Epoch 92/200\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.3902 - accuracy: 0.8354 - val_loss: 0.4214 - val_accuracy: 0.8438\n",
            "Epoch 93/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.4011 - accuracy: 0.8339 - val_loss: 0.3757 - val_accuracy: 0.8687\n",
            "Epoch 94/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.3970 - accuracy: 0.8433 - val_loss: 0.4492 - val_accuracy: 0.8375\n",
            "Epoch 95/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.3835 - accuracy: 0.8386 - val_loss: 0.4112 - val_accuracy: 0.8375\n",
            "Epoch 96/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.3617 - accuracy: 0.8464 - val_loss: 0.3615 - val_accuracy: 0.8625\n",
            "Epoch 97/200\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.3834 - accuracy: 0.8354 - val_loss: 0.3632 - val_accuracy: 0.8687\n",
            "Epoch 98/200\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.4053 - accuracy: 0.8386 - val_loss: 0.4048 - val_accuracy: 0.8375\n",
            "Epoch 99/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.3811 - accuracy: 0.8495 - val_loss: 0.3781 - val_accuracy: 0.8687\n",
            "Epoch 100/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.3680 - accuracy: 0.8464 - val_loss: 0.3701 - val_accuracy: 0.8687\n",
            "Epoch 101/200\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.3762 - accuracy: 0.8574 - val_loss: 0.3794 - val_accuracy: 0.8500\n",
            "Epoch 102/200\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.3683 - accuracy: 0.8464 - val_loss: 0.4160 - val_accuracy: 0.8375\n",
            "Epoch 103/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.3540 - accuracy: 0.8480 - val_loss: 0.3738 - val_accuracy: 0.8500\n",
            "Epoch 104/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.3660 - accuracy: 0.8480 - val_loss: 0.3886 - val_accuracy: 0.8375\n",
            "Epoch 105/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.3666 - accuracy: 0.8589 - val_loss: 0.3681 - val_accuracy: 0.8625\n",
            "Epoch 106/200\n",
            "20/20 [==============================] - 0s 6ms/step - loss: 0.3520 - accuracy: 0.8480 - val_loss: 0.3910 - val_accuracy: 0.8313\n",
            "Epoch 107/200\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.3639 - accuracy: 0.8621 - val_loss: 0.3635 - val_accuracy: 0.8562\n",
            "Epoch 108/200\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.3520 - accuracy: 0.8668 - val_loss: 0.3779 - val_accuracy: 0.8500\n",
            "Epoch 109/200\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.3496 - accuracy: 0.8574 - val_loss: 0.4595 - val_accuracy: 0.8062\n",
            "Epoch 110/200\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.3616 - accuracy: 0.8542 - val_loss: 0.3856 - val_accuracy: 0.8438\n",
            "Epoch 111/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.3464 - accuracy: 0.8527 - val_loss: 0.3766 - val_accuracy: 0.8250\n",
            "Epoch 112/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.3500 - accuracy: 0.8589 - val_loss: 0.3824 - val_accuracy: 0.8438\n",
            "Epoch 113/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.3461 - accuracy: 0.8558 - val_loss: 0.3512 - val_accuracy: 0.8687\n",
            "Epoch 114/200\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.3514 - accuracy: 0.8589 - val_loss: 0.3525 - val_accuracy: 0.8562\n",
            "Epoch 115/200\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.3457 - accuracy: 0.8589 - val_loss: 0.3508 - val_accuracy: 0.8875\n",
            "Epoch 116/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.3531 - accuracy: 0.8464 - val_loss: 0.3681 - val_accuracy: 0.8625\n",
            "Epoch 117/200\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.3425 - accuracy: 0.8605 - val_loss: 0.3567 - val_accuracy: 0.8562\n",
            "Epoch 118/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.3450 - accuracy: 0.8636 - val_loss: 0.3459 - val_accuracy: 0.8687\n",
            "Epoch 119/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.3351 - accuracy: 0.8605 - val_loss: 0.3963 - val_accuracy: 0.8375\n",
            "Epoch 120/200\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.3410 - accuracy: 0.8527 - val_loss: 0.3524 - val_accuracy: 0.8687\n",
            "Epoch 121/200\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.3498 - accuracy: 0.8589 - val_loss: 0.3639 - val_accuracy: 0.8562\n",
            "Epoch 122/200\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.3431 - accuracy: 0.8621 - val_loss: 0.4200 - val_accuracy: 0.8313\n",
            "Epoch 123/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.3210 - accuracy: 0.8699 - val_loss: 0.4009 - val_accuracy: 0.8313\n",
            "Epoch 124/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.3065 - accuracy: 0.8856 - val_loss: 0.3636 - val_accuracy: 0.8625\n",
            "Epoch 125/200\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.3464 - accuracy: 0.8730 - val_loss: 0.3411 - val_accuracy: 0.8750\n",
            "Epoch 126/200\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.3639 - accuracy: 0.8605 - val_loss: 0.3383 - val_accuracy: 0.8875\n",
            "Epoch 127/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.3436 - accuracy: 0.8605 - val_loss: 0.3723 - val_accuracy: 0.8625\n",
            "Epoch 128/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.3464 - accuracy: 0.8542 - val_loss: 0.4011 - val_accuracy: 0.8250\n",
            "Epoch 129/200\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.3340 - accuracy: 0.8558 - val_loss: 0.3905 - val_accuracy: 0.8313\n",
            "Epoch 130/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.3307 - accuracy: 0.8542 - val_loss: 0.3564 - val_accuracy: 0.8813\n",
            "Epoch 131/200\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.3284 - accuracy: 0.8668 - val_loss: 0.4099 - val_accuracy: 0.8125\n",
            "Epoch 132/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.3372 - accuracy: 0.8652 - val_loss: 0.3821 - val_accuracy: 0.8500\n",
            "Epoch 133/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.3391 - accuracy: 0.8605 - val_loss: 0.3577 - val_accuracy: 0.8625\n",
            "Epoch 134/200\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.3050 - accuracy: 0.8840 - val_loss: 0.4090 - val_accuracy: 0.8250\n",
            "Epoch 135/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.3169 - accuracy: 0.8699 - val_loss: 0.3985 - val_accuracy: 0.8313\n",
            "Epoch 136/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.3428 - accuracy: 0.8542 - val_loss: 0.4556 - val_accuracy: 0.8062\n",
            "Epoch 137/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.3404 - accuracy: 0.8683 - val_loss: 0.3882 - val_accuracy: 0.8438\n",
            "Epoch 138/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.3417 - accuracy: 0.8668 - val_loss: 0.3546 - val_accuracy: 0.8813\n",
            "Epoch 139/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.3436 - accuracy: 0.8605 - val_loss: 0.4166 - val_accuracy: 0.8125\n",
            "Epoch 140/200\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.3232 - accuracy: 0.8777 - val_loss: 0.4415 - val_accuracy: 0.8313\n",
            "Epoch 141/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.3387 - accuracy: 0.8668 - val_loss: 0.3812 - val_accuracy: 0.8500\n",
            "Epoch 142/200\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.3046 - accuracy: 0.8824 - val_loss: 0.3854 - val_accuracy: 0.8562\n",
            "Epoch 143/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.3285 - accuracy: 0.8730 - val_loss: 0.4295 - val_accuracy: 0.8125\n",
            "Epoch 144/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.3221 - accuracy: 0.8746 - val_loss: 0.3728 - val_accuracy: 0.8438\n",
            "Epoch 145/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.3148 - accuracy: 0.8856 - val_loss: 0.4413 - val_accuracy: 0.8188\n",
            "Epoch 146/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.3208 - accuracy: 0.8793 - val_loss: 0.3882 - val_accuracy: 0.8375\n",
            "Epoch 147/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.3101 - accuracy: 0.8777 - val_loss: 0.3541 - val_accuracy: 0.8687\n",
            "Epoch 148/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.3222 - accuracy: 0.8715 - val_loss: 0.3686 - val_accuracy: 0.8625\n",
            "Epoch 149/200\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.3063 - accuracy: 0.8668 - val_loss: 0.3868 - val_accuracy: 0.8500\n",
            "Epoch 150/200\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.3237 - accuracy: 0.8777 - val_loss: 0.3933 - val_accuracy: 0.8500\n",
            "Epoch 151/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.3229 - accuracy: 0.8683 - val_loss: 0.4058 - val_accuracy: 0.8188\n",
            "Epoch 152/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.3192 - accuracy: 0.8730 - val_loss: 0.4441 - val_accuracy: 0.8062\n",
            "Epoch 153/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.3166 - accuracy: 0.8589 - val_loss: 0.3641 - val_accuracy: 0.8750\n",
            "Epoch 154/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.3260 - accuracy: 0.8715 - val_loss: 0.3631 - val_accuracy: 0.8313\n",
            "Epoch 155/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.3091 - accuracy: 0.8715 - val_loss: 0.3927 - val_accuracy: 0.8313\n",
            "Epoch 156/200\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.3059 - accuracy: 0.8746 - val_loss: 0.4309 - val_accuracy: 0.8000\n",
            "Epoch 157/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.3264 - accuracy: 0.8746 - val_loss: 0.3612 - val_accuracy: 0.8562\n",
            "Epoch 158/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.3116 - accuracy: 0.8824 - val_loss: 0.3645 - val_accuracy: 0.8687\n",
            "Epoch 159/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.3006 - accuracy: 0.8777 - val_loss: 0.3863 - val_accuracy: 0.8375\n",
            "Epoch 160/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.3041 - accuracy: 0.8762 - val_loss: 0.3830 - val_accuracy: 0.8438\n",
            "Epoch 161/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.2891 - accuracy: 0.8809 - val_loss: 0.3984 - val_accuracy: 0.8375\n",
            "Epoch 162/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.3147 - accuracy: 0.8809 - val_loss: 0.3767 - val_accuracy: 0.8562\n",
            "Epoch 163/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.3121 - accuracy: 0.8730 - val_loss: 0.4111 - val_accuracy: 0.8438\n",
            "Epoch 164/200\n",
            "20/20 [==============================] - 0s 6ms/step - loss: 0.2979 - accuracy: 0.8777 - val_loss: 0.3741 - val_accuracy: 0.8500\n",
            "Epoch 165/200\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.3028 - accuracy: 0.8777 - val_loss: 0.4163 - val_accuracy: 0.8125\n",
            "Epoch 166/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.3107 - accuracy: 0.8730 - val_loss: 0.3786 - val_accuracy: 0.8438\n",
            "Epoch 167/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.3099 - accuracy: 0.8856 - val_loss: 0.4528 - val_accuracy: 0.8062\n",
            "Epoch 168/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.2948 - accuracy: 0.8746 - val_loss: 0.3837 - val_accuracy: 0.8438\n",
            "Epoch 169/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.3018 - accuracy: 0.8918 - val_loss: 0.3645 - val_accuracy: 0.8562\n",
            "Epoch 170/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.3043 - accuracy: 0.8746 - val_loss: 0.4097 - val_accuracy: 0.8500\n",
            "Epoch 171/200\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.2906 - accuracy: 0.8840 - val_loss: 0.3735 - val_accuracy: 0.8687\n",
            "Epoch 172/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.3041 - accuracy: 0.8809 - val_loss: 0.4139 - val_accuracy: 0.8188\n",
            "Epoch 173/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.3074 - accuracy: 0.8652 - val_loss: 0.4587 - val_accuracy: 0.7875\n",
            "Epoch 174/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.3186 - accuracy: 0.8636 - val_loss: 0.3827 - val_accuracy: 0.8562\n",
            "Epoch 175/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.2917 - accuracy: 0.8699 - val_loss: 0.3679 - val_accuracy: 0.8687\n",
            "Epoch 176/200\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.3053 - accuracy: 0.8793 - val_loss: 0.3738 - val_accuracy: 0.8438\n",
            "Epoch 177/200\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.2907 - accuracy: 0.8840 - val_loss: 0.4039 - val_accuracy: 0.8250\n",
            "Epoch 178/200\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.2946 - accuracy: 0.8762 - val_loss: 0.4132 - val_accuracy: 0.8062\n",
            "Epoch 179/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.2919 - accuracy: 0.8824 - val_loss: 0.3916 - val_accuracy: 0.8562\n",
            "Epoch 180/200\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.3180 - accuracy: 0.8715 - val_loss: 0.4402 - val_accuracy: 0.7937\n",
            "Epoch 181/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.3031 - accuracy: 0.8715 - val_loss: 0.3891 - val_accuracy: 0.8375\n",
            "Epoch 182/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.2911 - accuracy: 0.8824 - val_loss: 0.4160 - val_accuracy: 0.8438\n",
            "Epoch 183/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.3049 - accuracy: 0.8809 - val_loss: 0.4109 - val_accuracy: 0.8375\n",
            "Epoch 184/200\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.3007 - accuracy: 0.8793 - val_loss: 0.3644 - val_accuracy: 0.8625\n",
            "Epoch 185/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.3072 - accuracy: 0.8793 - val_loss: 0.4078 - val_accuracy: 0.8438\n",
            "Epoch 186/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.3052 - accuracy: 0.8730 - val_loss: 0.4670 - val_accuracy: 0.8062\n",
            "Epoch 187/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.2990 - accuracy: 0.8824 - val_loss: 0.3843 - val_accuracy: 0.8625\n",
            "Epoch 188/200\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.2997 - accuracy: 0.8809 - val_loss: 0.3813 - val_accuracy: 0.8562\n",
            "Epoch 189/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.2965 - accuracy: 0.8730 - val_loss: 0.4386 - val_accuracy: 0.8062\n",
            "Epoch 190/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.2898 - accuracy: 0.8715 - val_loss: 0.3969 - val_accuracy: 0.8562\n",
            "Epoch 191/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.2848 - accuracy: 0.8793 - val_loss: 0.4522 - val_accuracy: 0.8062\n",
            "Epoch 192/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.2902 - accuracy: 0.8777 - val_loss: 0.3974 - val_accuracy: 0.8625\n",
            "Epoch 193/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.2948 - accuracy: 0.8793 - val_loss: 0.4103 - val_accuracy: 0.8375\n",
            "Epoch 194/200\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.2867 - accuracy: 0.8824 - val_loss: 0.4228 - val_accuracy: 0.8188\n",
            "Epoch 195/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.2782 - accuracy: 0.8840 - val_loss: 0.4318 - val_accuracy: 0.8313\n",
            "Epoch 196/200\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.2874 - accuracy: 0.8793 - val_loss: 0.3720 - val_accuracy: 0.8625\n",
            "Epoch 197/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.2873 - accuracy: 0.8824 - val_loss: 0.4475 - val_accuracy: 0.8000\n",
            "Epoch 198/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.3017 - accuracy: 0.8840 - val_loss: 0.4236 - val_accuracy: 0.8188\n",
            "Epoch 199/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.2811 - accuracy: 0.8824 - val_loss: 0.4387 - val_accuracy: 0.8188\n",
            "Epoch 200/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.2944 - accuracy: 0.8746 - val_loss: 0.4150 - val_accuracy: 0.8250\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 0.4095 - accuracy: 0.8583\n",
            "## evaluation loss and_metrics ##\n",
            "[0.40950456261634827, 0.8583333492279053]\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "0.9142857142857143\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "ST_Slope_Down"
      ],
      "metadata": {
        "id": "SXrJSjGnrIhV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "heart = pd.read_csv(f_path)\n",
        "\n",
        "heart = pd.get_dummies(heart)\n",
        "\n",
        "x = heart.drop('HeartDisease', axis=1)\n",
        "y = pd.get_dummies(heart[\"HeartDisease\"])\n",
        "\n",
        "heart['ST_Slope_Down'] = 0\n",
        "\n",
        "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size = 0.13,shuffle=True, random_state = 42)\n",
        "\n",
        "print(\"X_train: \", x_train.shape)\n",
        "print(\"y_train: \", y_train.shape)\n",
        "\n",
        "print(\"X_test: \", x_test.shape)\n",
        "print(\"y_test: \", y_test.shape)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "ModelExceptST_Slope_Down = Sequential()\n",
        "\n",
        "\n",
        "ModelExceptST_Slope_Down.add(Dense(128, activation = \"relu\",input_dim=20))\n",
        "ModelExceptST_Slope_Down.add(Dropout(rate=0.2))\n",
        "ModelExceptST_Slope_Down.add(Dense(64, activation = \"relu\"))\n",
        "ModelExceptST_Slope_Down.add(Dropout(rate=0.2))\n",
        "ModelExceptST_Slope_Down.add(Dense(32, activation = \"relu\"))\n",
        "ModelExceptST_Slope_Down.add(Dropout(rate=0.1))\n",
        "ModelExceptST_Slope_Down.add(Dense(16, activation = \"relu\"))\n",
        "ModelExceptST_Slope_Down.add(Dense(8, activation = \"relu\"))\n",
        "ModelExceptST_Slope_Down.add(Dense(2, activation = \"sigmoid\"))\n",
        "\n",
        "ModelExceptST_Slope_Down.compile(optimizer = \"adam\", loss = \"categorical_crossentropy\", metrics = [\"accuracy\"])\n",
        "ModelExceptST_Slope_Down.summary()\n",
        "\n",
        "hin=ModelExceptST_Slope_Down.fit(x_train,y_train,epochs=200, validation_split=0.2)\n",
        "\n",
        "loss_and_metrics = ModelExceptST_Slope_Down.evaluate(x_test, y_test, batch_size=32)\n",
        "print('## evaluation loss and_metrics ##')\n",
        "print(loss_and_metrics)\n",
        "\n",
        "y_predST_Slope_Down = ModelExceptST_Slope_Down.predict(x_test)\n",
        "y_predST_Slope_Down\n",
        "\n",
        "y_pred_classST_Slope_Down = np.argmax(y_predST_Slope_Down, axis=1)\n",
        "y_pred_classST_Slope_Down\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "y_test  = y_test.to_numpy()\n",
        "y_test\n",
        "\n",
        "y_test = np.argmax(y_test,axis=1)\n",
        "y_test\n",
        "\n",
        "np.mean(y_test == y_pred_classST_Slope_Down)\n",
        "ST_Slope_Downscore=recall_score(y_test,y_pred_classST_Slope_Down)\n",
        "print(ST_Slope_Downscore)"
      ],
      "metadata": {
        "id": "ThHbd_npzAk4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "64d6bda3-1537-4cc3-83ab-161d723b4a47"
      },
      "execution_count": 100,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "X_train:  (798, 20)\n",
            "y_train:  (798, 2)\n",
            "X_test:  (120, 20)\n",
            "y_test:  (120, 2)\n",
            "Model: \"sequential_22\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense_132 (Dense)           (None, 128)               2688      \n",
            "                                                                 \n",
            " dropout_66 (Dropout)        (None, 128)               0         \n",
            "                                                                 \n",
            " dense_133 (Dense)           (None, 64)                8256      \n",
            "                                                                 \n",
            " dropout_67 (Dropout)        (None, 64)                0         \n",
            "                                                                 \n",
            " dense_134 (Dense)           (None, 32)                2080      \n",
            "                                                                 \n",
            " dropout_68 (Dropout)        (None, 32)                0         \n",
            "                                                                 \n",
            " dense_135 (Dense)           (None, 16)                528       \n",
            "                                                                 \n",
            " dense_136 (Dense)           (None, 8)                 136       \n",
            "                                                                 \n",
            " dense_137 (Dense)           (None, 2)                 18        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 13,706\n",
            "Trainable params: 13,706\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/200\n",
            "20/20 [==============================] - 1s 12ms/step - loss: 2.2679 - accuracy: 0.5455 - val_loss: 0.7103 - val_accuracy: 0.4688\n",
            "Epoch 2/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 1.0261 - accuracy: 0.5125 - val_loss: 0.6388 - val_accuracy: 0.6687\n",
            "Epoch 3/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.8369 - accuracy: 0.5721 - val_loss: 0.9110 - val_accuracy: 0.4938\n",
            "Epoch 4/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.8670 - accuracy: 0.5752 - val_loss: 0.6986 - val_accuracy: 0.4750\n",
            "Epoch 5/200\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.7705 - accuracy: 0.5768 - val_loss: 0.6633 - val_accuracy: 0.4938\n",
            "Epoch 6/200\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.7585 - accuracy: 0.5643 - val_loss: 0.6082 - val_accuracy: 0.6687\n",
            "Epoch 7/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.7417 - accuracy: 0.5643 - val_loss: 0.6394 - val_accuracy: 0.5938\n",
            "Epoch 8/200\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.7461 - accuracy: 0.5533 - val_loss: 0.6887 - val_accuracy: 0.4938\n",
            "Epoch 9/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.7231 - accuracy: 0.5768 - val_loss: 0.6464 - val_accuracy: 0.6438\n",
            "Epoch 10/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.6936 - accuracy: 0.5768 - val_loss: 0.6443 - val_accuracy: 0.6438\n",
            "Epoch 11/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.7068 - accuracy: 0.5909 - val_loss: 0.6442 - val_accuracy: 0.4625\n",
            "Epoch 12/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.7139 - accuracy: 0.5580 - val_loss: 0.6115 - val_accuracy: 0.6875\n",
            "Epoch 13/200\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.6755 - accuracy: 0.6034 - val_loss: 0.6160 - val_accuracy: 0.6500\n",
            "Epoch 14/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.6686 - accuracy: 0.6082 - val_loss: 0.6062 - val_accuracy: 0.6750\n",
            "Epoch 15/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.6981 - accuracy: 0.5925 - val_loss: 0.5776 - val_accuracy: 0.7250\n",
            "Epoch 16/200\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.6828 - accuracy: 0.5878 - val_loss: 0.5593 - val_accuracy: 0.7250\n",
            "Epoch 17/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.6693 - accuracy: 0.5940 - val_loss: 0.6107 - val_accuracy: 0.7000\n",
            "Epoch 18/200\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.6630 - accuracy: 0.6254 - val_loss: 0.6110 - val_accuracy: 0.6062\n",
            "Epoch 19/200\n",
            "20/20 [==============================] - 0s 6ms/step - loss: 0.6515 - accuracy: 0.6301 - val_loss: 0.5994 - val_accuracy: 0.7125\n",
            "Epoch 20/200\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.6469 - accuracy: 0.6129 - val_loss: 0.5782 - val_accuracy: 0.7500\n",
            "Epoch 21/200\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.6469 - accuracy: 0.6191 - val_loss: 0.5924 - val_accuracy: 0.7563\n",
            "Epoch 22/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.6444 - accuracy: 0.6520 - val_loss: 0.5563 - val_accuracy: 0.7312\n",
            "Epoch 23/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.6606 - accuracy: 0.6034 - val_loss: 0.5809 - val_accuracy: 0.7188\n",
            "Epoch 24/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.6343 - accuracy: 0.6238 - val_loss: 0.5806 - val_accuracy: 0.6875\n",
            "Epoch 25/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.6215 - accuracy: 0.6771 - val_loss: 0.6090 - val_accuracy: 0.6375\n",
            "Epoch 26/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.6284 - accuracy: 0.6364 - val_loss: 0.5732 - val_accuracy: 0.7188\n",
            "Epoch 27/200\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.5910 - accuracy: 0.6928 - val_loss: 0.5712 - val_accuracy: 0.7250\n",
            "Epoch 28/200\n",
            "20/20 [==============================] - 0s 8ms/step - loss: 0.6346 - accuracy: 0.6583 - val_loss: 0.5581 - val_accuracy: 0.6812\n",
            "Epoch 29/200\n",
            "20/20 [==============================] - 0s 11ms/step - loss: 0.5949 - accuracy: 0.6928 - val_loss: 0.5412 - val_accuracy: 0.7437\n",
            "Epoch 30/200\n",
            "20/20 [==============================] - 0s 7ms/step - loss: 0.5894 - accuracy: 0.6724 - val_loss: 0.5834 - val_accuracy: 0.6375\n",
            "Epoch 31/200\n",
            "20/20 [==============================] - 0s 11ms/step - loss: 0.6149 - accuracy: 0.6693 - val_loss: 0.5492 - val_accuracy: 0.7625\n",
            "Epoch 32/200\n",
            "20/20 [==============================] - 0s 11ms/step - loss: 0.6059 - accuracy: 0.6661 - val_loss: 0.5645 - val_accuracy: 0.7563\n",
            "Epoch 33/200\n",
            "20/20 [==============================] - 0s 7ms/step - loss: 0.5854 - accuracy: 0.6881 - val_loss: 0.5647 - val_accuracy: 0.7500\n",
            "Epoch 34/200\n",
            "20/20 [==============================] - 0s 7ms/step - loss: 0.5946 - accuracy: 0.6897 - val_loss: 0.5493 - val_accuracy: 0.7688\n",
            "Epoch 35/200\n",
            "20/20 [==============================] - 0s 6ms/step - loss: 0.5770 - accuracy: 0.6850 - val_loss: 0.5511 - val_accuracy: 0.7625\n",
            "Epoch 36/200\n",
            "20/20 [==============================] - 0s 7ms/step - loss: 0.5633 - accuracy: 0.7571 - val_loss: 0.5106 - val_accuracy: 0.7625\n",
            "Epoch 37/200\n",
            "20/20 [==============================] - 0s 7ms/step - loss: 0.5864 - accuracy: 0.6991 - val_loss: 0.5388 - val_accuracy: 0.7500\n",
            "Epoch 38/200\n",
            "20/20 [==============================] - 0s 7ms/step - loss: 0.5732 - accuracy: 0.7273 - val_loss: 0.5416 - val_accuracy: 0.7625\n",
            "Epoch 39/200\n",
            "20/20 [==============================] - 0s 6ms/step - loss: 0.5749 - accuracy: 0.6928 - val_loss: 0.5451 - val_accuracy: 0.7250\n",
            "Epoch 40/200\n",
            "20/20 [==============================] - 0s 6ms/step - loss: 0.5613 - accuracy: 0.7320 - val_loss: 0.5032 - val_accuracy: 0.7500\n",
            "Epoch 41/200\n",
            "20/20 [==============================] - 0s 6ms/step - loss: 0.5768 - accuracy: 0.7210 - val_loss: 0.5076 - val_accuracy: 0.7688\n",
            "Epoch 42/200\n",
            "20/20 [==============================] - 0s 7ms/step - loss: 0.5584 - accuracy: 0.7163 - val_loss: 0.5073 - val_accuracy: 0.7750\n",
            "Epoch 43/200\n",
            "20/20 [==============================] - 0s 7ms/step - loss: 0.5637 - accuracy: 0.7257 - val_loss: 0.5253 - val_accuracy: 0.7500\n",
            "Epoch 44/200\n",
            "20/20 [==============================] - 0s 7ms/step - loss: 0.5662 - accuracy: 0.7445 - val_loss: 0.5205 - val_accuracy: 0.7437\n",
            "Epoch 45/200\n",
            "20/20 [==============================] - 0s 6ms/step - loss: 0.5462 - accuracy: 0.7524 - val_loss: 0.5172 - val_accuracy: 0.7688\n",
            "Epoch 46/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.5659 - accuracy: 0.7179 - val_loss: 0.5238 - val_accuracy: 0.7500\n",
            "Epoch 47/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.5479 - accuracy: 0.7367 - val_loss: 0.5165 - val_accuracy: 0.7312\n",
            "Epoch 48/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.5377 - accuracy: 0.7492 - val_loss: 0.5346 - val_accuracy: 0.7437\n",
            "Epoch 49/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.5488 - accuracy: 0.7445 - val_loss: 0.5047 - val_accuracy: 0.7812\n",
            "Epoch 50/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.5125 - accuracy: 0.7555 - val_loss: 0.4884 - val_accuracy: 0.7812\n",
            "Epoch 51/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.5189 - accuracy: 0.7555 - val_loss: 0.5134 - val_accuracy: 0.7437\n",
            "Epoch 52/200\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.5507 - accuracy: 0.7414 - val_loss: 0.4836 - val_accuracy: 0.7937\n",
            "Epoch 53/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.5120 - accuracy: 0.7633 - val_loss: 0.4785 - val_accuracy: 0.7937\n",
            "Epoch 54/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.5271 - accuracy: 0.7633 - val_loss: 0.4978 - val_accuracy: 0.7812\n",
            "Epoch 55/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.5174 - accuracy: 0.7774 - val_loss: 0.4860 - val_accuracy: 0.7937\n",
            "Epoch 56/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.5049 - accuracy: 0.7696 - val_loss: 0.4816 - val_accuracy: 0.7812\n",
            "Epoch 57/200\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.5167 - accuracy: 0.7602 - val_loss: 0.4716 - val_accuracy: 0.8000\n",
            "Epoch 58/200\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.5027 - accuracy: 0.7727 - val_loss: 0.4838 - val_accuracy: 0.7812\n",
            "Epoch 59/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.4983 - accuracy: 0.7665 - val_loss: 0.4803 - val_accuracy: 0.7875\n",
            "Epoch 60/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.5069 - accuracy: 0.7759 - val_loss: 0.4731 - val_accuracy: 0.8000\n",
            "Epoch 61/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.4876 - accuracy: 0.7931 - val_loss: 0.4716 - val_accuracy: 0.7875\n",
            "Epoch 62/200\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.4668 - accuracy: 0.7884 - val_loss: 0.4714 - val_accuracy: 0.7875\n",
            "Epoch 63/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.4778 - accuracy: 0.7868 - val_loss: 0.4559 - val_accuracy: 0.8250\n",
            "Epoch 64/200\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.4764 - accuracy: 0.7853 - val_loss: 0.4464 - val_accuracy: 0.8188\n",
            "Epoch 65/200\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.4827 - accuracy: 0.7790 - val_loss: 0.4401 - val_accuracy: 0.8188\n",
            "Epoch 66/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.4734 - accuracy: 0.7947 - val_loss: 0.4452 - val_accuracy: 0.8188\n",
            "Epoch 67/200\n",
            "20/20 [==============================] - 0s 6ms/step - loss: 0.4754 - accuracy: 0.8088 - val_loss: 0.4789 - val_accuracy: 0.7812\n",
            "Epoch 68/200\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.4772 - accuracy: 0.8088 - val_loss: 0.4254 - val_accuracy: 0.8438\n",
            "Epoch 69/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.4529 - accuracy: 0.8119 - val_loss: 0.4393 - val_accuracy: 0.7937\n",
            "Epoch 70/200\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.4606 - accuracy: 0.8072 - val_loss: 0.4573 - val_accuracy: 0.7625\n",
            "Epoch 71/200\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.4499 - accuracy: 0.8197 - val_loss: 0.4428 - val_accuracy: 0.7937\n",
            "Epoch 72/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.4470 - accuracy: 0.8213 - val_loss: 0.4345 - val_accuracy: 0.8188\n",
            "Epoch 73/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.4307 - accuracy: 0.8135 - val_loss: 0.4431 - val_accuracy: 0.7937\n",
            "Epoch 74/200\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.4232 - accuracy: 0.8229 - val_loss: 0.4124 - val_accuracy: 0.8313\n",
            "Epoch 75/200\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.4436 - accuracy: 0.7994 - val_loss: 0.4068 - val_accuracy: 0.8438\n",
            "Epoch 76/200\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.4293 - accuracy: 0.8135 - val_loss: 0.4226 - val_accuracy: 0.8125\n",
            "Epoch 77/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.4348 - accuracy: 0.8182 - val_loss: 0.4088 - val_accuracy: 0.8250\n",
            "Epoch 78/200\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.4066 - accuracy: 0.8339 - val_loss: 0.3924 - val_accuracy: 0.8438\n",
            "Epoch 79/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.4135 - accuracy: 0.8323 - val_loss: 0.4009 - val_accuracy: 0.8313\n",
            "Epoch 80/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.4126 - accuracy: 0.8307 - val_loss: 0.3954 - val_accuracy: 0.8313\n",
            "Epoch 81/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.4002 - accuracy: 0.8307 - val_loss: 0.3820 - val_accuracy: 0.8438\n",
            "Epoch 82/200\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.4103 - accuracy: 0.8245 - val_loss: 0.3708 - val_accuracy: 0.8500\n",
            "Epoch 83/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.4047 - accuracy: 0.8307 - val_loss: 0.3748 - val_accuracy: 0.8625\n",
            "Epoch 84/200\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.4051 - accuracy: 0.8354 - val_loss: 0.4310 - val_accuracy: 0.8313\n",
            "Epoch 85/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.3855 - accuracy: 0.8276 - val_loss: 0.3937 - val_accuracy: 0.8500\n",
            "Epoch 86/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.3721 - accuracy: 0.8558 - val_loss: 0.3560 - val_accuracy: 0.8687\n",
            "Epoch 87/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.3672 - accuracy: 0.8480 - val_loss: 0.3769 - val_accuracy: 0.8687\n",
            "Epoch 88/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.4000 - accuracy: 0.8370 - val_loss: 0.3634 - val_accuracy: 0.8562\n",
            "Epoch 89/200\n",
            "20/20 [==============================] - 0s 6ms/step - loss: 0.3892 - accuracy: 0.8370 - val_loss: 0.3685 - val_accuracy: 0.8562\n",
            "Epoch 90/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.4027 - accuracy: 0.8276 - val_loss: 0.3736 - val_accuracy: 0.8562\n",
            "Epoch 91/200\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.3670 - accuracy: 0.8527 - val_loss: 0.4243 - val_accuracy: 0.8375\n",
            "Epoch 92/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.3567 - accuracy: 0.8574 - val_loss: 0.3885 - val_accuracy: 0.8562\n",
            "Epoch 93/200\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.3498 - accuracy: 0.8589 - val_loss: 0.3638 - val_accuracy: 0.8562\n",
            "Epoch 94/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.3512 - accuracy: 0.8636 - val_loss: 0.3521 - val_accuracy: 0.8750\n",
            "Epoch 95/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.3825 - accuracy: 0.8370 - val_loss: 0.3508 - val_accuracy: 0.8625\n",
            "Epoch 96/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.3511 - accuracy: 0.8511 - val_loss: 0.3724 - val_accuracy: 0.8625\n",
            "Epoch 97/200\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.3665 - accuracy: 0.8480 - val_loss: 0.3982 - val_accuracy: 0.8438\n",
            "Epoch 98/200\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.3376 - accuracy: 0.8683 - val_loss: 0.4111 - val_accuracy: 0.8375\n",
            "Epoch 99/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.3546 - accuracy: 0.8636 - val_loss: 0.3695 - val_accuracy: 0.8500\n",
            "Epoch 100/200\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.3356 - accuracy: 0.8605 - val_loss: 0.3612 - val_accuracy: 0.8687\n",
            "Epoch 101/200\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.3464 - accuracy: 0.8605 - val_loss: 0.3902 - val_accuracy: 0.8500\n",
            "Epoch 102/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.3494 - accuracy: 0.8652 - val_loss: 0.3589 - val_accuracy: 0.8813\n",
            "Epoch 103/200\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.3436 - accuracy: 0.8511 - val_loss: 0.3663 - val_accuracy: 0.8687\n",
            "Epoch 104/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.3766 - accuracy: 0.8527 - val_loss: 0.3514 - val_accuracy: 0.8750\n",
            "Epoch 105/200\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.3617 - accuracy: 0.8386 - val_loss: 0.3674 - val_accuracy: 0.8562\n",
            "Epoch 106/200\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.3576 - accuracy: 0.8589 - val_loss: 0.3827 - val_accuracy: 0.8375\n",
            "Epoch 107/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.3393 - accuracy: 0.8527 - val_loss: 0.3869 - val_accuracy: 0.8500\n",
            "Epoch 108/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.3300 - accuracy: 0.8605 - val_loss: 0.3505 - val_accuracy: 0.8750\n",
            "Epoch 109/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.3326 - accuracy: 0.8809 - val_loss: 0.3510 - val_accuracy: 0.8813\n",
            "Epoch 110/200\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.3564 - accuracy: 0.8652 - val_loss: 0.3829 - val_accuracy: 0.8375\n",
            "Epoch 111/200\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.3490 - accuracy: 0.8574 - val_loss: 0.4190 - val_accuracy: 0.8125\n",
            "Epoch 112/200\n",
            "20/20 [==============================] - 0s 6ms/step - loss: 0.3407 - accuracy: 0.8480 - val_loss: 0.3830 - val_accuracy: 0.8313\n",
            "Epoch 113/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.3346 - accuracy: 0.8668 - val_loss: 0.3674 - val_accuracy: 0.8562\n",
            "Epoch 114/200\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.3141 - accuracy: 0.8730 - val_loss: 0.3569 - val_accuracy: 0.8750\n",
            "Epoch 115/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.3295 - accuracy: 0.8636 - val_loss: 0.3902 - val_accuracy: 0.8438\n",
            "Epoch 116/200\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.3412 - accuracy: 0.8652 - val_loss: 0.3875 - val_accuracy: 0.8500\n",
            "Epoch 117/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.3260 - accuracy: 0.8621 - val_loss: 0.3659 - val_accuracy: 0.8500\n",
            "Epoch 118/200\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.3253 - accuracy: 0.8652 - val_loss: 0.4173 - val_accuracy: 0.8250\n",
            "Epoch 119/200\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.3279 - accuracy: 0.8574 - val_loss: 0.4286 - val_accuracy: 0.8250\n",
            "Epoch 120/200\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.3345 - accuracy: 0.8668 - val_loss: 0.4380 - val_accuracy: 0.8062\n",
            "Epoch 121/200\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.3442 - accuracy: 0.8527 - val_loss: 0.3662 - val_accuracy: 0.8562\n",
            "Epoch 122/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.3384 - accuracy: 0.8636 - val_loss: 0.3977 - val_accuracy: 0.8250\n",
            "Epoch 123/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.3292 - accuracy: 0.8636 - val_loss: 0.3497 - val_accuracy: 0.8687\n",
            "Epoch 124/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.3153 - accuracy: 0.8636 - val_loss: 0.3752 - val_accuracy: 0.8500\n",
            "Epoch 125/200\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.3076 - accuracy: 0.8683 - val_loss: 0.3683 - val_accuracy: 0.8625\n",
            "Epoch 126/200\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.3297 - accuracy: 0.8621 - val_loss: 0.3741 - val_accuracy: 0.8438\n",
            "Epoch 127/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.3210 - accuracy: 0.8668 - val_loss: 0.3587 - val_accuracy: 0.8562\n",
            "Epoch 128/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.3341 - accuracy: 0.8511 - val_loss: 0.4012 - val_accuracy: 0.8438\n",
            "Epoch 129/200\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.3161 - accuracy: 0.8730 - val_loss: 0.3782 - val_accuracy: 0.8438\n",
            "Epoch 130/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.3259 - accuracy: 0.8715 - val_loss: 0.3821 - val_accuracy: 0.8313\n",
            "Epoch 131/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.3149 - accuracy: 0.8730 - val_loss: 0.4281 - val_accuracy: 0.8125\n",
            "Epoch 132/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.3388 - accuracy: 0.8652 - val_loss: 0.3667 - val_accuracy: 0.8750\n",
            "Epoch 133/200\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.3185 - accuracy: 0.8621 - val_loss: 0.3570 - val_accuracy: 0.8750\n",
            "Epoch 134/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.3168 - accuracy: 0.8746 - val_loss: 0.4156 - val_accuracy: 0.8188\n",
            "Epoch 135/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.3187 - accuracy: 0.8762 - val_loss: 0.3503 - val_accuracy: 0.8813\n",
            "Epoch 136/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.3341 - accuracy: 0.8746 - val_loss: 0.3572 - val_accuracy: 0.8687\n",
            "Epoch 137/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.3145 - accuracy: 0.8746 - val_loss: 0.3818 - val_accuracy: 0.8562\n",
            "Epoch 138/200\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.2935 - accuracy: 0.8856 - val_loss: 0.4649 - val_accuracy: 0.8125\n",
            "Epoch 139/200\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.3154 - accuracy: 0.8840 - val_loss: 0.4263 - val_accuracy: 0.8125\n",
            "Epoch 140/200\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.3306 - accuracy: 0.8699 - val_loss: 0.3853 - val_accuracy: 0.8375\n",
            "Epoch 141/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.3053 - accuracy: 0.8809 - val_loss: 0.3625 - val_accuracy: 0.8625\n",
            "Epoch 142/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.3327 - accuracy: 0.8621 - val_loss: 0.3763 - val_accuracy: 0.8438\n",
            "Epoch 143/200\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.3216 - accuracy: 0.8715 - val_loss: 0.3758 - val_accuracy: 0.8625\n",
            "Epoch 144/200\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.2944 - accuracy: 0.8840 - val_loss: 0.3763 - val_accuracy: 0.8750\n",
            "Epoch 145/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.3167 - accuracy: 0.8730 - val_loss: 0.4328 - val_accuracy: 0.8125\n",
            "Epoch 146/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.3384 - accuracy: 0.8636 - val_loss: 0.3645 - val_accuracy: 0.8500\n",
            "Epoch 147/200\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.2995 - accuracy: 0.8746 - val_loss: 0.3484 - val_accuracy: 0.8625\n",
            "Epoch 148/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.3174 - accuracy: 0.8746 - val_loss: 0.3526 - val_accuracy: 0.8750\n",
            "Epoch 149/200\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.3301 - accuracy: 0.8824 - val_loss: 0.3455 - val_accuracy: 0.8687\n",
            "Epoch 150/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.3114 - accuracy: 0.8746 - val_loss: 0.3786 - val_accuracy: 0.8375\n",
            "Epoch 151/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.3008 - accuracy: 0.8824 - val_loss: 0.3448 - val_accuracy: 0.8750\n",
            "Epoch 152/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.3208 - accuracy: 0.8715 - val_loss: 0.4509 - val_accuracy: 0.8000\n",
            "Epoch 153/200\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.3152 - accuracy: 0.8605 - val_loss: 0.4144 - val_accuracy: 0.8313\n",
            "Epoch 154/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.2974 - accuracy: 0.8887 - val_loss: 0.4033 - val_accuracy: 0.8375\n",
            "Epoch 155/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.3078 - accuracy: 0.8762 - val_loss: 0.3437 - val_accuracy: 0.8813\n",
            "Epoch 156/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.2888 - accuracy: 0.8903 - val_loss: 0.3889 - val_accuracy: 0.8500\n",
            "Epoch 157/200\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.3153 - accuracy: 0.8652 - val_loss: 0.3821 - val_accuracy: 0.8562\n",
            "Epoch 158/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.2934 - accuracy: 0.8793 - val_loss: 0.4489 - val_accuracy: 0.8250\n",
            "Epoch 159/200\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.3092 - accuracy: 0.8777 - val_loss: 0.3708 - val_accuracy: 0.8500\n",
            "Epoch 160/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.3037 - accuracy: 0.8762 - val_loss: 0.3788 - val_accuracy: 0.8438\n",
            "Epoch 161/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.3154 - accuracy: 0.8824 - val_loss: 0.4031 - val_accuracy: 0.8250\n",
            "Epoch 162/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.3175 - accuracy: 0.8558 - val_loss: 0.3989 - val_accuracy: 0.8375\n",
            "Epoch 163/200\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.3321 - accuracy: 0.8715 - val_loss: 0.3715 - val_accuracy: 0.8438\n",
            "Epoch 164/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.3124 - accuracy: 0.8887 - val_loss: 0.3596 - val_accuracy: 0.8750\n",
            "Epoch 165/200\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.3262 - accuracy: 0.8652 - val_loss: 0.4110 - val_accuracy: 0.8313\n",
            "Epoch 166/200\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.3204 - accuracy: 0.8621 - val_loss: 0.3716 - val_accuracy: 0.8562\n",
            "Epoch 167/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.2955 - accuracy: 0.8777 - val_loss: 0.3830 - val_accuracy: 0.8313\n",
            "Epoch 168/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.3041 - accuracy: 0.8683 - val_loss: 0.3631 - val_accuracy: 0.8562\n",
            "Epoch 169/200\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.2998 - accuracy: 0.8793 - val_loss: 0.4216 - val_accuracy: 0.8062\n",
            "Epoch 170/200\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.3132 - accuracy: 0.8730 - val_loss: 0.4143 - val_accuracy: 0.8062\n",
            "Epoch 171/200\n",
            "20/20 [==============================] - 0s 6ms/step - loss: 0.3003 - accuracy: 0.8699 - val_loss: 0.3931 - val_accuracy: 0.8313\n",
            "Epoch 172/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.3024 - accuracy: 0.8777 - val_loss: 0.3633 - val_accuracy: 0.8687\n",
            "Epoch 173/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.2864 - accuracy: 0.8777 - val_loss: 0.4209 - val_accuracy: 0.8438\n",
            "Epoch 174/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.2942 - accuracy: 0.8840 - val_loss: 0.3990 - val_accuracy: 0.8375\n",
            "Epoch 175/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.3078 - accuracy: 0.8856 - val_loss: 0.3788 - val_accuracy: 0.8562\n",
            "Epoch 176/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.2863 - accuracy: 0.8762 - val_loss: 0.4111 - val_accuracy: 0.8438\n",
            "Epoch 177/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.2883 - accuracy: 0.8871 - val_loss: 0.3571 - val_accuracy: 0.8875\n",
            "Epoch 178/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.3083 - accuracy: 0.8793 - val_loss: 0.3548 - val_accuracy: 0.8687\n",
            "Epoch 179/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.3032 - accuracy: 0.8856 - val_loss: 0.3946 - val_accuracy: 0.8375\n",
            "Epoch 180/200\n",
            "20/20 [==============================] - 0s 6ms/step - loss: 0.2840 - accuracy: 0.8934 - val_loss: 0.3770 - val_accuracy: 0.8562\n",
            "Epoch 181/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.2759 - accuracy: 0.8950 - val_loss: 0.4002 - val_accuracy: 0.8375\n",
            "Epoch 182/200\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.2827 - accuracy: 0.8856 - val_loss: 0.4095 - val_accuracy: 0.8313\n",
            "Epoch 183/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.2948 - accuracy: 0.8715 - val_loss: 0.4422 - val_accuracy: 0.8062\n",
            "Epoch 184/200\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.2966 - accuracy: 0.8856 - val_loss: 0.3970 - val_accuracy: 0.8188\n",
            "Epoch 185/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.2986 - accuracy: 0.8934 - val_loss: 0.3534 - val_accuracy: 0.8625\n",
            "Epoch 186/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.2988 - accuracy: 0.8762 - val_loss: 0.3714 - val_accuracy: 0.8625\n",
            "Epoch 187/200\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.2891 - accuracy: 0.8793 - val_loss: 0.3811 - val_accuracy: 0.8438\n",
            "Epoch 188/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.2949 - accuracy: 0.8777 - val_loss: 0.4233 - val_accuracy: 0.8062\n",
            "Epoch 189/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.2906 - accuracy: 0.8793 - val_loss: 0.4092 - val_accuracy: 0.8188\n",
            "Epoch 190/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.2964 - accuracy: 0.8699 - val_loss: 0.3847 - val_accuracy: 0.8375\n",
            "Epoch 191/200\n",
            "20/20 [==============================] - 0s 7ms/step - loss: 0.2926 - accuracy: 0.8809 - val_loss: 0.4060 - val_accuracy: 0.8313\n",
            "Epoch 192/200\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.2880 - accuracy: 0.8887 - val_loss: 0.3611 - val_accuracy: 0.8438\n",
            "Epoch 193/200\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.2964 - accuracy: 0.8793 - val_loss: 0.3960 - val_accuracy: 0.8188\n",
            "Epoch 194/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.2956 - accuracy: 0.8621 - val_loss: 0.3964 - val_accuracy: 0.8188\n",
            "Epoch 195/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.2930 - accuracy: 0.8746 - val_loss: 0.4334 - val_accuracy: 0.8125\n",
            "Epoch 196/200\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.3031 - accuracy: 0.8652 - val_loss: 0.3796 - val_accuracy: 0.8562\n",
            "Epoch 197/200\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.3019 - accuracy: 0.8762 - val_loss: 0.3662 - val_accuracy: 0.8375\n",
            "Epoch 198/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.2767 - accuracy: 0.8777 - val_loss: 0.3577 - val_accuracy: 0.8813\n",
            "Epoch 199/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.3086 - accuracy: 0.8605 - val_loss: 0.3779 - val_accuracy: 0.8687\n",
            "Epoch 200/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.2827 - accuracy: 0.8840 - val_loss: 0.3881 - val_accuracy: 0.8438\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 0.4206 - accuracy: 0.8500\n",
            "## evaluation loss and_metrics ##\n",
            "[0.4205709993839264, 0.8500000238418579]\n",
            "4/4 [==============================] - 0s 4ms/step\n",
            "0.8857142857142857\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "ST_Slope_Flat"
      ],
      "metadata": {
        "id": "2bSpFySnrJhK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "heart = pd.read_csv(f_path)\n",
        "\n",
        "heart = pd.get_dummies(heart)\n",
        "\n",
        "x = heart.drop('HeartDisease', axis=1)\n",
        "y = pd.get_dummies(heart[\"HeartDisease\"])\n",
        "\n",
        "heart['ST_Slope_Flat'] = 0\n",
        "\n",
        "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size = 0.13,shuffle=True, random_state = 42)\n",
        "\n",
        "print(\"X_train: \", x_train.shape)\n",
        "print(\"y_train: \", y_train.shape)\n",
        "\n",
        "print(\"X_test: \", x_test.shape)\n",
        "print(\"y_test: \", y_test.shape)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "ModelExceptST_Slope_Flat = Sequential()\n",
        "\n",
        "\n",
        "ModelExceptST_Slope_Flat.add(Dense(128, activation = \"relu\",input_dim=20))\n",
        "ModelExceptST_Slope_Flat.add(Dropout(rate=0.2))\n",
        "ModelExceptST_Slope_Flat.add(Dense(64, activation = \"relu\"))\n",
        "ModelExceptST_Slope_Flat.add(Dropout(rate=0.2))\n",
        "ModelExceptST_Slope_Flat.add(Dense(32, activation = \"relu\"))\n",
        "ModelExceptST_Slope_Flat.add(Dropout(rate=0.1))\n",
        "ModelExceptST_Slope_Flat.add(Dense(16, activation = \"relu\"))\n",
        "ModelExceptST_Slope_Flat.add(Dense(8, activation = \"relu\"))\n",
        "ModelExceptST_Slope_Flat.add(Dense(2, activation = \"sigmoid\"))\n",
        "\n",
        "ModelExceptST_Slope_Flat.compile(optimizer = \"adam\", loss = \"categorical_crossentropy\", metrics = [\"accuracy\"])\n",
        "ModelExceptST_Slope_Flat.summary()\n",
        "\n",
        "hin=ModelExceptST_Slope_Flat.fit(x_train,y_train,epochs=200, validation_split=0.2)\n",
        "\n",
        "loss_and_metrics = ModelExceptST_Slope_Flat.evaluate(x_test, y_test, batch_size=32)\n",
        "print('## evaluation loss and_metrics ##')\n",
        "print(loss_and_metrics)\n",
        "\n",
        "y_predST_Slope_Flat = ModelExceptST_Slope_Flat.predict(x_test)\n",
        "y_predST_Slope_Flat\n",
        "\n",
        "y_pred_classST_Slope_Flat = np.argmax(y_predST_Slope_Flat, axis=1)\n",
        "y_pred_classST_Slope_Flat\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "y_test  = y_test.to_numpy()\n",
        "y_test\n",
        "\n",
        "y_test = np.argmax(y_test,axis=1)\n",
        "y_test\n",
        "\n",
        "np.mean(y_test == y_pred_classST_Slope_Flat)\n",
        "ST_Slope_Flatscore=recall_score(y_test,y_pred_classST_Slope_Flat)\n",
        "print(ST_Slope_Flatscore)"
      ],
      "metadata": {
        "id": "qil0aaL3zBJY",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "49fac677-f8bf-4e81-d06d-111672bf8ea2"
      },
      "execution_count": 101,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "X_train:  (798, 20)\n",
            "y_train:  (798, 2)\n",
            "X_test:  (120, 20)\n",
            "y_test:  (120, 2)\n",
            "Model: \"sequential_23\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense_138 (Dense)           (None, 128)               2688      \n",
            "                                                                 \n",
            " dropout_69 (Dropout)        (None, 128)               0         \n",
            "                                                                 \n",
            " dense_139 (Dense)           (None, 64)                8256      \n",
            "                                                                 \n",
            " dropout_70 (Dropout)        (None, 64)                0         \n",
            "                                                                 \n",
            " dense_140 (Dense)           (None, 32)                2080      \n",
            "                                                                 \n",
            " dropout_71 (Dropout)        (None, 32)                0         \n",
            "                                                                 \n",
            " dense_141 (Dense)           (None, 16)                528       \n",
            "                                                                 \n",
            " dense_142 (Dense)           (None, 8)                 136       \n",
            "                                                                 \n",
            " dense_143 (Dense)           (None, 2)                 18        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 13,706\n",
            "Trainable params: 13,706\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/200\n",
            "20/20 [==============================] - 1s 12ms/step - loss: 1.2635 - accuracy: 0.5643 - val_loss: 0.7956 - val_accuracy: 0.5063\n",
            "Epoch 2/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.8729 - accuracy: 0.5376 - val_loss: 0.7655 - val_accuracy: 0.3250\n",
            "Epoch 3/200\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.7932 - accuracy: 0.5361 - val_loss: 0.6354 - val_accuracy: 0.4875\n",
            "Epoch 4/200\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.7230 - accuracy: 0.5533 - val_loss: 0.6387 - val_accuracy: 0.4875\n",
            "Epoch 5/200\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.7080 - accuracy: 0.5502 - val_loss: 0.6348 - val_accuracy: 0.4938\n",
            "Epoch 6/200\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.6858 - accuracy: 0.5376 - val_loss: 0.6276 - val_accuracy: 0.4938\n",
            "Epoch 7/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.6769 - accuracy: 0.5486 - val_loss: 0.6275 - val_accuracy: 0.4938\n",
            "Epoch 8/200\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.6703 - accuracy: 0.5705 - val_loss: 0.6286 - val_accuracy: 0.4938\n",
            "Epoch 9/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.6496 - accuracy: 0.5580 - val_loss: 0.6303 - val_accuracy: 0.4938\n",
            "Epoch 10/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.6589 - accuracy: 0.5752 - val_loss: 0.6257 - val_accuracy: 0.4938\n",
            "Epoch 11/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.6730 - accuracy: 0.5580 - val_loss: 0.6349 - val_accuracy: 0.4938\n",
            "Epoch 12/200\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.6582 - accuracy: 0.5549 - val_loss: 0.6299 - val_accuracy: 0.4938\n",
            "Epoch 13/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.6485 - accuracy: 0.5690 - val_loss: 0.6303 - val_accuracy: 0.4938\n",
            "Epoch 14/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.6665 - accuracy: 0.5658 - val_loss: 0.6278 - val_accuracy: 0.4938\n",
            "Epoch 15/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.6639 - accuracy: 0.5643 - val_loss: 0.6249 - val_accuracy: 0.4938\n",
            "Epoch 16/200\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.6511 - accuracy: 0.5596 - val_loss: 0.6237 - val_accuracy: 0.4938\n",
            "Epoch 17/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.6730 - accuracy: 0.5611 - val_loss: 0.6227 - val_accuracy: 0.4938\n",
            "Epoch 18/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.6460 - accuracy: 0.5564 - val_loss: 0.6229 - val_accuracy: 0.4938\n",
            "Epoch 19/200\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.6493 - accuracy: 0.5643 - val_loss: 0.6213 - val_accuracy: 0.4938\n",
            "Epoch 20/200\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.6419 - accuracy: 0.5674 - val_loss: 0.6198 - val_accuracy: 0.4938\n",
            "Epoch 21/200\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.6571 - accuracy: 0.5486 - val_loss: 0.6183 - val_accuracy: 0.4938\n",
            "Epoch 22/200\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.6428 - accuracy: 0.5674 - val_loss: 0.6169 - val_accuracy: 0.4938\n",
            "Epoch 23/200\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.6398 - accuracy: 0.5674 - val_loss: 0.6181 - val_accuracy: 0.5500\n",
            "Epoch 24/200\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.6392 - accuracy: 0.6113 - val_loss: 0.6225 - val_accuracy: 0.5063\n",
            "Epoch 25/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.6407 - accuracy: 0.6176 - val_loss: 0.6182 - val_accuracy: 0.6062\n",
            "Epoch 26/200\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.6423 - accuracy: 0.6223 - val_loss: 0.6171 - val_accuracy: 0.5750\n",
            "Epoch 27/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.6429 - accuracy: 0.6034 - val_loss: 0.6147 - val_accuracy: 0.7188\n",
            "Epoch 28/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.6392 - accuracy: 0.6238 - val_loss: 0.6145 - val_accuracy: 0.6687\n",
            "Epoch 29/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.6406 - accuracy: 0.6160 - val_loss: 0.6128 - val_accuracy: 0.6812\n",
            "Epoch 30/200\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.6411 - accuracy: 0.6113 - val_loss: 0.6131 - val_accuracy: 0.7188\n",
            "Epoch 31/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.6317 - accuracy: 0.6520 - val_loss: 0.6152 - val_accuracy: 0.6375\n",
            "Epoch 32/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.6408 - accuracy: 0.6489 - val_loss: 0.6101 - val_accuracy: 0.6625\n",
            "Epoch 33/200\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.6354 - accuracy: 0.5987 - val_loss: 0.6079 - val_accuracy: 0.7312\n",
            "Epoch 34/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.6439 - accuracy: 0.6348 - val_loss: 0.6212 - val_accuracy: 0.5375\n",
            "Epoch 35/200\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.6304 - accuracy: 0.6395 - val_loss: 0.6195 - val_accuracy: 0.5437\n",
            "Epoch 36/200\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.6381 - accuracy: 0.6348 - val_loss: 0.6175 - val_accuracy: 0.5750\n",
            "Epoch 37/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.6397 - accuracy: 0.6332 - val_loss: 0.6209 - val_accuracy: 0.5500\n",
            "Epoch 38/200\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.6382 - accuracy: 0.6411 - val_loss: 0.6090 - val_accuracy: 0.6875\n",
            "Epoch 39/200\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.6367 - accuracy: 0.6207 - val_loss: 0.5973 - val_accuracy: 0.7250\n",
            "Epoch 40/200\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.6165 - accuracy: 0.6787 - val_loss: 0.5994 - val_accuracy: 0.7188\n",
            "Epoch 41/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.6239 - accuracy: 0.6567 - val_loss: 0.5968 - val_accuracy: 0.7375\n",
            "Epoch 42/200\n",
            "20/20 [==============================] - 0s 6ms/step - loss: 0.6204 - accuracy: 0.6646 - val_loss: 0.5910 - val_accuracy: 0.7250\n",
            "Epoch 43/200\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.6161 - accuracy: 0.6724 - val_loss: 0.5876 - val_accuracy: 0.7437\n",
            "Epoch 44/200\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.6176 - accuracy: 0.6520 - val_loss: 0.5850 - val_accuracy: 0.7188\n",
            "Epoch 45/200\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.6073 - accuracy: 0.6850 - val_loss: 0.5828 - val_accuracy: 0.7375\n",
            "Epoch 46/200\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.5946 - accuracy: 0.6959 - val_loss: 0.5846 - val_accuracy: 0.7188\n",
            "Epoch 47/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.6191 - accuracy: 0.6677 - val_loss: 0.6020 - val_accuracy: 0.6438\n",
            "Epoch 48/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.6098 - accuracy: 0.7210 - val_loss: 0.5714 - val_accuracy: 0.7437\n",
            "Epoch 49/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.6056 - accuracy: 0.6803 - val_loss: 0.5886 - val_accuracy: 0.7063\n",
            "Epoch 50/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.6004 - accuracy: 0.6881 - val_loss: 0.5658 - val_accuracy: 0.7437\n",
            "Epoch 51/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.5971 - accuracy: 0.6975 - val_loss: 0.5630 - val_accuracy: 0.7563\n",
            "Epoch 52/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.5942 - accuracy: 0.7147 - val_loss: 0.5636 - val_accuracy: 0.7500\n",
            "Epoch 53/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.5720 - accuracy: 0.7226 - val_loss: 0.5486 - val_accuracy: 0.7812\n",
            "Epoch 54/200\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.5854 - accuracy: 0.7194 - val_loss: 0.5475 - val_accuracy: 0.7688\n",
            "Epoch 55/200\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.6078 - accuracy: 0.7022 - val_loss: 0.5435 - val_accuracy: 0.7812\n",
            "Epoch 56/200\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.5899 - accuracy: 0.7085 - val_loss: 0.5453 - val_accuracy: 0.7875\n",
            "Epoch 57/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.5757 - accuracy: 0.7382 - val_loss: 0.5452 - val_accuracy: 0.7625\n",
            "Epoch 58/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.5745 - accuracy: 0.7257 - val_loss: 0.5368 - val_accuracy: 0.7875\n",
            "Epoch 59/200\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.5582 - accuracy: 0.7398 - val_loss: 0.5679 - val_accuracy: 0.7312\n",
            "Epoch 60/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.5793 - accuracy: 0.7367 - val_loss: 0.5633 - val_accuracy: 0.7312\n",
            "Epoch 61/200\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.5446 - accuracy: 0.7445 - val_loss: 0.5283 - val_accuracy: 0.7875\n",
            "Epoch 62/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.5571 - accuracy: 0.7492 - val_loss: 0.5308 - val_accuracy: 0.7625\n",
            "Epoch 63/200\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.5541 - accuracy: 0.7539 - val_loss: 0.5096 - val_accuracy: 0.8000\n",
            "Epoch 64/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.5570 - accuracy: 0.7508 - val_loss: 0.5174 - val_accuracy: 0.8125\n",
            "Epoch 65/200\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.5486 - accuracy: 0.7539 - val_loss: 0.5111 - val_accuracy: 0.8062\n",
            "Epoch 66/200\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.5463 - accuracy: 0.7586 - val_loss: 0.5049 - val_accuracy: 0.8188\n",
            "Epoch 67/200\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.5350 - accuracy: 0.7712 - val_loss: 0.5295 - val_accuracy: 0.7688\n",
            "Epoch 68/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.5416 - accuracy: 0.7602 - val_loss: 0.5251 - val_accuracy: 0.7875\n",
            "Epoch 69/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.5411 - accuracy: 0.7429 - val_loss: 0.5064 - val_accuracy: 0.7875\n",
            "Epoch 70/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.5280 - accuracy: 0.7821 - val_loss: 0.4947 - val_accuracy: 0.8250\n",
            "Epoch 71/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.5334 - accuracy: 0.7586 - val_loss: 0.5015 - val_accuracy: 0.8125\n",
            "Epoch 72/200\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.5145 - accuracy: 0.7900 - val_loss: 0.4809 - val_accuracy: 0.8188\n",
            "Epoch 73/200\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.5157 - accuracy: 0.7962 - val_loss: 0.4883 - val_accuracy: 0.8125\n",
            "Epoch 74/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.5020 - accuracy: 0.7884 - val_loss: 0.4730 - val_accuracy: 0.8188\n",
            "Epoch 75/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.5018 - accuracy: 0.7837 - val_loss: 0.4803 - val_accuracy: 0.8188\n",
            "Epoch 76/200\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.5035 - accuracy: 0.7821 - val_loss: 0.4749 - val_accuracy: 0.8250\n",
            "Epoch 77/200\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.5013 - accuracy: 0.8041 - val_loss: 0.4957 - val_accuracy: 0.8000\n",
            "Epoch 78/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.4860 - accuracy: 0.8072 - val_loss: 0.4641 - val_accuracy: 0.8250\n",
            "Epoch 79/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.4951 - accuracy: 0.8009 - val_loss: 0.4588 - val_accuracy: 0.8250\n",
            "Epoch 80/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.4786 - accuracy: 0.8025 - val_loss: 0.4972 - val_accuracy: 0.8000\n",
            "Epoch 81/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.4793 - accuracy: 0.8041 - val_loss: 0.4849 - val_accuracy: 0.8125\n",
            "Epoch 82/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.4815 - accuracy: 0.7978 - val_loss: 0.4740 - val_accuracy: 0.8125\n",
            "Epoch 83/200\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.4528 - accuracy: 0.8229 - val_loss: 0.4595 - val_accuracy: 0.8313\n",
            "Epoch 84/200\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.4588 - accuracy: 0.8135 - val_loss: 0.4400 - val_accuracy: 0.8438\n",
            "Epoch 85/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.4684 - accuracy: 0.8260 - val_loss: 0.4643 - val_accuracy: 0.8188\n",
            "Epoch 86/200\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.4590 - accuracy: 0.8182 - val_loss: 0.4486 - val_accuracy: 0.8375\n",
            "Epoch 87/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.4435 - accuracy: 0.8386 - val_loss: 0.4584 - val_accuracy: 0.8250\n",
            "Epoch 88/200\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.4481 - accuracy: 0.8213 - val_loss: 0.4362 - val_accuracy: 0.8375\n",
            "Epoch 89/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.4435 - accuracy: 0.8370 - val_loss: 0.4412 - val_accuracy: 0.8375\n",
            "Epoch 90/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.4566 - accuracy: 0.8245 - val_loss: 0.4331 - val_accuracy: 0.8438\n",
            "Epoch 91/200\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.4254 - accuracy: 0.8323 - val_loss: 0.4332 - val_accuracy: 0.8375\n",
            "Epoch 92/200\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.4373 - accuracy: 0.8197 - val_loss: 0.4274 - val_accuracy: 0.8375\n",
            "Epoch 93/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.4346 - accuracy: 0.8323 - val_loss: 0.4393 - val_accuracy: 0.8375\n",
            "Epoch 94/200\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.4286 - accuracy: 0.8323 - val_loss: 0.4216 - val_accuracy: 0.8313\n",
            "Epoch 95/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.4089 - accuracy: 0.8323 - val_loss: 0.4095 - val_accuracy: 0.8438\n",
            "Epoch 96/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.4224 - accuracy: 0.8370 - val_loss: 0.4226 - val_accuracy: 0.8438\n",
            "Epoch 97/200\n",
            "20/20 [==============================] - 0s 6ms/step - loss: 0.4146 - accuracy: 0.8339 - val_loss: 0.4204 - val_accuracy: 0.8500\n",
            "Epoch 98/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.3978 - accuracy: 0.8464 - val_loss: 0.4135 - val_accuracy: 0.8625\n",
            "Epoch 99/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.3977 - accuracy: 0.8292 - val_loss: 0.4210 - val_accuracy: 0.8438\n",
            "Epoch 100/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.4133 - accuracy: 0.8307 - val_loss: 0.4032 - val_accuracy: 0.8562\n",
            "Epoch 101/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.4165 - accuracy: 0.8339 - val_loss: 0.3668 - val_accuracy: 0.8562\n",
            "Epoch 102/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.3968 - accuracy: 0.8448 - val_loss: 0.3984 - val_accuracy: 0.8500\n",
            "Epoch 103/200\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.3920 - accuracy: 0.8495 - val_loss: 0.3820 - val_accuracy: 0.8562\n",
            "Epoch 104/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.3654 - accuracy: 0.8480 - val_loss: 0.4184 - val_accuracy: 0.8188\n",
            "Epoch 105/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.3768 - accuracy: 0.8417 - val_loss: 0.3746 - val_accuracy: 0.8500\n",
            "Epoch 106/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.3980 - accuracy: 0.8433 - val_loss: 0.3781 - val_accuracy: 0.8500\n",
            "Epoch 107/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.3701 - accuracy: 0.8636 - val_loss: 0.3739 - val_accuracy: 0.8500\n",
            "Epoch 108/200\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.3838 - accuracy: 0.8417 - val_loss: 0.3902 - val_accuracy: 0.8500\n",
            "Epoch 109/200\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.3801 - accuracy: 0.8511 - val_loss: 0.4035 - val_accuracy: 0.8375\n",
            "Epoch 110/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.3611 - accuracy: 0.8527 - val_loss: 0.3576 - val_accuracy: 0.8562\n",
            "Epoch 111/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.3491 - accuracy: 0.8683 - val_loss: 0.3918 - val_accuracy: 0.8625\n",
            "Epoch 112/200\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.3789 - accuracy: 0.8589 - val_loss: 0.3494 - val_accuracy: 0.8625\n",
            "Epoch 113/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.3653 - accuracy: 0.8433 - val_loss: 0.3658 - val_accuracy: 0.8500\n",
            "Epoch 114/200\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.3676 - accuracy: 0.8495 - val_loss: 0.3701 - val_accuracy: 0.8562\n",
            "Epoch 115/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.3629 - accuracy: 0.8401 - val_loss: 0.3977 - val_accuracy: 0.8250\n",
            "Epoch 116/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.3558 - accuracy: 0.8699 - val_loss: 0.3798 - val_accuracy: 0.8438\n",
            "Epoch 117/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.3374 - accuracy: 0.8605 - val_loss: 0.3728 - val_accuracy: 0.8438\n",
            "Epoch 118/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.3624 - accuracy: 0.8589 - val_loss: 0.3750 - val_accuracy: 0.8500\n",
            "Epoch 119/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.3458 - accuracy: 0.8605 - val_loss: 0.3355 - val_accuracy: 0.8625\n",
            "Epoch 120/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.3442 - accuracy: 0.8589 - val_loss: 0.3577 - val_accuracy: 0.8625\n",
            "Epoch 121/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.3365 - accuracy: 0.8683 - val_loss: 0.3682 - val_accuracy: 0.8562\n",
            "Epoch 122/200\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.3714 - accuracy: 0.8621 - val_loss: 0.3812 - val_accuracy: 0.8438\n",
            "Epoch 123/200\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.3387 - accuracy: 0.8636 - val_loss: 0.3764 - val_accuracy: 0.8562\n",
            "Epoch 124/200\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.3466 - accuracy: 0.8527 - val_loss: 0.3642 - val_accuracy: 0.8687\n",
            "Epoch 125/200\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.3377 - accuracy: 0.8668 - val_loss: 0.3779 - val_accuracy: 0.8562\n",
            "Epoch 126/200\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.3411 - accuracy: 0.8683 - val_loss: 0.3860 - val_accuracy: 0.8438\n",
            "Epoch 127/200\n",
            "20/20 [==============================] - 0s 6ms/step - loss: 0.3338 - accuracy: 0.8730 - val_loss: 0.4284 - val_accuracy: 0.8188\n",
            "Epoch 128/200\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.3406 - accuracy: 0.8480 - val_loss: 0.3677 - val_accuracy: 0.8500\n",
            "Epoch 129/200\n",
            "20/20 [==============================] - 0s 6ms/step - loss: 0.3265 - accuracy: 0.8793 - val_loss: 0.3570 - val_accuracy: 0.8750\n",
            "Epoch 130/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.3393 - accuracy: 0.8699 - val_loss: 0.3501 - val_accuracy: 0.8687\n",
            "Epoch 131/200\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.3111 - accuracy: 0.8762 - val_loss: 0.3939 - val_accuracy: 0.8438\n",
            "Epoch 132/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.3255 - accuracy: 0.8746 - val_loss: 0.3551 - val_accuracy: 0.8625\n",
            "Epoch 133/200\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.3351 - accuracy: 0.8730 - val_loss: 0.3895 - val_accuracy: 0.8375\n",
            "Epoch 134/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.3349 - accuracy: 0.8589 - val_loss: 0.3543 - val_accuracy: 0.8687\n",
            "Epoch 135/200\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.3435 - accuracy: 0.8574 - val_loss: 0.4175 - val_accuracy: 0.8062\n",
            "Epoch 136/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.3208 - accuracy: 0.8746 - val_loss: 0.3506 - val_accuracy: 0.8687\n",
            "Epoch 137/200\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.3491 - accuracy: 0.8699 - val_loss: 0.3522 - val_accuracy: 0.8687\n",
            "Epoch 138/200\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.3208 - accuracy: 0.8636 - val_loss: 0.3440 - val_accuracy: 0.8562\n",
            "Epoch 139/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.3168 - accuracy: 0.8793 - val_loss: 0.3548 - val_accuracy: 0.8687\n",
            "Epoch 140/200\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.3221 - accuracy: 0.8715 - val_loss: 0.4144 - val_accuracy: 0.8188\n",
            "Epoch 141/200\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.3136 - accuracy: 0.8683 - val_loss: 0.4550 - val_accuracy: 0.8062\n",
            "Epoch 142/200\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.3152 - accuracy: 0.8824 - val_loss: 0.3989 - val_accuracy: 0.8500\n",
            "Epoch 143/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.3224 - accuracy: 0.8683 - val_loss: 0.3606 - val_accuracy: 0.8562\n",
            "Epoch 144/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.3141 - accuracy: 0.8683 - val_loss: 0.3864 - val_accuracy: 0.8625\n",
            "Epoch 145/200\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.3187 - accuracy: 0.8715 - val_loss: 0.3528 - val_accuracy: 0.8625\n",
            "Epoch 146/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.3173 - accuracy: 0.8636 - val_loss: 0.4029 - val_accuracy: 0.8500\n",
            "Epoch 147/200\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.3155 - accuracy: 0.8652 - val_loss: 0.3729 - val_accuracy: 0.8625\n",
            "Epoch 148/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.3009 - accuracy: 0.8824 - val_loss: 0.3564 - val_accuracy: 0.8625\n",
            "Epoch 149/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.3326 - accuracy: 0.8746 - val_loss: 0.3836 - val_accuracy: 0.8562\n",
            "Epoch 150/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.3283 - accuracy: 0.8746 - val_loss: 0.3664 - val_accuracy: 0.8625\n",
            "Epoch 151/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.3319 - accuracy: 0.8699 - val_loss: 0.3806 - val_accuracy: 0.8625\n",
            "Epoch 152/200\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.3051 - accuracy: 0.8762 - val_loss: 0.3997 - val_accuracy: 0.8500\n",
            "Epoch 153/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.3129 - accuracy: 0.8746 - val_loss: 0.3744 - val_accuracy: 0.8562\n",
            "Epoch 154/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.3022 - accuracy: 0.8824 - val_loss: 0.3687 - val_accuracy: 0.8687\n",
            "Epoch 155/200\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.3165 - accuracy: 0.8636 - val_loss: 0.3733 - val_accuracy: 0.8625\n",
            "Epoch 156/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.3125 - accuracy: 0.8668 - val_loss: 0.3680 - val_accuracy: 0.8562\n",
            "Epoch 157/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.3190 - accuracy: 0.8668 - val_loss: 0.3918 - val_accuracy: 0.8375\n",
            "Epoch 158/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.3186 - accuracy: 0.8683 - val_loss: 0.3673 - val_accuracy: 0.8562\n",
            "Epoch 159/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.3217 - accuracy: 0.8715 - val_loss: 0.3600 - val_accuracy: 0.8687\n",
            "Epoch 160/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.3182 - accuracy: 0.8730 - val_loss: 0.3666 - val_accuracy: 0.8625\n",
            "Epoch 161/200\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.3300 - accuracy: 0.8746 - val_loss: 0.3503 - val_accuracy: 0.8625\n",
            "Epoch 162/200\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.3246 - accuracy: 0.8715 - val_loss: 0.3782 - val_accuracy: 0.8562\n",
            "Epoch 163/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.3184 - accuracy: 0.8840 - val_loss: 0.3655 - val_accuracy: 0.8562\n",
            "Epoch 164/200\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.3084 - accuracy: 0.8793 - val_loss: 0.3978 - val_accuracy: 0.8562\n",
            "Epoch 165/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.3029 - accuracy: 0.8730 - val_loss: 0.3579 - val_accuracy: 0.8625\n",
            "Epoch 166/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.3003 - accuracy: 0.8746 - val_loss: 0.3606 - val_accuracy: 0.8625\n",
            "Epoch 167/200\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.3181 - accuracy: 0.8793 - val_loss: 0.3684 - val_accuracy: 0.8687\n",
            "Epoch 168/200\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.3096 - accuracy: 0.8699 - val_loss: 0.3587 - val_accuracy: 0.8813\n",
            "Epoch 169/200\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.3049 - accuracy: 0.8668 - val_loss: 0.3980 - val_accuracy: 0.8438\n",
            "Epoch 170/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.3114 - accuracy: 0.8668 - val_loss: 0.3605 - val_accuracy: 0.8687\n",
            "Epoch 171/200\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.3032 - accuracy: 0.8762 - val_loss: 0.3606 - val_accuracy: 0.8625\n",
            "Epoch 172/200\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.3115 - accuracy: 0.8699 - val_loss: 0.3918 - val_accuracy: 0.8500\n",
            "Epoch 173/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.3054 - accuracy: 0.8856 - val_loss: 0.3626 - val_accuracy: 0.8750\n",
            "Epoch 174/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.3101 - accuracy: 0.8824 - val_loss: 0.3562 - val_accuracy: 0.8625\n",
            "Epoch 175/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.3062 - accuracy: 0.8730 - val_loss: 0.3819 - val_accuracy: 0.8625\n",
            "Epoch 176/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.3135 - accuracy: 0.8762 - val_loss: 0.3861 - val_accuracy: 0.8438\n",
            "Epoch 177/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.3014 - accuracy: 0.8762 - val_loss: 0.3714 - val_accuracy: 0.8500\n",
            "Epoch 178/200\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.3008 - accuracy: 0.8809 - val_loss: 0.3838 - val_accuracy: 0.8500\n",
            "Epoch 179/200\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.3036 - accuracy: 0.8793 - val_loss: 0.3515 - val_accuracy: 0.8687\n",
            "Epoch 180/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.3088 - accuracy: 0.8746 - val_loss: 0.3714 - val_accuracy: 0.8500\n",
            "Epoch 181/200\n",
            "20/20 [==============================] - 0s 6ms/step - loss: 0.2923 - accuracy: 0.8746 - val_loss: 0.3871 - val_accuracy: 0.8500\n",
            "Epoch 182/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.3040 - accuracy: 0.8777 - val_loss: 0.4158 - val_accuracy: 0.8313\n",
            "Epoch 183/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.3008 - accuracy: 0.8871 - val_loss: 0.3663 - val_accuracy: 0.8562\n",
            "Epoch 184/200\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.2992 - accuracy: 0.8762 - val_loss: 0.4033 - val_accuracy: 0.8500\n",
            "Epoch 185/200\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.3006 - accuracy: 0.8746 - val_loss: 0.3621 - val_accuracy: 0.8625\n",
            "Epoch 186/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.3063 - accuracy: 0.8605 - val_loss: 0.3900 - val_accuracy: 0.8625\n",
            "Epoch 187/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.3222 - accuracy: 0.8699 - val_loss: 0.4114 - val_accuracy: 0.8250\n",
            "Epoch 188/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.3086 - accuracy: 0.8715 - val_loss: 0.3637 - val_accuracy: 0.8625\n",
            "Epoch 189/200\n",
            "20/20 [==============================] - 0s 6ms/step - loss: 0.2933 - accuracy: 0.8793 - val_loss: 0.4115 - val_accuracy: 0.8313\n",
            "Epoch 190/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.2848 - accuracy: 0.8793 - val_loss: 0.3718 - val_accuracy: 0.8687\n",
            "Epoch 191/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.2930 - accuracy: 0.8683 - val_loss: 0.3783 - val_accuracy: 0.8687\n",
            "Epoch 192/200\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.2882 - accuracy: 0.8809 - val_loss: 0.4143 - val_accuracy: 0.8375\n",
            "Epoch 193/200\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.2918 - accuracy: 0.8715 - val_loss: 0.3715 - val_accuracy: 0.8500\n",
            "Epoch 194/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.2864 - accuracy: 0.8871 - val_loss: 0.3878 - val_accuracy: 0.8375\n",
            "Epoch 195/200\n",
            "20/20 [==============================] - 0s 6ms/step - loss: 0.2955 - accuracy: 0.8762 - val_loss: 0.3996 - val_accuracy: 0.8375\n",
            "Epoch 196/200\n",
            "20/20 [==============================] - 0s 6ms/step - loss: 0.2800 - accuracy: 0.8856 - val_loss: 0.3944 - val_accuracy: 0.8625\n",
            "Epoch 197/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.2891 - accuracy: 0.8793 - val_loss: 0.3707 - val_accuracy: 0.8750\n",
            "Epoch 198/200\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.3082 - accuracy: 0.8762 - val_loss: 0.4284 - val_accuracy: 0.8188\n",
            "Epoch 199/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.2921 - accuracy: 0.8824 - val_loss: 0.4160 - val_accuracy: 0.8375\n",
            "Epoch 200/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.2884 - accuracy: 0.8809 - val_loss: 0.3373 - val_accuracy: 0.8562\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.4372 - accuracy: 0.8500\n",
            "## evaluation loss and_metrics ##\n",
            "[0.4371781051158905, 0.8500000238418579]\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "0.8285714285714286\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "heart.count()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JVYkcSlfsU_1",
        "outputId": "eb42bd33-aa7a-41f3-87d2-6e9122f056dc"
      },
      "execution_count": 103,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Age                  918\n",
              "RestingBP            918\n",
              "Cholesterol          918\n",
              "FastingBS            918\n",
              "MaxHR                918\n",
              "Oldpeak              918\n",
              "HeartDisease         918\n",
              "Sex_F                918\n",
              "Sex_M                918\n",
              "ChestPainType_ASY    918\n",
              "ChestPainType_ATA    918\n",
              "ChestPainType_NAP    918\n",
              "ChestPainType_TA     918\n",
              "RestingECG_LVH       918\n",
              "RestingECG_Normal    918\n",
              "RestingECG_ST        918\n",
              "ExerciseAngina_N     918\n",
              "ExerciseAngina_Y     918\n",
              "ST_Slope_Down        918\n",
              "ST_Slope_Flat        918\n",
              "ST_Slope_Up          918\n",
              "dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 103
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "Slupscore=0.8"
      ],
      "metadata": {
        "id": "wDMkYlmCtsmL"
      },
      "execution_count": 106,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test=np.array([Agescore,RestingBP,Cholesterolscore,FastingBSscore, MaxHRscore,  Oldpeakscore,  Sex_Fscore,                \n",
        "Sex_Mscore,                \n",
        "ChestPainType_ASYscore,    \n",
        "ChestPainType_ATAscore,    \n",
        "ChestPainType_NAPscore,    \n",
        "ChestPainType_TAscore,    \n",
        "RestingECG_LVHscore,      \n",
        "RestingECG_Normalscore,   \n",
        "RestingECG_STscore,        \n",
        "ExerciseAngina_Nscore,     \n",
        "ExerciseAngina_Yscore,     \n",
        "ST_Slope_Downscore,        \n",
        "ST_Slope_Flatscore,       \n",
        "Slupscore])"
      ],
      "metadata": {
        "id": "-g7jaf1NscDT"
      },
      "execution_count": 115,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(test)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "URqTFzOMwwzB",
        "outputId": "08ff9b0f-7af9-4bb6-908a-2ded4fef6b65"
      },
      "execution_count": 117,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[0.91428571 0.88571429 0.9        0.87142857 0.92857143 0.88571429\n",
            " 0.68571429 0.9        0.85714286 0.82857143 0.88571429 0.84285714\n",
            " 0.91428571 0.9        0.87142857 0.87142857 0.91428571 0.88571429\n",
            " 0.82857143 0.8       ]\n"
          ]
        }
      ]
    }
  ]
}